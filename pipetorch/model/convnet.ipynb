{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting convnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile convnet.py\n",
    "from torchvision.models import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def split_int_tuple(value, hdefault=None, vdefault=None):\n",
    "    try:\n",
    "        return value[0], value[1]\n",
    "    except:\n",
    "        if value is None:\n",
    "            return hdefault, vdefault\n",
    "        return value, value\n",
    "\n",
    "def compute_size(size, kernel, stride, padding, layer):\n",
    "    s = (size - kernel + 2 * padding) / stride + 1\n",
    "    assert s == int(s), f'size {size} at layer {layer} does not match with kernel size {kernel}, stride {stride} and padding {padding}'\n",
    "    return int(s)\n",
    "\n",
    "def greyscale(x):\n",
    "    return  x[:,0,:,:].view(x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Construct a Convolutional Network based on the given parameters. The networks is always built up as\n",
    "    a sequence of Convolutional layers, followed by a sequence of Linear layers. The number of pixels \n",
    "    at the end of the convolutional layer is automatically computed, and the final layer is automatically added.\n",
    "\n",
    "    Args:\n",
    "        *layers: int\n",
    "            one or more channel sizes that are used for the convolutional layers. e.g for RGB images (3 channels)\n",
    "            that are processed by two convolutional layers of resp. 32 and 64 filters, set layers to 3, 32, 64.\n",
    "            \n",
    "        size: int or (int, int) (default 224)\n",
    "            the height and width of the images. When squared images are used, one number is enough.\n",
    "            \n",
    "        kernel_size: int or (int, int) (default 3)\n",
    "            the height and width of the kernel used in the nn.Conv2d layers.\n",
    "            \n",
    "        stride: int or (int, int) (default 1)\n",
    "            the stride used in the nn.Conv2d layers\n",
    "            \n",
    "        padding: int or (int, int) (default None)\n",
    "            the padding used in de nn.Conv2d layers, None means kern_size // 2 is used\n",
    "            \n",
    "        pool_size: int or (int, int) (default 2)\n",
    "            the kernel size used in nn.MaxPool2d\n",
    "            \n",
    "        pool_stride: int or (int, int) (default 2)\n",
    "            the stride used in nn.MaxPool2d\n",
    "            \n",
    "        preprocess: func (None)\n",
    "            a function that is called on X prior to feeding the input to the first layer.\n",
    "            \n",
    "        batchnorm: bool (False)\n",
    "            if True, then nn.BatchNorm2d are added to every concolutional layer\n",
    "            \n",
    "        linear: int or [int] ([])\n",
    "            the convolutional network is always finished by one or more linear layers. The default adds\n",
    "            a single linear layer, automatically computing the number of pixels after the last convolutional \n",
    "            layer, no information is needed except num_classes. Alternatively, a single int adds two linear \n",
    "            layers where the int is the hidden size. Or when linear is a list, the list contains the hidden\n",
    "            layer sizes of consecutive hidden layers.\n",
    "            \n",
    "        num_classes: int (default 1)\n",
    "            the number of outputs\n",
    "            \n",
    "        final_activation: func (None)\n",
    "            the activation function on the ouput layer. If None and num_classes == 1, binary classification is\n",
    "            assumed and a nn.Sigmoid is added, otherwise a multi-label classification is assumed and no\n",
    "            final activation function is added. You can override by providing a final activation function, or\n",
    "            if no activation is needed with num_classes==1 pass final_activation=lambda x:x\n",
    "            \n",
    "        post_forward: func (None)\n",
    "            The PipeTorch trainer uses the post_forward function on a model to process the results after\n",
    "            the loss function and before the evaluation. Typical and default use for binary classification \n",
    "            is to use torch.round() on the estimated likelihoods and for multi-label classification to use \n",
    "            torch.argmax(). To override the default, pass a function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *layers, size=224, kernel_size=3, stride=1, linear=[], padding=None, pool_size=2, \n",
    "                 pool_stride=2, preprocess=None, batchnorm=False, num_classes=1, final_activation=None,\n",
    "                 post_forward=None):\n",
    "        super().__init__()\n",
    "        self.preprocess = preprocess\n",
    "        hstride, vstride = split_int_tuple(stride)\n",
    "        hkernel, vkernel = split_int_tuple(kernel_size)\n",
    "        hpadding, vpadding = split_int_tuple(padding, hkernel // 2, vkernel // 2)\n",
    "        hpixels, vpixels = split_int_tuple(size)\n",
    "        hpool_size, vpool_size = split_int_tuple(pool_size)\n",
    "        hpool_stride, vpool_stride = split_int_tuple(pool_stride)\n",
    "        self.layers = []\n",
    "        self.linears = []\n",
    "        for i, o in zip(layers[:-1], layers[1:]):\n",
    "            if batchnorm:\n",
    "                layer = nn.Sequential( \n",
    "                    nn.Conv2d(i, o, kernel_size=(hkernel, vkernel), stride=(hstride, vstride), padding=(hpadding, vpadding)),\n",
    "                    nn.BatchNorm2d(o),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=(hpool_size, vpool_size), stride=(hpool_stride, vpool_stride)))\n",
    "            else:\n",
    "                layer = nn.Sequential( \n",
    "                    nn.Conv2d(i, o, kernel_size=(hkernel, vkernel), stride=(hstride, vstride), padding=(hpadding, vpadding)),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=(hpool_size, vpool_size), stride=(hpool_stride, vpool_stride)))\n",
    "            n = self._add_layer(layer)\n",
    "            self.layers.append(layer)\n",
    "            hpixels = compute_size(hpixels, hkernel, hstride, hpadding, f'horizontal conv{n}')\n",
    "            vpixels = compute_size(vpixels, vkernel, vstride, vpadding, f'vertical conv{n}')\n",
    "            hpixels = compute_size(hpixels, hpool_size, hpool_stride, 0, f'horizontal pool{n}')\n",
    "            vpixels = compute_size(vpixels, vpool_size, vpool_stride, 0, f'vertical pool{n}')\n",
    "        nodes = o * hpixels * vpixels\n",
    "        if type(linear) == int:\n",
    "            linear = [ linear ]\n",
    "        for i in linear:\n",
    "            layer = nn.Sequential( nn.Linear(nodes, i), nn.ReLU() )\n",
    "            self._add_layer( layer )\n",
    "            self.linears.append( layer )\n",
    "            nodes = i\n",
    "        \n",
    "        layer = nn.Linear(nodes, num_classes)\n",
    "        self._add_layer( layer )\n",
    "        self.linears.append( layer )\n",
    "        if final_activation is None:\n",
    "            self.final_activation = (lambda x:x) if num_classes > 1 else nn.Sigmoid()\n",
    "        else:\n",
    "            self.final_activation = final_activation\n",
    "        if post_forward is None:\n",
    "            if num_classes == 1:\n",
    "                self.post_forward = lambda y:torch.round(y)\n",
    "            else:\n",
    "                self.post_forward = lambda y:torch.argmax(y, axis=1)\n",
    "        else:\n",
    "            self.post_forward = post_forward\n",
    "\n",
    "    def _add_layer( self, layer ):\n",
    "        n = len(self.layers) + len(self.linears) + 1\n",
    "        self.__setattr__(f'layer_{n+1}', layer)\n",
    "        return n\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.preprocess is not None:\n",
    "            x = self.preprocess(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        for layer in self.linears:\n",
    "            x = layer(x)\n",
    "        return self.final_activation(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

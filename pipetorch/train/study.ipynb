{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36475a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting study.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile study.py\n",
    "import optuna\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import inspect\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "class Study(optuna.study.Study):\n",
    "    \"\"\"\n",
    "    Extension to an optuna Study. This extension caches the target functions and plot_hyperparameters\n",
    "    provides a good side-by-side overvew of the hyperparameters over the targets.\n",
    "    \n",
    "    For more information, check out Optuna Study.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, study, *target, trainer=None):\n",
    "        \"\"\"\n",
    "        Call create_study to instantiate a study\n",
    "        \"\"\"\n",
    "        super().__init__(study.study_name, study._storage, study.sampler, study.pruner)\n",
    "        assert len(target) > 0, 'You need to define at least one target'\n",
    "        for t in target:\n",
    "            assert type(t) == str, 'Only str names for targets are currently supported'\n",
    "        self.target = target\n",
    "        self.trainer = trainer\n",
    "        \n",
    "    @classmethod\n",
    "    def create_study(cls, *target, trainer=None, storage=None, sampler=None, pruner=None, study_name=None, direction=None, directions=None, load_if_exists=False):\n",
    "        \"\"\"\n",
    "        Uses optuna.create_study to create a Study. This extension registers the target metrics for inspection.\n",
    "        \n",
    "        Arguments:\n",
    "            *target: 'loss' or str or callable or Trainer\n",
    "                When called with no targets, this is set to 'loss'\n",
    "                When called with a trainer, this is set to 'loss' + all metrics that are registered by the trainer\n",
    "                Otherwise call with a sequence of callables or strings in the same order they are registered by\n",
    "                the Trainer that is used, e.g. a `Trainer(metrics='f1_score')` will have the `optimum` function return\n",
    "                `(loss, f1_score)`, therefore, register the study with `Study.create_study('loss', f1_score)`.\n",
    "                When direction is omitted, loss is set to minimize and all other directions to maximize.\n",
    "            other arguments: check optuna\n",
    "        \"\"\"\n",
    "        if len(target) == 0:\n",
    "            target = ['loss']\n",
    "        if len(target) == 1:\n",
    "            from .trainer import Trainer\n",
    "            if type(target[0]) == Trainer:\n",
    "                trainer=target[0]\n",
    "                target = ['loss'] + [ m.__name__ for m in target[0].metrics ]\n",
    "        if direction is None and directions is None:\n",
    "            if len(target) > 1:\n",
    "                directions = [ 'minimize' if t == 'loss' else 'maximize' for t in target ]\n",
    "            else:\n",
    "                direction = 'minimize' if target[0] == 'loss' else 'maximize'\n",
    "        study = optuna.create_study(storage=storage, sampler=sampler, pruner=pruner,\n",
    "                                    study_name=study_name, direction=direction, directions=directions, \n",
    "                                    load_if_exists=load_if_exists)\n",
    "        return cls(study, *target, trainer=trainer)\n",
    "    \n",
    "    def optimize(self, func, n_trials=None, timeout=None, catch=(), callbacks=None, \n",
    "                 gc_after_trial=False, show_progress_bar=False):\n",
    "        \"\"\"\n",
    "        See Optuna's optimize, this extensions adds passing the trainer to the trial function.\n",
    "        \"\"\"\n",
    "        \n",
    "        args = len(inspect.getargspec(func)[0])\n",
    "        if args == 2:\n",
    "            assert self.trainer is not None, 'You can only pass a func with two arguments when trainer is set'\n",
    "            func = partial(func, self.trainer)\n",
    "        super().optimize(func, n_trials=n_trials, timeout=timeout, catch=catch, callbacks=callbacks,\n",
    "                      gc_after_trial=gc_after_trial, show_progress_bar=show_progress_bar)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.validate())\n",
    "    \n",
    "    def filter_targets(self, results):\n",
    "        return [ results[t] for t in self.target ]\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.trials[0].params.keys()\n",
    "\n",
    "    def results(self):\n",
    "        table = []\n",
    "        for t in self.trials:\n",
    "            for param, paramv in t.params.items():\n",
    "                for target, value in zip(self.target, t.values):\n",
    "                    table.append((t.number, param, paramv, target, value))\n",
    "        return pd.DataFrame(table, columns=['trial', 'parameter', 'parametersetting', 'target', 'targetvalue'])\n",
    "\n",
    "    \n",
    "    def distribution(self, param):\n",
    "        dist = self.trials[0].distributions[param]\n",
    "        return dist\n",
    "    \n",
    "    def is_log_distribution(self, param):\n",
    "        return self.distribution(param).__class__.__name__.startswith('Log')\n",
    "    \n",
    "    def plot_hyperparameters(self, figsize=None, logscale=['loss']):\n",
    "        \"\"\"\n",
    "        Plots the sensitivity of each hyperparameter over each recorded metric.\n",
    "        \n",
    "        Arguments:\n",
    "            figsize: (width, height) None\n",
    "                controls the size of the figure displayed\n",
    "            logscale: ['loss']\n",
    "                list of metrics whose y-axis is shown as a log scale. By default this is done for the loss\n",
    "                because the learning rate is often sampled from a log distribution and this makes it easier\n",
    "                to estimate the optimum.\n",
    "        \"\"\"\n",
    "        results = self.results()\n",
    "        parameters = self.parameters()\n",
    "        if figsize is None:\n",
    "            figsize = (4 * len(parameters), 4 * len(self.target))\n",
    "        \n",
    "        fig, axs = plt.subplots(len(self.target), len(parameters), sharex='col', sharey='row', figsize=figsize)\n",
    "        \n",
    "        if len(parameters) == 1:\n",
    "            if len(self.target) == 1:\n",
    "                axs = np.array([[axs]])\n",
    "            else:\n",
    "                axs = np.expand_dims(axs, axis=1)\n",
    "        elif len(self.target) == 1:\n",
    "            axs = np.expand_dims(axs, axis=0)\n",
    "        for parami, param in enumerate(parameters):\n",
    "            for targeti, target in enumerate(self.target):\n",
    "                subset = results[(results.parameter == param) & (results.target == target)]\n",
    "                self._subplot(axs[targeti, parami], subset)\n",
    "                if targeti == 0:\n",
    "                    axs[targeti, parami].set_title(param)\n",
    "                    if self.is_log_distribution(param):\n",
    "                        axs[targeti, parami].set_xscale('log')\n",
    "                if target in logscale:\n",
    "                    axs[targeti, parami].set_yscale('log')\n",
    "                if parami == 0:\n",
    "                    axs[targeti, parami].set_ylabel(target)\n",
    "    \n",
    "    def trial_targets(self):\n",
    "        \"\"\"\n",
    "        lists to metrics over the trials.\n",
    "        \"\"\"\n",
    "        l = defaultdict(list)\n",
    "        for t in self.trials:\n",
    "            for target, value in zip(self.target, t.values):\n",
    "                l[target].append(value)\n",
    "        return pd.DataFrame.from_dict(l)        \n",
    "       \n",
    "    def validate(self):\n",
    "        \"\"\"\n",
    "        Reports the mean and variance for each metric over the trials, providing more stable outcomes using\n",
    "        n-fold cross validation.\n",
    "        \"\"\"\n",
    "        l = defaultdict(list)\n",
    "        for t in self.trials:\n",
    "            for target, value in zip(self.target, t.values):\n",
    "                l[target].append(value)\n",
    "        mean = []\n",
    "        std = []\n",
    "        for target, values in l.items():\n",
    "            mean.append(np.mean(values))\n",
    "            std.append(np.std(values))\n",
    "        return pd.DataFrame({'target':self.target, 'mean':mean, 'std':std})        \n",
    "    \n",
    "    def _subplot(self, ax, subset):\n",
    "        x = subset.parametersetting.astype(np.float64)\n",
    "        y = subset.targetvalue.astype(np.float64)\n",
    "        z = subset.trial\n",
    "        ax.scatter(x, y, c=z, cmap='plasma')\n",
    "        \n",
    "    def plot(self):\n",
    "        optuna.visualization.plot_slice(self, params=[\"hidden\"],\n",
    "                                  target_name=\"F1 Score\")\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd21f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b9407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

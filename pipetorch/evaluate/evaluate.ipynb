{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluate.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from .evaluateresults import EvaluatorResults\n",
    "from collections.abc import Iterable\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, df, *metrics):\n",
    "        self.df = df\n",
    "        self.metrics = metrics\n",
    "        self.reset()   # create a fresh set of results\n",
    "    \n",
    "    def append(self, evaluator):\n",
    "        r = copy.copy(self)\n",
    "        r.results = r.results.append(evaluator.results, sort=True, ignore_index=True)\n",
    "        return r\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.results)\n",
    "    \n",
    "    def _1d(self, y):\n",
    "        if y is None:\n",
    "            return y\n",
    "        try:\n",
    "            y = y.cpu()\n",
    "        except: pass\n",
    "        try:\n",
    "            y = y.numpy()\n",
    "        except: pass\n",
    "        try:\n",
    "            y = y.to_numpy()\n",
    "        except: pass\n",
    "        return y.reshape(-1) if len(y.shape) > 1 else y\n",
    "    \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    \n",
    "    @df.setter\n",
    "    def df(self, df):\n",
    "        self._df = df\n",
    "    \n",
    "    @property\n",
    "    def train_X(self):\n",
    "        return self.df.train_X\n",
    "\n",
    "    @property\n",
    "    def train_y(self):\n",
    "        return self.df.train_y\n",
    "\n",
    "    @property\n",
    "    def valid_X(self):\n",
    "        return self.df.valid_X\n",
    "\n",
    "    @property\n",
    "    def valid_y(self):\n",
    "        return self.df.valid_y\n",
    "\n",
    "    @property\n",
    "    def test_X(self):\n",
    "        return self.df.test_X\n",
    "\n",
    "    @property\n",
    "    def test_y(self):\n",
    "        return self.df.test_y\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.results.train\n",
    "    \n",
    "    @property\n",
    "    def valid(self):\n",
    "        return self.results.valid\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.results.test\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.results[key]\n",
    "    \n",
    "    def compute_metrics(self, true_y, pred_y):\n",
    "        pred_y = self._1d(pred_y)\n",
    "        if len(self.metrics) > 0:\n",
    "            return {m.__name__: m(true_y, pred_y) for m in self.metrics}\n",
    "        return dict()\n",
    "\n",
    "    def _dict_to_df(self, *dicts):\n",
    "        r = []\n",
    "        for d in dicts:\n",
    "            d = { key:([value] if isinstance(value, Iterable) else value) for key,value in d.items() }\n",
    "            r.append( pd.DataFrame(d, index=[0]))\n",
    "        return pd.concat(r, axis=1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.results = EvaluatorResults.from_evaluator(self)\n",
    "    \n",
    "    def optimum(self, *targets, direction=None, directions=None, validation=None, test=None, select=None):\n",
    "        \"\"\"\n",
    "        Finds the optimal value in a training trial, i.e. where the given `optimize` value over the validation\n",
    "        set is optimal. The optimize metric must be among the metrics that are cached.\n",
    "        \n",
    "        When there are multiple target metrics, ties on the first metric are resolved by the second, etc. \n",
    "        \n",
    "        Arguments:\n",
    "            *targets: str\n",
    "                one or more target metrics that are used to find the optimum\n",
    "                if empty, all recorded metrics are used in the order they were registered (usually loss first)\n",
    "            direction: str ('minimize')\n",
    "                'minimize' or 'maximize' to return the resp. lowest or highest score on the validation set\n",
    "            directions: [ str ] ('minimize')\n",
    "                for multi-target training\n",
    "            validation, test: \n",
    "                for internal use, allows recursive calls to resolve finding a multi-target optimum\n",
    "        \n",
    "        Returns:\n",
    "            { metric:value }\n",
    "            A dictionary of values obtained over the cached metrics on the validation set\n",
    "        \"\"\"\n",
    "        \n",
    "        if validation is None:\n",
    "            validation = self._select(select).valid\n",
    "        if test is None:\n",
    "            test = self._select(select).test if 'test' in self.results.phase.unique() else validation\n",
    "        if len(targets) == 0:\n",
    "            return self.optimum(*self.metrics, direction=direction, directions=directions, validation=validation, test=test)\n",
    "        if directions is None and direction is None:\n",
    "            return self.optimum(*targets, directions=[ 'minimize' if t == 'loss' else 'maximize' for t in targets ], validation=validation, test=test)\n",
    "        if direction is not None:\n",
    "            assert directions is None, 'You can only use direction or directions'\n",
    "            return self.optimum(*targets, directions=[ direction ], validation=validation, test=test)\n",
    "        for t in targets:\n",
    "            assert t in validation.metric.unique(), f'target {t} must be a cached metric'\n",
    "        m = validation[validation.metric == targets[0]]\n",
    "        if directions[0] == 'minimize':\n",
    "            optimum = m.value.min()\n",
    "        elif directions[0] == 'maximize':\n",
    "            optimum = m.value.max()\n",
    "        else:\n",
    "            assert False, 'direction must be minimize or maximize'\n",
    "        epochs = m.epoch[m.value == optimum]\n",
    "        test = test[test.epoch.isin(epochs)]\n",
    "        if len(epochs) > 1 and len(targets) > 1:\n",
    "            validation = validation[validation.epoch.isin(epochs)]\n",
    "            return self.optimum( *target[1:], directions=directions[1:], validation=validation, test=test)\n",
    "        elif len(epochs) > 1:\n",
    "            test = test.loc[test.epoch == epochs[0]]\n",
    "        return {t:test.value[test.metric == t].item() for t in targets }\n",
    "    \n",
    "    def train_valid_sklearn(self, df):\n",
    "            model.fit(df.train_X, df.train_y)\n",
    "            valid_pred = df.valid._predict(predict)\n",
    "            valid_y = df._inverse_transform_y( df.valid_y )\n",
    "            valid_pred = df._inverse_transform_y( valid_pred )\n",
    "            metrics = self.compute_metrics(valid_y, valid_pred)\n",
    "            for k, v in metrics.items():\n",
    "                results_valid[k] += v * len(df.valid_X) / len(df)\n",
    "            train_pred = dfk.train._predict(predict)\n",
    "            y = dfk._inverse_transform_y( y )\n",
    "            y_pred = dfk._inverse_transform_y( y_pred )\n",
    "            metrics = self.compute_metrics(y, y_pred)\n",
    "            for k, v in metrics.items():\n",
    "                results_train[k] += v  * len(dfk.train_X) / len(df)\n",
    "    \n",
    "    def run(self, train, predict, model=None, df=None, n_splits=1, stratify=None, **annot):\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "        if n_splits == 1:\n",
    "            train(df.train_X, df.train_y)\n",
    "            self.score_train(predict, df=df, **annot)\n",
    "            self.score_valid(predict, df=df, **annot)\n",
    "        else:\n",
    "            results_train = defaultdict(lambda:0)\n",
    "            results_valid = defaultdict(lambda:0)\n",
    "            for dfk in df.kfold(n_splits=n_splits, stratify=stratify):\n",
    "                train(dfk.train_X, dfk.train_y)\n",
    "                y_pred = dfk.valid._predict(predict)\n",
    "                y = dfk._inverse_transform_y( y )\n",
    "                y_pred = dfk._inverse_transform_y( y_pred )\n",
    "                metrics = self.compute_metrics(y, y_pred)\n",
    "                for k, v in metrics.items():\n",
    "                    results_valid[k] += v * len(dfk.valid_X) / len(df)\n",
    "                y_pred = dfk.train._predict(predict)\n",
    "                y = dfk._inverse_transform_y( y )\n",
    "                y_pred = dfk._inverse_transform_y( y_pred )\n",
    "                metrics = self.compute_metrics(y, y_pred)\n",
    "                for k, v in metrics.items():\n",
    "                    results_train[k] += v  * len(dfk.train_X) / len(df)\n",
    "            results_train['phase'] = 'train'\n",
    "            results_valid['phase'] = 'valid'\n",
    "            self.results = self.results._add(self._dict_to_df(train_results, annot))\n",
    "            self.results = self.results._add(self._dict_to_df(valid_results, annot))\n",
    "            \n",
    "    def run_sklearn(self, model, df=None, **annot):\n",
    "            \n",
    "        self.run(model.fit, model.predict, model=model, df=df, **annot)\n",
    "\n",
    "    def _inverse_transform_y(self, df, y):\n",
    "        if callable(getattr(df, \"inverse_transform_y\", None)):\n",
    "            return df.inverse_transform_y( y )\n",
    "        return y\n",
    "        \n",
    "    def _store_predict(self, predict, df, **annot):\n",
    "        y_pred = df._predict(predict)\n",
    "        self._store_metrics(df.y, y_pred, df=df, **annot)        \n",
    "        \n",
    "    def _store_metrics(self, y, y_pred, df=None, **annot):\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "        y = self._inverse_transform_y( df, y )\n",
    "        y_pred = self._inverse_transform_y( df, y_pred )\n",
    "        metrics = self.compute_metrics(y, y_pred)\n",
    "        for m, value in metrics.items():\n",
    "            self._store_metric(m, value, **annot)\n",
    "        return metrics\n",
    "\n",
    "    def _store_metric(self, metric, value, **annot):\n",
    "        self.results = self.results._add(self._dict_to_df({'metric':metric, 'value': value}, annot))\n",
    "            \n",
    "    def score_train(self, predict, df=None, **annot):\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "        self._store_predict(predict, df.train, phase='train', **annot)\n",
    "            \n",
    "    def score_valid(self, predict, df=None, **annot):\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "        if len(df.valid_X) > 0:\n",
    "            self._store_predict(predict, df.valid, phase='valid', **annot)\n",
    "\n",
    "    def score_test(self, predict, df=None, **annot):\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "        if len(df.test_X) > 0:\n",
    "            self._store_predict(predict, df.test, phase='test', **annot)\n",
    "                \n",
    "    def _order(self, X):\n",
    "        return X[:, 0].argsort(axis=0)\n",
    "\n",
    "    def scatter2d_class(self, x1=None, x2=None, y=None, xlabel=None, ylabel=None, title=None, loc='best', noise=0, df=None, **kwargs):\n",
    "        f = _figure2d(self, x1=x1, x2=x2, y=y, xlabel=xlabel, ylabel=ylabel, title=title, df=df, noise=noise)\n",
    "        for c in sorted(np.unique(f.graph_y)):\n",
    "            indices = (c == f.graph_y)\n",
    "            plt.scatter(f.graph_x1[indices], f.graph_x2[indices], label=int(c), **kwargs)\n",
    "        plt.gca().legend(loc=loc)\n",
    "\n",
    "    def scatter2d_color(self, x1=None, x2=None, c=None, xlabel=None, ylabel=None, title=None, noise=0, df=None, cmap=plt.get_cmap(\"jet\"), s=1, **kwargs):\n",
    "        f = _figure2d(self, x1=x1, x2=x2, y=c, xlabel=xlabel, ylabel=ylabel, title=title, df=df, noise=noise)\n",
    "        plt.scatter(f.graph_x1, f.graph_x2, c=f.graph_y, cmap=cmap, s=s, **kwargs)\n",
    "        plt.colorbar()\n",
    "        \n",
    "    def scatter2d_size(self, x1=None, x2=None, s=None, xlabel=None, ylabel=None, title=None, noise=0, df=None, **kwargs):\n",
    "        f = _figure2d(self, x1=x1, x2=x2, y=s, xlabel=xlabel, ylabel=ylabel, title=title, df=df, noise=noise)\n",
    "        plt.scatter(f.graph_x1, f.graph_x2, s=f.graph_y, **kwargs)\n",
    "        \n",
    "    def _boundaries(self, predict):\n",
    "        ax = plt.gca()\n",
    "        x_min, x_max = ax.get_xlim()\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        stepx = (x_max - x_min) / 600\n",
    "        stepy = (y_max - y_min) / 600\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, stepx),\n",
    "                             np.arange(y_min, y_max, stepy))\n",
    "        X = np.array(np.vstack([xx.ravel(), yy.ravel()])).T\n",
    "        dataset = self.df.from_numpy(X)\n",
    "        boundaries = dataset._predict(predict).to_numpy()\n",
    "        boundaries.resize(xx.shape)\n",
    "        return ax, xx, yy, boundaries\n",
    "    \n",
    "    def plot_boundary(self, predict, levels=[0.5]):\n",
    "        ax, xx, yy, boundary = self._boundaries(predict)\n",
    "        ax.contour(xx, yy, boundary, levels=levels)  \n",
    "        \n",
    "    def _coef(self, coefs, subset, model):\n",
    "        try:\n",
    "            model.fit(self.df.train_X[subset], self.df.train_y[subset])\n",
    "            coefs.append( (model.intercept_, self.get_coef(model.coef_ ) ) )\n",
    "        except:pass\n",
    "    \n",
    "    def _loss_minmax(self, model, loss):\n",
    "        model.fit(self.df.train_X, self.df.train_y)\n",
    "        min0 = model.intercept_\n",
    "        min1 = self.get_coef(model.coef_ )\n",
    "        m = np.argsort(self.df.train_X[:, 0])\n",
    "        n = len(m)//2\n",
    "        coefs = []\n",
    "        self._coef(coefs, m[:n], model)\n",
    "        self._coef(coefs, m[n:], model)\n",
    "        m = np.argsort(self.df.train_y)\n",
    "        self._coef(coefs, m[:n], model)\n",
    "        self._coef(coefs, m[n:], model)\n",
    "        model.fit(self.df.train_X, self.df.train_y)\n",
    "        max0 = max([ a for a, _ in coefs ])\n",
    "        max1 = max([ b for _, b in coefs ])\n",
    "        l = self._loss_coef_intercept(model, loss, min0, min1)\n",
    "        loss0 = self._loss_coef_intercept(model, loss, max0, min1)\n",
    "        loss1 = self._loss_coef_intercept(model, loss, min0, max1)\n",
    "        if (loss0 - l) < (loss1 - l)/ 2:\n",
    "            while (loss0 - l) < (loss1 - l)/ 2:\n",
    "                max0 *= 2\n",
    "                loss0 = self._loss_coef_intercept(model, loss, max0, min1)\n",
    "        elif (loss1 - l) < (loss0 - l) / 2:\n",
    "            while (loss1 - l) < (loss0 - l) / 2:\n",
    "                max1 *= 2\n",
    "                loss1 = self._loss_coef_intercept(model, loss, min0, max1)\n",
    "        min0 = min0 - (max0 - min0)\n",
    "        min1 = min1 - (max1 - min1)\n",
    "        return min0, max0, min1, max1\n",
    "\n",
    "    def _loss_coef_intercept(self, model, loss, intercept, coef):\n",
    "        self.set_coef( model.coef_, coef )\n",
    "        model.intercept_ = intercept\n",
    "        pred_y = model.predict(self.df.train_X)\n",
    "        return loss(self.df.train_y, pred_y)\n",
    "\n",
    "    def get_coef(self, coef):\n",
    "        if len(coef.shape) > 1:\n",
    "            return self.get_coef(coef[0])\n",
    "        return coef[0]\n",
    "    \n",
    "    def set_coef(self, coef, value):\n",
    "        if len(coef.shape) > 1:\n",
    "            self.set_coef(coef[0], value)\n",
    "        coef[0] = value\n",
    "    \n",
    "    def loss_surface(self, model, loss, linewidth=1, antialiased=False, cmap=cm.coolwarm, intersects=50, **kwargs):\n",
    "        model = copy.copy(model)\n",
    "        min0, max0, min1, max1 = self._loss_minmax(model, loss)\n",
    "        step0 = np.abs(max0 - min0) / intersects\n",
    "        step1 = np.abs(max1 - min1) / intersects\n",
    "        xx, yy = np.meshgrid(np.arange(min0, max0, step0),\n",
    "                             np.arange(min1, max1, step1))\n",
    "        X = np.array(np.vstack([xx.ravel(), yy.ravel()])).T\n",
    "        l = np.array([ self._loss_coef_intercept(model, loss, intercept, coef) for intercept, coef in X ])\n",
    "        l = l.reshape(xx.shape)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(xx, yy, l, cmap=cmap, linewidth=linewidth, antialiased=antialiased)\n",
    "        plt.xlabel(r'$\\theta_0$')\n",
    "        plt.ylabel(r'$\\theta_1$')\n",
    "        plt.show()\n",
    "        \n",
    "    def _figure(self, x=None, y=None, xlabel = None, ylabel = None, sort=False, title=None, interpolate=0, df=None, fig=plt):\n",
    "        return _figure(self, x=x, y=y, xlabel=xlabel, ylabel=ylabel, title=title, sort=sort, interpolate=interpolate, df=df, fig=fig)\n",
    "    \n",
    "    def _plot(self, pltfunction, x=None, y=None, xlabel = None, ylabel = None, sort=False, title=None, marker=None, interpolate=0, df=None, loc='best', fig=plt, **kwargs):\n",
    "        #fig = plt.figure()\n",
    "        f = _figure(self, x=x, y=y, xlabel=xlabel, ylabel=ylabel, title=title, sort=sort, interpolate=interpolate, df=df, fig=fig)\n",
    "        pltfunction(f.graph_x, f.graph_y, marker=marker, **kwargs)\n",
    "        if 'label' in kwargs:\n",
    "            fig.gca().legend(loc=loc)\n",
    "        #fig.show()\n",
    "    \n",
    "    def line(self, x=None, y=None, xlabel = None, ylabel = None, title=None, interpolate=0, df=None, loc='best', fig=plt, **kwargs):\n",
    "        plot = fig.plot if fig else plt.plot\n",
    "        self._plot(plot, x=x, y=y, xlabel=xlabel, ylabel=ylabel, title=title, interpolate=interpolate, sort=True, df=df, loc=loc, fig=fig, **kwargs)\n",
    "\n",
    "    def scatter(self, x=None, y=None, xlabel = None, ylabel = None, title=None, interpolate=0, df=None, loc='best', fig=plt, **kwargs):\n",
    "        plot = fig.scatter if fig else plt.scatter\n",
    "        self._plot(plot, x=x, y=y, xlabel=xlabel, ylabel=ylabel, title=title, interpolate=interpolate, df=df, loc=loc, fig=fig, **kwargs)\n",
    "       \n",
    "    def _select(self, select):\n",
    "        if select is None:\n",
    "            s = self.results\n",
    "        elif type(select) is pd.core.series.Series:\n",
    "            s = self.results[select]\n",
    "        elif type(select) is EvaluatorResults:\n",
    "            s = select\n",
    "        elif type(select) is str:\n",
    "            s = self.results[self.results.phase == select]\n",
    "        elif type(select) == dict:\n",
    "            s = self.results\n",
    "            for key, value in select.items():\n",
    "                s = s.loc[s[key] == value].copy()\n",
    "        else:\n",
    "            raise ValueError('Unknown type passed for select')\n",
    "        return s\n",
    "\n",
    "    def _groups(self, selection, series='phase'):\n",
    "        for g, d in selection.groupby(by=series):\n",
    "            yield g, self.results._copy_meta(d)\n",
    "    \n",
    "    def scatter_metric(self, x, y=None, series='phase', select=None, xlabel = None, ylabel = None, title=None, label_prefix='', label=None, fig=None, **kwargs):\n",
    "        y = y or self.metrics[0].__name__\n",
    "        selection = self._select(select)\n",
    "        selection = selection[selection.metric == y]\n",
    "        ylabel = ylabel or y\n",
    "        unique_groups = self._unique(selection, series)\n",
    "        for g, d in self._groups(selection, series=series):\n",
    "            g = label or (label_prefix + str(g) if unique_groups > 1 else ylabel)\n",
    "            d.scatter(x, y='value', xlabel=xlabel, ylabel=y, title=title, label=g, fig=fig, **kwargs)\n",
    "    \n",
    "    def line_metric(self, x, y=None, series='phase', select=None, xlabel = None, ylabel = None, title=None, label_prefix='', label=None, fig=None, **kwargs):\n",
    "        y = y or self.metrics[0].__name__\n",
    "        selection = self._select(select)\n",
    "        selection = selection[selection.metric == y]\n",
    "        ylabel = ylabel or y\n",
    "        unique_groups = len([ a for a in self._groups(selection, series=series) ])\n",
    "        for g, d in self._groups(selection, series=series):\n",
    "            g = label or (label_prefix + str(g) if unique_groups > 1 else ylabel)\n",
    "            d.line(x, y='value', xlabel=xlabel, ylabel=ylabel, title=title, label=g, fig=fig, **kwargs)\n",
    "        \n",
    "class _figures:\n",
    "    def _graph_coords_callable(self, df, f):\n",
    "        if callable(f):\n",
    "            return self.evaluator.df.inverse_transform_y( f(df.X) ).to_numpy()\n",
    "        elif type(f) == str:\n",
    "            return np.squeeze(df[[f]].to_numpy())\n",
    "        return f\n",
    "    \n",
    "    def _graph_coords(self, df, *fields):\n",
    "        return  [ self._graph_coords_callable(df, f) for f in fields ]         \n",
    "        \n",
    "class _figure(_figures):\n",
    "    def __init__(self, evaluator, x=None, y=None, xlabel = None, ylabel = None, title = None, sort=False, interpolate=0, phase='train', df=None, fig=plt ):\n",
    "        self.evaluator = evaluator\n",
    "        self.df = copy.copy(df if df is not None else evaluator.df.train)\n",
    "        self.x = x\n",
    "        self.xlabel = xlabel or self.x\n",
    "        if interpolate > 0:\n",
    "            assert (y is None) or (type(y)==str) or callable(y), 'You cannot interpolate with given results'\n",
    "            self.df = self.df.interpolate_factor(interpolate)\n",
    "        elif sort:\n",
    "            self.df = self.df.sort_values(by=self.x)\n",
    "        self.y = y\n",
    "        self.ylabel = ylabel or self.y\n",
    "        self.fig = fig\n",
    "        if title is not None:\n",
    "            try:\n",
    "                fig.title(title)\n",
    "            except:\n",
    "                fig.suptitle(title)\n",
    "        try:\n",
    "            fig.ylabel(self.ylabel)\n",
    "        except:\n",
    "            fig.set_ylabel(self.ylabel)\n",
    "        try:\n",
    "            fig.xlabel(self.xlabel)\n",
    "        except:\n",
    "            fig.set_xlabel(self.xlabel)\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._x\n",
    "    \n",
    "    @x.setter\n",
    "    def x(self, value):\n",
    "        if value is None:\n",
    "            self._x = self.df._columnx[0]\n",
    "        elif value is int:\n",
    "            self._x = self.df._columnx[value]\n",
    "        elif type(value) == str:\n",
    "            self._x = value\n",
    "        else:\n",
    "            self._x = self.df._columnx[0]\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "    \n",
    "    @y.setter\n",
    "    def y(self, value):\n",
    "        if value is None:\n",
    "            self._y = self.df._columny[0]\n",
    "        elif str(value) is int:\n",
    "            self._y = self.df._columny[value]\n",
    "        elif type(value) == str:\n",
    "            self._y = value\n",
    "        else:\n",
    "            self._y = self.df._columny[0]\n",
    "            self.df = self.df.replace_y(value)\n",
    "\n",
    "    @property\n",
    "    def xlabel(self):\n",
    "        return self._xlabel\n",
    "    \n",
    "    @xlabel.setter\n",
    "    def xlabel(self, value):\n",
    "        self._xlabel = value\n",
    "\n",
    "    @property\n",
    "    def ylabel(self):\n",
    "        return self._ylabel\n",
    "    \n",
    "    @ylabel.setter\n",
    "    def ylabel(self, value):\n",
    "        self._ylabel = value\n",
    "\n",
    "    @property\n",
    "    def graph_x(self):\n",
    "        return self._graph_coords_callable(self.df, self.x)\n",
    "\n",
    "    @property\n",
    "    def graph_y(self):\n",
    "        return self._graph_coords_callable(self.df, self.y)\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.df.X\n",
    "\n",
    "class _figure2d(_figures):\n",
    "    def __init__(self, evaluator, x1=None, x2=None, y=None, xlabel = None, ylabel = None, title = None, df=None, noise=0, fig=plt ):\n",
    "        self.evaluator = evaluator\n",
    "        self.df = copy.copy(df if df is not None else evaluator.df.train)\n",
    "        self.noise = noise\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.y = y\n",
    "        self.xlabel = xlabel\n",
    "        self.ylabel = ylabel\n",
    "        self.fig = fig\n",
    "        if title is not None:\n",
    "            try:\n",
    "                fig.title(title)\n",
    "            except:\n",
    "                fig.suptitle(title)\n",
    "        try:\n",
    "            fig.ylabel(self.ylabel)\n",
    "        except:\n",
    "            fig.set_ylabel(self.ylabel)\n",
    "        try:\n",
    "            fig.xlabel(self.xlabel)\n",
    "        except:\n",
    "            fig.set_xlabel(self.xlabel)\n",
    "\n",
    "    @property\n",
    "    def x1(self):\n",
    "        return self._x1\n",
    "    \n",
    "    @x1.setter\n",
    "    def x1(self, value):\n",
    "        if value is None:\n",
    "            self._x1 = self.df[self.df._columnx[0]]\n",
    "            self._xlabel = self.df._columnx[0]\n",
    "        elif value is int:\n",
    "            self._x1 = self.df[self.df._columnx[value]]\n",
    "            self._xlabel = self.df._columnx[value]\n",
    "        elif type(value) == str:\n",
    "            self._x1 = self.df[value]\n",
    "            self._xlabel = value\n",
    "        else:\n",
    "            self._x1 = value\n",
    "            self._xlabel = self.df._columnx[0]\n",
    "\n",
    "    @property\n",
    "    def x2(self):\n",
    "        return self._x2\n",
    "    \n",
    "    @x2.setter\n",
    "    def x2(self, value):\n",
    "        if value is None:\n",
    "            self._x2 = self.df[self.df._columnx[1]]\n",
    "            self._ylabel = self.df._columnx[1]\n",
    "        elif value is int:\n",
    "            self._x2 = self.df[self.df._columnx[value]]\n",
    "            self._ylabel = self.df._columnx[value]\n",
    "        elif type(value) == str:\n",
    "            self._x2 = self.df[value]\n",
    "            self._ylabel = value\n",
    "        else:\n",
    "            self._x2 = value\n",
    "            self._ylabel = self.df._columnx[1]\n",
    "        \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "    \n",
    "    @y.setter\n",
    "    def y(self, value):\n",
    "        if value is None:\n",
    "            self._y = self.df._columny[0]\n",
    "        elif str(value) is int:\n",
    "            self._y = self.df._columny[value]\n",
    "        elif type(value) == str:\n",
    "            self._y = value\n",
    "        else:\n",
    "            self._y = self.df._columny[0]\n",
    "            self.df = self.df.replace_y(value)\n",
    "        \n",
    "    @property\n",
    "    def xlabel(self):\n",
    "        return self._xlabel\n",
    "    \n",
    "    @xlabel.setter\n",
    "    def xlabel(self, value):\n",
    "        if value is not None:\n",
    "            self._xlabel = value\n",
    "\n",
    "    @property\n",
    "    def ylabel(self):\n",
    "        return self._ylabel\n",
    "    \n",
    "    @ylabel.setter\n",
    "    def ylabel(self, value):\n",
    "        if value is not None:\n",
    "            self._ylabel = value\n",
    "\n",
    "    @property\n",
    "    def graph_x1_noiseless(self):\n",
    "        return self._graph_coords_callable(self.df, self.x1)\n",
    "\n",
    "    @property\n",
    "    def graph_x2_noiseless(self):\n",
    "        return self._graph_coords_callable(self.df, self.x2)\n",
    "\n",
    "    @property\n",
    "    def graph_y(self):\n",
    "        return self._graph_coords_callable(self.df, self.y)\n",
    "\n",
    "    @property\n",
    "    def graph_x1(self):\n",
    "        try:\n",
    "            return self._graph_x1\n",
    "        except:\n",
    "            self._graph_x1 = self.graph_x1_noiseless\n",
    "            if self.noise > 0:\n",
    "                # should we flatten??\n",
    "                sd = np.std(self._graph_x1)\n",
    "                self._graph_x1 = self._graph_x1 + np.random.normal(0, self.noise * sd, self._graph_x1.shape)\n",
    "            return self._graph_x1\n",
    "\n",
    "    @property\n",
    "    def graph_x2(self):\n",
    "        try:\n",
    "            return self._graph_x2\n",
    "        except:\n",
    "            self._graph_x2 = self.graph_x2_noiseless\n",
    "            if self.noise > 0:\n",
    "                sd = np.std(self._graph_x2)\n",
    "                self._graph_x2 = self._graph_x2 + np.random.normal(0, self.noise * sd, self._graph_x2.shape)\n",
    "            return self._graph_x2\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.df.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

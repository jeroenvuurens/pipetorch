{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e4c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting datasets.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile datasets.py\n",
    "\n",
    "from .imagedframe import ImageDatabunch\n",
    "from ..data.datasets import path_user, path_shared, dataset_path, kaggle_download, kaggle_download_competition\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from pathlib import Path\n",
    "from getpass import getuser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import io\n",
    "from PIL import Image, ImageStat\n",
    "\n",
    "def create_path(p, mode=0o777):\n",
    "    path = Path(p)\n",
    "    os.makedirs(path, mode, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def image_folder():\n",
    "    return f'/tmp/{getuser()}/images'\n",
    "\n",
    "def FastCIFAR(root=None, train=False, transform=None, size=None, normalize=True, download=False, **kwargs):\n",
    "    \"\"\"\n",
    "    A Dataset for Cifar10, that caches the dataset on gpu for faster processing. \n",
    "    The images dataset are shaped (3,32,32).\n",
    "    \n",
    "    Arguments:\n",
    "        root: str (None)\n",
    "            local path where the dataset is stored. If None, first ~/.pipetorchuser is checked, then\n",
    "            ~/.pipetorch (for shared datasets).\n",
    "        \n",
    "        test: bool (True)\n",
    "            whether the train or test set is retrieved\n",
    "            \n",
    "        transform: callable (None)\n",
    "            an optional function to perform additional transformations on the data\n",
    "            not that the images are already tensors\n",
    "            \n",
    "        device: torch.device (None)\n",
    "            the device to cache the dataset on\n",
    "            \n",
    "        size: int (None)\n",
    "            the required width/height of the image in pixels\n",
    "        normalize: bool (True)\n",
    "            Whether or not to normalize the images, which you normally should do, \n",
    "            but when you wish to inspect some of the images, you can turn it off.\n",
    "            \n",
    "        **kwargs: dict\n",
    "            passed to torchvision's CIFAR10\n",
    "    \"\"\"\n",
    "    if root is None:\n",
    "        try:\n",
    "            return _FastCIFAR(root='~/.pipetorchuser', download=False, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "        except: pass\n",
    "        try:\n",
    "            return _FastCIFAR(root='~/.pipetorch', download=False, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "        except: pass\n",
    "        root = '~/.pipetorchuser'\n",
    "    return _FastCIFAR(root=root, download=download, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "\n",
    "class _FastCIFAR(CIFAR10):\n",
    "    def __init__(self, root=None, train=True, transform=None, size=None, normalize=True, **kwargs):\n",
    "        super().__init__(root=root, train=train, **kwargs)\n",
    "        self.transform=transform\n",
    "        # Scale data to [0,1]\n",
    "        self.data = torch.tensor(self.data).float().div(255)\n",
    "        self.data = self.data.permute(0, 3, 1, 2)\n",
    "        if size is not None:\n",
    "            self.data = F.interpolate(self.data, (3, size, size))\n",
    "        # Normalize it with the usual MNIST mean and std\n",
    "        if normalize:\n",
    "            self.data[:,0] = self.data[:,0].sub_(0.4057).div_(0.2039)\n",
    "            self.data[:,1] = self.data[:,1].sub_(0.5112).div_(0.2372)\n",
    "            self.data[:,2] = self.data[:,2].sub_(0.5245).div_(0.3238)\n",
    "        self.targets = torch.tensor(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target  \n",
    "\n",
    "def FastMNIST(root=None, train=True, transform=None, size=None, normalize=True, download=False, **kwargs):\n",
    "    \"\"\"\n",
    "    A Dataset for MNIST, that caches the dataset on gpu for faster processing. \n",
    "    The images dataset are shaped (3,32,32).\n",
    "    \n",
    "    Arguments:\n",
    "        root: str (None)\n",
    "            local path where the dataset is stored. If None, first ~/.pipetorchuser is checked, then\n",
    "            ~/.pipetorch (for shared datasets).\n",
    "        \n",
    "        train: bool (True)\n",
    "            whether the train or test set is retrieved\n",
    "            \n",
    "        transform: callable (None)\n",
    "            an optional function to perform additional transformations on the data\n",
    "            not that the images are already tensors\n",
    "            \n",
    "        size: int (None)\n",
    "            the required width/height of the image in pixels\n",
    "        normalize: bool (True)\n",
    "            Whether or not to normalize the images, which you normally should do, \n",
    "            but when you wish to inspect some of the images, you can turn it off.\n",
    "            \n",
    "        **kwargs: dict\n",
    "            passed to torchvision's CIFAR10\n",
    "    \"\"\"\n",
    "    if root is None:\n",
    "        try:\n",
    "            return _FastMNIST(root='~/.pipetorchuser', download=False, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "        except: pass\n",
    "        try:\n",
    "            return _FastMNIST(root='~/.pipetorch', download=False, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "        except: pass\n",
    "        root = '~/.pipetorchuser'\n",
    "    return _FastMNIST(root=root, download=download, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "                 \n",
    "class _FastMNIST(MNIST):\n",
    "    def __init__(self, root, train=True, transform=None, size=None, normalize=True, **kwargs):\n",
    "        super().__init__(root=root, train=train, **kwargs)\n",
    "        self.transform=transform\n",
    "        # Scale data to [0,1]\n",
    "        self.data = self.data.unsqueeze(1).float().div(255)\n",
    "        if size is not None:\n",
    "            self.data = F.interpolate(self.data, (size, size))\n",
    "        if normalize:\n",
    "            # Normalize it with the usual MNIST mean and std\n",
    "            self.data = self.data.sub_(0.1307).div_(0.3081)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print(index, len(self.data), len(self.targets))\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "def FastMNIST3(root=None, train=True, transform=None, size=None, normalize=True, download=False, **kwargs):\n",
    "    \"\"\"\n",
    "    A Dataset for MNIST, that caches the dataset on gpu for faster processing. \n",
    "    The images dataset are shaped (3,32,32).\n",
    "    \n",
    "    Arguments:\n",
    "        root: str (None)\n",
    "            local path where the dataset is stored. If None, first ~/.pipetorchuser is checked, then\n",
    "            ~/.pipetorch (for shared datasets).\n",
    "        \n",
    "        train: bool (True)\n",
    "            whether the train or test set is retrieved\n",
    "            \n",
    "        transform: callable (None)\n",
    "            an optional function to perform additional transformations on the data\n",
    "            not that the images are already tensors\n",
    "            \n",
    "        size: int (None)\n",
    "            the required width/height of the image in pixels\n",
    "        normalize: bool (True)\n",
    "            Whether or not to normalize the images, which you normally should do, \n",
    "            but when you wish to inspect some of the images, you can turn it off.\n",
    "            \n",
    "        **kwargs: dict\n",
    "            passed to torchvision's CIFAR10\n",
    "    \"\"\"\n",
    "    if root is None:\n",
    "        try:\n",
    "            return _FastMNIST3(root='~/.pipetorchuser', download=False, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "        except: pass\n",
    "        try:\n",
    "            return _FastMNIST3(root='~/.pipetorch', download=False, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "        except: pass\n",
    "        root = '~/.pipetorchuser'\n",
    "    return _FastMNIST3(root=root, download=download, train=train, transform=transform, \n",
    "                             normalize=normalize, **kwargs)\n",
    "\n",
    "class _FastMNIST3(_FastMNIST):\n",
    "    \"\"\"\n",
    "    A Dataset for MNist, that provides RGB images (3 channels) \n",
    "    and caches the dataset on a device (gpu) for faster processing.\n",
    "    The resizing is delayed to the getitem, to allow large images without requiring too much memory\n",
    "    \n",
    "    see FastMNist\n",
    "    \"\"\"\n",
    "    def __init__(self, root, train=True, transform=None, \n",
    "                       size=None, normalize=True, **kwargs):\n",
    "        super().__init__(root, train=train, transform=transform, normalize=normalize, **kwargs)\n",
    "        self.size = size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        if self.size is not None:\n",
    "            img = F.interpolate(img.unsqueeze(0), (self.size, self.size)).squeeze(0)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        img = torch.cat([img, img, img], axis=0)\n",
    "        return img, target\n",
    "    \n",
    "def mnist(root=None, test=False, valid_perc=0.1, batch_size=64, transform=None, size=None, \n",
    "          normalize=True, num_workers=2, **kwargs):\n",
    "    '''\n",
    "    An image_databunch of the mnist dataset in greyscale (shape is (1,28,28).\n",
    "    \n",
    "    Arguments:\n",
    "        test: bool (False)\n",
    "            if True, the test set is also included in the Databunch\n",
    "            \n",
    "        valid_perc: float (0.1)\n",
    "            the size of the train set that is used for validation\n",
    "    \n",
    "        root=None, transform=None, size=None, normalize=True, **kwargs\n",
    "            see FastMNIST for documentation\n",
    "\n",
    "        batch_size=64, num_workers=2\n",
    "            see ImageDatabunch for documentation\n",
    "        \n",
    "    Returns: ImageDatabunch\n",
    "        An extension to a Databunch that provides additional support for images, like image normalization,\n",
    "        transformation and show_batch to show an example.    \n",
    "    '''\n",
    "    train_ds = FastMNIST(root, transform=transform, train=True, size=size, normalize=normalize, **kwargs)\n",
    "    if test:\n",
    "        test_ds = FastMNIST(root, transform=transform, train=False, size=size, normalize=normalize, **kwargs)\n",
    "    else:\n",
    "        test_ds = None\n",
    "    return ImageDatabunch.from_train_test_ds(train_ds, test_ds, \n",
    "                                             valid_perc=valid_perc, batch_size=batch_size, \n",
    "                                             num_workers=num_workers)\n",
    "\n",
    "def mnist3(root=None, test=False, batch_size=64, valid_perc=0.1, size=None, transform=None, \n",
    "           normalize=True, num_workers=2, **kwargs):\n",
    "    '''\n",
    "    An image_databunch of the mnist dataset in RGB (shape is (3,28,28).\n",
    "    \n",
    "    Arguments:\n",
    "        test: bool (False)\n",
    "            if True, the test set is also included in the Databunch\n",
    "            \n",
    "        valid_perc: float (0.1)\n",
    "            the size of the train set that is used for validation\n",
    "    \n",
    "        root=None, transform=None, size=None, normalize=True, **kwargs\n",
    "            see FastMNIST for documentation\n",
    "\n",
    "        batch_size=64, num_workers=2\n",
    "            see ImageDatabunch for documentation\n",
    "\n",
    "    Returns: ImageDatabunch\n",
    "        An extension to a Databunch that provides additional support for images, like image normalization,\n",
    "        transformation and show_batch to show an example.    \n",
    "    '''\n",
    "    train_ds = FastMNIST3(root, transform=transform, train=True, size=size, normalize=normalize, **kwargs)\n",
    "    if test:\n",
    "        test_ds = FastMNIST3(root, transform=transform, train=False, size=size, normalize=normalize, **kwargs)\n",
    "    else:\n",
    "        test_ds = None\n",
    "    return ImageDatabunch.from_train_test_ds(train_ds, test_ds, \n",
    "                                             valid_perc=valid_perc, batch_size=batch_size, \n",
    "                                             num_workers=num_workers)\n",
    "\n",
    "def cifar(root=None, batch_size=64, test=False, valid_perc=0.1, size=None, transform=None, \n",
    "          normalize=True, num_workers=2, **kwargs):\n",
    "    '''\n",
    "    An image_databunch of the CIFAR10 dataset in RGB (shape is (3,32,32).\n",
    "    \n",
    "    Arguments:\n",
    "        test: bool (False)\n",
    "            if True, the test set is also included in the Databunch\n",
    "            \n",
    "        valid_perc: float (0.1)\n",
    "            the size of the train set that is used for validation\n",
    "    \n",
    "        root=None, transform=None, size=None, normalize=True, **kwargs\n",
    "            see FastMNIST for documentation\n",
    "\n",
    "        batch_size=64, num_workers=2\n",
    "            see ImageDatabunch for documentation\n",
    "            \n",
    "    Returns: ImageDatabunch\n",
    "        An extension to a Databunch that provides additional support for images, like image normalization,\n",
    "        transformation and show_batch to show an example.    \n",
    "    '''\n",
    "    train_ds = FastCIFAR(root, transform=transform, train=True, size=size, normalize=normalize, **kwargs)\n",
    "    if test:\n",
    "        test_ds = FastCIFAR(root, transform=transform, train=False, size=size, normalize=normalize, **kwargs)\n",
    "    else:\n",
    "        test_ds = None\n",
    "    return ImageDatabunch.from_train_test_ds(train_ds, test_ds, \n",
    "                                             valid_perc=valid_perc, batch_size=batch_size, \n",
    "                                             num_workers=num_workers)\n",
    "\n",
    "def _gis_args(keywords, output_directory=None, \n",
    "                 image_directory=None, limit=200, format='jpg', color_type='full-color', \n",
    "                 size='medium', type='photo', delay=0, **kwargs):\n",
    "    \"\"\"\n",
    "    helper function for crawl_images, which uses google image search\n",
    "    \"\"\"\n",
    "    if output_directory is None:\n",
    "        output_directory = str(create_path(image_folder()))\n",
    "    if image_directory is None:\n",
    "        image_directory = '_'.join(keywords.split())\n",
    "    arguments = {\"keywords\":keywords, \n",
    "                 \"limit\":limit, \"format\":format, \"color_type\":color_type, \"size\":size, \"type\":type, \n",
    "                 \"delay\":delay, \"image_directory\":image_directory, \n",
    "                 \"output_directory\":output_directory, \"chromedriver\":\"/usr/bin/chromedriver\" }\n",
    "    arguments.update(kwargs)\n",
    "    return arguments\n",
    "\n",
    "def crawl_images(keywords, output_directory=None, \n",
    "                 image_directory=None, limit=200, format='jpg', color_type='full-color', \n",
    "                 size='medium', type='photo', delay=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Downloads images through Google Image Search, \n",
    "    see https://google-images-download.readthedocs.io/en/latest/arguments.html \n",
    "    for info on the arguments.\n",
    "    The supporting library frequently breaks, so do not expect this to work.\n",
    "    \n",
    "    Arguments:\n",
    "        keywords: the keywords passed to google image search to retrieve images\n",
    "        limit: maximum number of images to retrieve (default=200). You will actually receive less iamges because many links will not work\n",
    "        output_directory: base folder for the downloads (default: /tmp/username/images/)\n",
    "        image_directory: subpath to store the images for this query (by default uses the query name)\n",
    "        format: compression type of photos that are downloaded (default='jpg')\n",
    "        color-type: default='full-color', see https://google-images-download.readthedocs.io/en/latest/arguments.html\n",
    "        size: default='medium', see https://google-images-download.readthedocs.io/en/latest/arguments.html\n",
    "        type: default='photo', see https://google-images-download.readthedocs.io/en/latest/arguments.html\n",
    "        delay: default=0, to pause between downloads, see https://google-images-download.readthedocs.io/en/latest/arguments.html\n",
    "        **kwargs: any additional arguments that google-images-download accepts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from .google_images_download import googleimagesdownload\n",
    "    except:\n",
    "        raise NotImplemented('Need google images download for this')\n",
    "    kwargs = _gis_args(keywords, output_directory=output_directory, image_directory=image_directory, \n",
    "             limit=limit, format=format, color_type=color_type, size=size, type=type, delay=delay, \n",
    "             **kwargs)\n",
    "    response = googleimagesdownload()   #class instantiation\n",
    "    paths = response.download(kwargs)   #passing the arguments to the function\n",
    "    \n",
    "def filter_images(keywords, folder=None, columns=4, height=200, width=200):\n",
    "    \"\"\"\n",
    "    Removes duplicate images and shows the remaining images so that the user can manually select\n",
    "    images to remove from the folder by pressing the DELETE button below.\n",
    "    \n",
    "    Arguments:\n",
    "        keywords: subfolder of 'folder' in which the images are stored\n",
    "        folder: folder/output_directory where the crawled images are stored (e.g. /tmp/username/images)\n",
    "        columns (4): number of images displayed per row\n",
    "        height (200): height of the images in pixels\n",
    "        width (200): width of the images in pixels\n",
    "    \"\"\"\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "    def on_click(button):\n",
    "        for r in rows:\n",
    "            if type(r) is widgets.HBox:\n",
    "                for c in r.children:\n",
    "                    checkbox = c.children[1]\n",
    "                    if checkbox.value:\n",
    "                        print(checkbox.description_tooltip)\n",
    "                        os.remove(checkbox.description_tooltip)\n",
    "\n",
    "    if folder is None:\n",
    "        folder = Path(image_folder())\n",
    "    keywords = '_'.join(keywords.split())\n",
    "    imagefiles = [f for f in folder.glob(keywords + '/*')]\n",
    "    rows = []\n",
    "    cols = []\n",
    "    bymean = {}\n",
    "    for i, imgfile in enumerate(tqdm(imagefiles)):\n",
    "        row = i // columns\n",
    "        col = i % columns\n",
    "        img = Image.open(imgfile)\n",
    "        m = hash(tuple(ImageStat.Stat(img).mean))\n",
    "        buff = io.BytesIO()   \n",
    "        img.save(buff, format='JPEG')\n",
    "        if m in bymean:\n",
    "            os.remove(imgfile)\n",
    "        else:\n",
    "            bymean[m] = imgfile\n",
    "\n",
    "        image = widgets.Image( value=buff.getvalue(), width=width, height=height )\n",
    "        button = widgets.Checkbox( description='Delete', description_tooltip = str(imgfile) )\n",
    "        box = widgets.VBox([image, button])\n",
    "        cols.append(box)\n",
    "        if len(cols) == columns:\n",
    "            rows.append(widgets.HBox(cols))\n",
    "            cols = []\n",
    "                 \n",
    "    if len(cols) > 0:\n",
    "        rows.append(widgets.HBox(cols))\n",
    "    button = widgets.Button( description='Delete' )\n",
    "    button.on_click(on_click)\n",
    "    rows.append(button)\n",
    "    return widgets.VBox(rows)        \n",
    "\n",
    "_ptdatasetslist = [('FastMNist B/W', 'pt.mnist()', 'https://github.com/y0ast/pytorch-snippets/tree/main/fast_mnist'),\n",
    "            ('FastMNist RGB', 'pt.mnist3()', 'http://yann.lecun.com/exdb/mnist/'),\n",
    "            ('FastCifar10', 'pt.cifar()', 'https://www.cs.toronto.edu/~kriz/cifar.html')\n",
    "           ]\n",
    "datasets = pd.DataFrame(_ptdatasetslist, columns=['dataset', 'method', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e4952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

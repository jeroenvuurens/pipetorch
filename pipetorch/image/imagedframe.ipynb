{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8dd8d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imagedframe.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imagedframe.py\n",
    "from ..data.dframe import DFrame, Databunch\n",
    "from ..data.helper import dataset_path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageStat\n",
    "import random\n",
    "\n",
    "def LoadImage(fp):\n",
    "    return Image.open(fp[0])\n",
    "\n",
    "def LoadImageFast(fp):\n",
    "    import pyvips\n",
    "    image = pyvips.Image.new_from_file(fp[0], access=\"sequential\")\n",
    "    image = image.colourspace(\"srgb\")\n",
    "    mem_img = image.write_to_memory()\n",
    "    return np.frombuffer(mem_img, dtype=np.uint8).reshape(image.height, image.width, 3)\n",
    "\n",
    "class _ShowBatch:\n",
    "    def _subplots(self, rows, cols, imgsize=4, figsize=None, title=None, **kwargs):\n",
    "        \"Like `plt.subplots` but with consistent axs shape, `kwargs` passed to `fig.suptitle` with `title`\"\n",
    "        if figsize is None:\n",
    "            figsize = (imgsize*cols, imgsize*rows)\n",
    "        fig, axs = plt.subplots(rows,cols,figsize=figsize)\n",
    "        if rows==cols==1:\n",
    "            axs = [[axs]]\n",
    "        elif (rows==1 and cols!=1) or (cols==1 and rows!=1):\n",
    "            axs = [axs]\n",
    "        if title is not None:\n",
    "            fig.suptitle(title, **kwargs)\n",
    "        return np.array(axs)\n",
    "\n",
    "    def _show_batch(self, ds, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        axs = self._subplots(rows, rows, imgsize=imgsize, figsize=figsize).flatten()\n",
    "\n",
    "        for i, ax in enumerate(axs):\n",
    "            img, y = ds[random.randrange(0, len(ds))]\n",
    "            if not issubclass(type(img), Image.Image) and not isinstance(img, Image.Image):\n",
    "                img = transforms.ToPILImage()(img)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = transforms.Resize([100,100])(img)\n",
    "            ax.imshow(img)\n",
    "            try:\n",
    "                y = self.classes[int(y)]\n",
    "            except: pass\n",
    "            ax.set_title(f'y={y}')\n",
    "        for ax in axs.flatten()[i:]:\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "class ImageDatabunch(Databunch, _ShowBatch):\n",
    "    def __init__(self, train_ds, valid_ds=None, test_ds=None, batch_size=32, \n",
    "                 valid_batch_size=None, num_workers=2, shuffle=True, pin_memory=False, \n",
    "                 balance=False, collate=None):\n",
    "        if valid_batch_size is None:\n",
    "            valid_batch_size = batch_size\n",
    "        super().__init__(None, train_ds, valid_ds=valid_ds, test_ds=test_ds, batch_size=batch_size, \n",
    "                         valid_batch_size=valid_batch_size, num_workers=num_workers, shuffle=shuffle, \n",
    "                         pin_memory=pin_memory, balance=balance, collate=collate)\n",
    "\n",
    "    @classmethod\n",
    "    def from_train_test_ds(cls, train_valid_ds, test_ds, valid_perc=0.2, \n",
    "                           batch_size=32, valid_batch_size=None, \n",
    "                           num_workers=2, shuffle=True, pin_memory=False, balance=False, collate=None):\n",
    "        valid_length = int(valid_perc * len(train_valid_ds))\n",
    "        train_length = len(train_valid_ds) - valid_length\n",
    "        train_ds, valid_ds = random_split(train_valid_ds, [train_length, valid_length])\n",
    "        return cls(train_ds, valid_ds, test_ds, batch_size=batch_size, \n",
    "                   valid_batch_size=valid_batch_size, num_workers=num_workers, shuffle=shuffle, \n",
    "                         pin_memory=pin_memory, balance=balance, collate=collate)\n",
    "        \n",
    "    def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        super()._show_batch( self.train_ds, rows=rows, imgsize=imgsize, figsize=figsize)\n",
    "\n",
    "class ImageDFrame(DFrame, _ShowBatch):\n",
    "    _metadata = DFrame._metadata + ['_pt_transforms', '_pt_normalize', '_pt_normalize_mean', '_pt_normalize_std',\n",
    "                                    '_pt_classes', '_pt_class_to_idx']\n",
    "\n",
    "    _internal_names = DFrame._internal_names + ['_pt__locked_normalize_mean', '_pt__locked_normalize_std']\n",
    "    \n",
    "    _internal_names_set = set( _internal_names )\n",
    "    \n",
    "    def __init__(self, data, *args, **kwargs):\n",
    "        super().__init__(data, *args, **kwargs)\n",
    "        self._pt_dtype = str\n",
    "        self._pt__locked_normalize_mean = None\n",
    "        self._pt__locked_normalize_std = None\n",
    "        self.normalize()\n",
    "        \n",
    "    @classmethod\n",
    "    def read_from_kaggle(cls, dataset, filename=None, shared=False, force=False, **kwargs):\n",
    "        if force:\n",
    "            try:\n",
    "                path = path_user(dataset)\n",
    "                shutil.rmtree(path)\n",
    "            except: pass\n",
    "        path = dataset_path(dataset)\n",
    "        if force or not path.exists():\n",
    "            kaggle_download(dataset, shared=shared)\n",
    "        path = dataset_path(dataset)\n",
    "        assert path.exists(), f'Problem downloading Kaggle dataset {dataset}'\n",
    "        rootfolder = None\n",
    "        if filename is None:\n",
    "            filename = '**/*'\n",
    "        files = list(path.glob(filename))\n",
    "        assert len(files) == 1, f'There are multiple files that match {files}, set filename to select a file'\n",
    "        return cls.from_image_folder(path / files[0])\n",
    "\n",
    "    def to_databunch(self, dataset=None, batch_size=32, valid_batch_size=None, \n",
    "                     num_workers=0, shuffle=True, pin_memory=False, balance=False, collate=None):\n",
    "        return ImageDatabunch(*self.to_datasets(dataset=dataset), \n",
    "                         batch_size=batch_size, valid_batch_size=valid_batch_size,\n",
    "                         num_workers=num_workers, shuffle=shuffle, \n",
    "                         pin_memory=pin_memory, balance=balance, collate=collate)  \n",
    "    \n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ImageDFrame\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._pt_classes\n",
    "    \n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return self._pt_class_to_idx\n",
    "    \n",
    "    @classes.setter\n",
    "    def classes(self, value):\n",
    "        self._pt_classes = value\n",
    "        self._pt_class_to_idx = { c:i for i, c in enumerate(value) }\n",
    "    \n",
    "    def _pre_transforms(self):\n",
    "        return [ LoadImage ]\n",
    "    \n",
    "    def _post_transforms(self):\n",
    "        return [ transforms.ToTensor() ]\n",
    "    \n",
    "    def _train_transformation_parameters(self, train_dset):\n",
    "        \"\"\"\n",
    "        This will be called from DFrame when the datasets are consructed on the train dataset.\n",
    "        \"\"\"\n",
    "        if self._pt_normalize:\n",
    "            if self._pt_normalize_mean is None or self._pt_normalize_std is None:\n",
    "                n = 0\n",
    "                sample = range(len(train_set)) if len(train_dset) < 100 else random.sample(range(len(train_dset)), min(100, len(train_dset)))\n",
    "                dset = train_dset.to_dataset()\n",
    "                for i in sample:\n",
    "                    x, y = dset[i]\n",
    "                    try:\n",
    "                        channels\n",
    "                    except:\n",
    "                        channels = len(x)\n",
    "                        x1 = [0.0 for i in range(channels)]\n",
    "                        x2 = [0.0 for i in range(channels)]\n",
    "\n",
    "                    for c in range(channels):\n",
    "                        x1[c] += x[c].view(-1).sum()\n",
    "                        x2[c] += (x[c].view(-1) ** 2).sum()\n",
    "                    n = n + x[0].shape[0] * x[0].shape[1]\n",
    "                sd = np.zeros(channels)\n",
    "                mean = np.zeros(channels)\n",
    "                for c in range(channels):\n",
    "                    sd[c] = np.sqrt(((n * x2[c]) - (x1[c] * x1[c])).numpy() / (n * (n - 1)))\n",
    "                    mean[c] = (x1[c] * x1[c]).numpy() / (n * (n - 1))\n",
    "                self._pt__locked_normalize_mean = torch.tensor(mean) \n",
    "                self._pt__locked_normalize_std = torch.tensor(sd)\n",
    "            else:\n",
    "                self._pt__locked_normalize_mean = self._pt_normalize_mean\n",
    "                self._pt__locked_normalize_std = self._pt_normalize_std\n",
    "            return True\n",
    "\n",
    "    def normalize(self, do=True, normalize_mean=None, normalize_std=None):\n",
    "        \"\"\"\n",
    "        Normalize the images. You can either supply normalize with a precalculated mean and standard\n",
    "        deviation per channel, or pass True to automatically calculate these parameters on the \n",
    "        training set. This will require an additional pass over the training set.\n",
    "        \n",
    "        Arguments:\n",
    "            do: bool (True) - if True images are normalized\n",
    "            \n",
    "            normalized_mean: (float)\n",
    "                set of precalculated means for the dataset. \n",
    "                The set size should be the same as the number of channels in the images.\n",
    "                \n",
    "            normalized_std: (float)\n",
    "                set of precalculated standard deviations for the dataset\n",
    "                The set size should be the same as the number of channels in the images.\n",
    "        \"\"\"\n",
    "        self._pt_normalize = do\n",
    "        self._pt_normalize_mean = torch.tensor(normalize_mean) if normalize_mean is not None else None\n",
    "        self._pt_normalize_std = torch.tensor(normalize_std) if normalize_std is not None else None\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def normalize_mean(self):\n",
    "        return self._pt__locked_normalize_mean    \n",
    "        \n",
    "    @property\n",
    "    def normalize_std(self):\n",
    "        return self._pt__locked_normalize_std    \n",
    "        \n",
    "    def _transforms(self, pre=True, train=True, standard=True, post=True, normalize=True):\n",
    "        t = super()._transforms(pre=pre, train=train, standard=standard, post=post)\n",
    "        if normalize and self._pt__locked_normalize_mean is not None and self._pt__locked_normalize_std is not None:\n",
    "            t.append(transforms.Normalize(mean=self._pt__locked_normalize_mean, \n",
    "                                          std=self._pt__locked_normalize_std))\n",
    "        return t\n",
    "    \n",
    "    def train_images_ds(self):\n",
    "        \"\"\"\n",
    "        returns a version of the train DataSet, for which normalization and post_transforms are turned off\n",
    "        in other words, this will return the images just before they are converted to tensors. \n",
    "        \"\"\"\n",
    "        return self._dset_indices(self._train_indices, self._transforms(post=False, normalize=False)).to_dataset()\n",
    "    \n",
    "    def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        \"\"\"\n",
    "        Shows a sample of rows*rows images from the training set.\n",
    "        \"\"\"\n",
    "        super()._show_batch( self.train_images_ds(), rows=rows, imgsize=imgsize, figsize=figsize)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_binary_folder(cls, folder, **kwargs):\n",
    "        \"\"\"\n",
    "        Construct an ImageDFrame from the filelist that is obtained from TorchVision's ImageFolder,\n",
    "        in other words, the subfolders are the class labels assigned to the files they contain.\n",
    "        \n",
    "        from_binary_folder assumes that we will attempt to use the dataset with a BCELoss functions\n",
    "        and put the target variable as float32 in a column (2D) vector \n",
    "        \"\"\"\n",
    "        try:\n",
    "            folder.samples\n",
    "        except:\n",
    "            folder = ImageFolder(root=folder)\n",
    "        r = ImageDFrame(folder.samples, columns=['filename', 'target'])\n",
    "        r.target = r.target.astype(np.float32)\n",
    "        r.classes = folder.classes\n",
    "        return r\n",
    "    \n",
    "    @classmethod\n",
    "    def from_image_folder(cls, folder, **kwargs):\n",
    "        \"\"\"\n",
    "        Construct an ImageDFrame from the filelist that is obtained from TorchVision's ImageFolder,\n",
    "        in other words, the subfolders are the class labels assigned to the files they contain.\n",
    "\n",
    "        from_image_folder assumes the data is used with a CrossEntropyLoss function\n",
    "        and puts the target variable as long in a row (1D) vector \n",
    "        \"\"\"\n",
    "        try:\n",
    "            folder.samples\n",
    "        except:\n",
    "            folder = ImageFolder(root=folder)\n",
    "        r = ImageDFrame(folder.samples, columns=['filename', 'target'])\n",
    "        r.target = r.target.astype(np.long)\n",
    "        r.classes = folder.classes\n",
    "        return r.columny(vector=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e9fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2aa98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

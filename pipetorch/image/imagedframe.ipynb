{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8dd8d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imagedframe.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imagedframe.py\n",
    "from ..data.dframe import DFrame, Databunch\n",
    "from ..data.transformabledataset import TransformableDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageStat\n",
    "\n",
    "def LoadImage(fp):\n",
    "    return Image.open(fp[0])\n",
    "\n",
    "# class image_databunch:\n",
    "#     def __init__(self, train_ds, valid_ds, batch_size=32, valid_batch_size=None, shuffle=True, num_workers=0, \n",
    "#                  pin_memory=False, valid_pin_memory=None, normalized_mean=None, normalized_std=None, \n",
    "#                  classes=None, class_to_idx=None):\n",
    "#         self.train_ds = train_ds\n",
    "#         self.valid_ds = valid_ds\n",
    "#         self.batch_size = batch_size\n",
    "#         self.valid_batch_size = batch_size if valid_batch_size is None else valid_batch_size\n",
    "#         self.valid_pin_memory = pin_memory if valid_pin_memory is None else valid_pin_memory\n",
    "#         self.num_workers = num_workers\n",
    "#         self.shuffle = shuffle\n",
    "#         self.pin_memory = pin_memory\n",
    "#         self.normalized_mean = normalized_mean\n",
    "#         self.normalized_std = normalized_std\n",
    "#         self.classes = classes\n",
    "#         self.class_to_idx = class_to_idx\n",
    "\n",
    "#     @staticmethod\n",
    "#     def balance(X, y):\n",
    "#         indices = [np.where(y==l)[0] for l in np.unique(y)]\n",
    "#         classlengths = [len(i) for i in indices]\n",
    "#         n = max(classlengths)\n",
    "#         mask = np.hstack([np.random.choice(i, n-l, replace=True) for l,i in zip(classlengths, indices)])\n",
    "#         indices = np.hstack([mask, range(len(y))])\n",
    "#         return X[indices], y[indices]\n",
    "\n",
    "#     def to(self, device):\n",
    "#         try:\n",
    "#             self.train_ds.data.to(device)\n",
    "#         except: pass\n",
    "#         try:\n",
    "#             self.train_ds.targets.to(device)\n",
    "#         except: pass\n",
    "#         try:\n",
    "#             self.valid_ds.data.to(device)\n",
    "#         except: pass\n",
    "#         try:\n",
    "#             self.valid_ds.targets.to(device)\n",
    "#         except: pass\n",
    "#         self.device=device\n",
    "#         return self\n",
    "\n",
    "#     def cpu(self):\n",
    "#         return self.to(torch.device('cpu'))\n",
    "\n",
    "#     def gpu(self):\n",
    "#         return self.to(torch.device('cuda:0'))\n",
    "\n",
    "#     @property\n",
    "#     def batch_size(self):\n",
    "#         return self._batch_size\n",
    "\n",
    "#     @batch_size.setter\n",
    "#     def batch_size(self, value):\n",
    "#         self._batch_size = min(value, len(self.train_ds))\n",
    "#         self.reset()\n",
    "\n",
    "#     @property\n",
    "#     def num_workers(self):\n",
    "#         return self._num_workers\n",
    "\n",
    "#     @num_workers.setter\n",
    "#     def num_workers(self, value):\n",
    "#         self._num_workers = value\n",
    "#         self.reset()\n",
    "\n",
    "#     def evaluate(self, *metrics):\n",
    "#         #assert len(metrics) > 0, 'You need to provide at least one metric for the evaluation'\n",
    "#         return Evaluator(self, *metrics)\n",
    "\n",
    "#     @property\n",
    "#     def labels(self):\n",
    "#         return self._labels\n",
    "    \n",
    "#     @property\n",
    "#     def train_dl(self):\n",
    "#         try:\n",
    "#             return self._train_dl\n",
    "#         except:\n",
    "#             self._train_dl = DataLoader(self.train_ds, num_workers=self.num_workers, shuffle=self.shuffle, batch_size=self.batch_size, pin_memory=self.pin_memory)\n",
    "#             return self._train_dl\n",
    "\n",
    "#     @train_dl.setter\n",
    "#     def train_dl(self, dl):\n",
    "#         self._train_dl = dl\n",
    "\n",
    "#     @property\n",
    "#     def valid_dl(self):\n",
    "#         try:\n",
    "#             return self._valid_dl\n",
    "#         except:\n",
    "#             self._valid_dl = DataLoader(self.valid_ds, shuffle=False, num_workers=self.num_workers, batch_size=self.valid_batch_size, pin_memory=self.valid_pin_memory)\n",
    "#             return self._valid_dl\n",
    "\n",
    "#     @valid_dl.setter\n",
    "#     def valid_dl(self, dl):\n",
    "#         self._valid_dl = dl\n",
    "\n",
    "#     @property\n",
    "#     def train_X(self):\n",
    "#         return self.train_ds.data\n",
    "\n",
    "#     @property\n",
    "#     def train_y(self):\n",
    "#         return self.train_ds.targets\n",
    "\n",
    "#     @property\n",
    "#     def valid_X(self):\n",
    "#         return self.valid_ds.data\n",
    "\n",
    "#     @property\n",
    "#     def valid_y(self):\n",
    "#         return self.valid_ds.targets\n",
    "\n",
    "#     @property\n",
    "#     def train_numpy(self):\n",
    "#         return to_numpy(self.train_X), to_numpy(self.train_y)\n",
    "\n",
    "#     @property\n",
    "#     def valid_numpy(self):\n",
    "#         return to_numpy(self.valid_X), to_numpy(self.valid_y)\n",
    "\n",
    "#     def sample(self, device=None):\n",
    "#         X, y = next(iter(self.train_dl))\n",
    "#         if device is not None:\n",
    "#             return X.to(device), y.to(device)\n",
    "#         return X, y\n",
    "\n",
    "#     def reset(self):\n",
    "#         try:\n",
    "#             del self.valid_dl\n",
    "#         except: pass\n",
    "#         try:\n",
    "#             del self._train_dl\n",
    "#         except: pass\n",
    "\n",
    "#     def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "#         #with plt_inline():\n",
    "#         old_backend = matplotlib.get_backend()\n",
    "#         Xs, ys = next(iter(self.train_dl))\n",
    "#         Xs = Xs[:rows*rows]\n",
    "#         ys = ys[:rows*rows]\n",
    "#         axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)\n",
    "#         invnormalize = self.inv_normalize()\n",
    "#         for x,y,ax in zip(Xs, ys, axs.flatten()):\n",
    "#             x = x.cpu()\n",
    "#             x = invnormalize(x)\n",
    "#             im = transforms.ToPILImage()(x).convert(\"RGB\")\n",
    "#             im = transforms.Resize([100,100])(im)\n",
    "#             ax.imshow(im)\n",
    "#             try:\n",
    "#                 y = self.classes[y]\n",
    "#             except: pass\n",
    "#             ax.set_title(f'y={y}')\n",
    "#         for ax in axs.flatten()[len(Xs):]:\n",
    "#             ax.axis('off')\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "   \n",
    "#     @classmethod\n",
    "#     def get_transformations_train(cls, size=224, crop_size=None, crop_padding=None, color_jitter=None, rotate=None, do_flip=True, normalize_mean=None, normalize_std=None):\n",
    "#         return cls.get_transformations(size=size, crop_size=crop_size, crop_padding=crop_padding, color_jitter=color_jitter, rotate=rotate, do_flip=do_flip, normalize_mean=normalize_mean, normalize_std=normalize_std)\n",
    "\n",
    "#     @classmethod\n",
    "#     def get_transformations(cls, size=224, crop_size=None, crop_padding=None, color_jitter=None, rotate=None, do_flip=None, normalize_mean=None, normalize_std=None):\n",
    "#         t = []\n",
    "#         if rotate is not None:\n",
    "#             t.append(transforms.RandomRotation(rotate))\n",
    "#         if color_jitter is not None:\n",
    "#             t.append(transforms.ColorJitter(*color_jitter))\n",
    "#         if crop_size is not None or crop_padding is not None:\n",
    "#             if crop_size is None:\n",
    "#                 crop_size = size\n",
    "#             if crop_padding is None:\n",
    "#                 crop_padding = 0\n",
    "#             t.append(transforms.RandomCrop(crop_size, padding=crop_padding, pad_if_needed=True))\n",
    "#         if size is not None:\n",
    "#             t.append(transforms.Resize([size,size]))\n",
    "#         if do_flip:\n",
    "#             t.append(transforms.RandomHorizontalFlip())\n",
    "#         t.append(transforms.ToTensor())\n",
    "#         if normalize_mean is not None and normalize_std is not None:\n",
    "#             t.append(transforms.Normalize(mean=normalize_mean, std=normalize_std))\n",
    "#         return transforms.Compose( t )\n",
    "\n",
    "#     def inv_normalize(self):\n",
    "#         if self.normalized_std is not None and self.normalized_mean is not None:\n",
    "#             return transforms.Normalize(mean=tuple(-m/s for m, s in zip(self.normalized_mean, self.normalized_std)), std=tuple(1/s for s in self.normalized_std))\n",
    "#         try:\n",
    "#             for l in self.train_ds.transform.transforms:\n",
    "#                 if type(l) == transforms.Normalize:\n",
    "#                     return transforms.Normalize(mean=tuple(-m/s for m, s in zip(l.mean, l.std)), std=tuple(1/s for s in l.std))\n",
    "#         except:pass\n",
    "#         try:\n",
    "#             for l in self.train_ds.dataset.transform.transforms:\n",
    "#                 if type(l) == transforms.Normalize:\n",
    "#                     return transforms.Normalize(mean=tuple(-m/s for m, s in zip(l.mean, l.std)), std=tuple(1/s for s in l.std))\n",
    "#         except:pass\n",
    "        \n",
    "#         return lambda x:x\n",
    "\n",
    "#     @staticmethod\n",
    "#     def tensor_ds(ds):\n",
    "#         try:\n",
    "#             ds1 = TransformableDataset(ds, transforms.ToTensor())\n",
    "#             ds1[0][0].shape[0]\n",
    "#             return ds1\n",
    "#         except:\n",
    "#             return ds\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def channels(ds):\n",
    "#         return image_databunch.tensor_ds(ds)[0][0].shape[0]\n",
    "    \n",
    "#     @classmethod\n",
    "#     def train_normalize(cls, ds):\n",
    "#         ds = image_databunch.tensor_ds(ds)\n",
    "#         channels = image_databunch.channels(ds)\n",
    "#         total_mean = []\n",
    "#         total_std = []\n",
    "#         for c in range(channels):\n",
    "#             s = torch.cat([X[c].view(-1) for X, y in ds])\n",
    "#             total_mean.append(s.mean())\n",
    "#             total_std.append(s.std())\n",
    "#         return torch.tensor(total_mean), torch.tensor(total_std) \n",
    "    \n",
    "#     @classmethod\n",
    "#     def from_image_folder(cls, path, valid_size=0.2, target_transform=None, size=224, crop_size=None, crop_padding=None, color_jitter=None, rotate=None, do_flip=None, normalize_mean=None, normalize_std=None, normalize=False, **kwargs):\n",
    "#         ds = ImageFolder(root=path, target_transform=target_transform)\n",
    "#         split = int((1-valid_size) * len(ds))\n",
    "#         indices = list(range(len(ds)))\n",
    "#         np.random.shuffle(indices)\n",
    "#         train_idx, valid_idx = indices[:split], indices[split:]\n",
    "#         if normalize:\n",
    "#             assert normalize_mean is None and normalize_std is None, 'You cannot set normalize=True and give the mean or std'\n",
    "#             normalize_mean, normalize_std = cls.train_normalize(Subset(ds, train_idx))\n",
    "#         train_transforms = cls.get_transformations_train(size=size, crop_size=crop_size, crop_padding=crop_padding, color_jitter=color_jitter, rotate=rotate, do_flip=do_flip, normalize_mean=normalize_mean, normalize_std=normalize_std)\n",
    "#         valid_transforms = cls.get_transformations(size=size, normalize_mean=normalize_mean, normalize_std=normalize_std)\n",
    "#         train_ds = TransformableDataset(Subset(ds, train_idx), train_transforms)\n",
    "#         valid_ds = TransformableDataset(Subset(ds, valid_idx), valid_transforms)\n",
    "#         return cls(train_ds, valid_ds, classes=ds.classes, class_to_idx=ds.class_to_idx, \n",
    "#                    normalized_mean=normalize_mean, normalized_std=normalize_std, **kwargs)\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_image_folders(cls, trainpath, validpath, size=None, transform=None, target_transform=None, **kwargs):\n",
    "#         if type(transform) is int:\n",
    "#             train_transforms = cls.get_transformations_train(size=transform)\n",
    "#             valid_transforms = cls.get_transformations(size=transform)\n",
    "#         elif type(transform) is dict:\n",
    "#             train_transforms = cls.get_transformations_train(**transform)\n",
    "#             valid_transforms = cls.get_transformations(**transform)\n",
    "#         elif type(transform) is tuple:\n",
    "#             train_transforms, valid_transforms = transform\n",
    "#         elif transform is None:\n",
    "#             train_transforms = transforms.Compose( [transforms.ToTensor()] )\n",
    "#             valid_transforms = train_transforms\n",
    "#         else:\n",
    "#             train_transforms = transform\n",
    "#             valid_transforms = transform\n",
    " \n",
    "#         train_ds = ImageFolder(root=trainpath, transform=train_transforms, target_transform=target_transform)\n",
    "#         valid_ds = ImageFolder(root=validpath, transform=valid_transforms, target_transform=target_transform)\n",
    "#         return cls(train_ds, valid_ds, classes=train_ds.classes, class_to_idx=train_ds.class_to_idx, **kwargs)        \n",
    "\n",
    "class _ShowBatch:\n",
    "    def _subplots(self, rows, cols, imgsize=4, figsize=None, title=None, **kwargs):\n",
    "        \"Like `plt.subplots` but with consistent axs shape, `kwargs` passed to `fig.suptitle` with `title`\"\n",
    "        if figsize is None:\n",
    "            figsize = (imgsize*cols, imgsize*rows)\n",
    "        fig, axs = plt.subplots(rows,cols,figsize=figsize)\n",
    "        if rows==cols==1:\n",
    "            axs = [[axs]]\n",
    "        elif (rows==1 and cols!=1) or (cols==1 and rows!=1):\n",
    "            axs = [axs]\n",
    "        if title is not None:\n",
    "            fig.suptitle(title, **kwargs)\n",
    "        return np.array(axs)\n",
    "\n",
    "    def _show_batch(self, ds, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        axs = self._subplots(rows, rows, imgsize=imgsize, figsize=figsize).flatten()\n",
    "\n",
    "        for i, ax in enumerate(axs):\n",
    "            img, y = ds[i]\n",
    "            if not issubclass(type(img), Image.Image) and not isinstance(img, Image.Image):\n",
    "                img = transforms.ToPILImage()(img)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = transforms.Resize([100,100])(img)\n",
    "            ax.imshow(img)\n",
    "            try:\n",
    "                y = self.classes[int(y)]\n",
    "            except: pass\n",
    "            ax.set_title(f'y={y}')\n",
    "        for ax in axs.flatten()[i:]:\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "class ImageDatabunch(Databunch, _ShowBatch):\n",
    "    def __init__(self, train_ds, valid_ds=None, test_ds=None, batch_size=32, \n",
    "                 valid_batch_size=None, num_workers=2, shuffle=True, pin_memory=False, balance=False, collate=None):\n",
    "        if valid_batch_size is None:\n",
    "            valid_batch_size = batch_size\n",
    "        super().__init__(None, train_ds, valid_ds=valid_ds, test_ds=test_ds, batch_size=batch_size, \n",
    "                         valid_batch_size=valid_batch_size, num_workers=num_workers, shuffle=shuffle, \n",
    "                         pin_memory=pin_memory, balance=balance, collate=collate)\n",
    "\n",
    "    def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        super()._show_batch( self.train_ds, rows=rows, imgsize=imgsize, figsize=figsize)\n",
    "\n",
    "class ImageDFrame(DFrame, _ShowBatch):\n",
    "    _metadata = DFrame._metadata + ['_pt_transforms', '_pt_normalize', '_pt_normalize_mean', '_pt_normalize_std',\n",
    "                                    '_pt_classes', '_pt_class_to_idx']\n",
    "\n",
    "    _internal_names = DFrame._internal_names + ['_pt__locked_normalize_mean', '_pt__locked_normalize_std']\n",
    "    \n",
    "    _internal_names_set = set( _internal_names )\n",
    "    \n",
    "    def __init__(self, data, *args, **kwargs):\n",
    "        super().__init__(data, *args, **kwargs)\n",
    "        self._pt_dtype = str\n",
    "        self._pt__locked_normalize_mean = None\n",
    "        self._pt__locked_normalize_std = None\n",
    "        self.normalize()\n",
    "        \n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ImageDFrame\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._pt_classes\n",
    "    \n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return self._pt_class_to_idx\n",
    "    \n",
    "    @classes.setter\n",
    "    def classes(self, value):\n",
    "        self._pt_classes = value\n",
    "        self._pt_class_to_idx = { c:i for i, c in enumerate(value) }\n",
    "    \n",
    "    def _pre_transforms(self):\n",
    "        return [ LoadImage ]\n",
    "    \n",
    "    def _post_transforms(self):\n",
    "        return [ transforms.ToTensor() ]\n",
    "    \n",
    "    def _train_transformation_parameters(self, train_dset):\n",
    "        if self._pt_normalize:\n",
    "            if self._pt_normalize_mean is None or self._pt_normalize_std is None:\n",
    "                n = 0\n",
    "                for x, y in iter(train_dset.to_dataset()):\n",
    "                    try:\n",
    "                        channels\n",
    "                    except:\n",
    "                        channels = len(x)\n",
    "                        x1 = [0.0 for i in range(channels)]\n",
    "                        x2 = [0.0 for i in range(channels)]\n",
    "\n",
    "                    for c in range(channels):\n",
    "                        x1[c] += x[c].view(-1).sum()\n",
    "                        x2[c] += (x[c].view(-1) ** 2).sum()\n",
    "                    n = n + len(x[0].view(-1))\n",
    "                sd = np.zeros(channels)\n",
    "                mean = np.zeros(channels)\n",
    "                for c in range(channels):\n",
    "                    sd[c] = np.sqrt(((n * x2[c]) - (x1[c] * x1[c])) / (n * (n - 1)))\n",
    "                    mean[c] = (x1[c] * x1[c]) / (n * (n - 1))\n",
    "                self._pt__locked_normalize_mean = torch.tensor(mean) \n",
    "                self._pt__locked_normalize_std = torch.tensor(sd)\n",
    "            else:\n",
    "                self._pt__locked_normalize_mean = self._pt_normalize_mean\n",
    "                self._pt__locked_normalize_std = self._pt_normalize_std\n",
    "            return True\n",
    "\n",
    "    def normalize(self, do=True, normalize_mean=None, normalize_std=None):\n",
    "        \"\"\"\n",
    "        Normalize the images. You can either supply normalize with a precalculated mean and standard\n",
    "        deviation per channel, or pass True to automatically calculate these parameters on the \n",
    "        training set. This will require an additional pass over the training set.\n",
    "        \n",
    "        Arguments:\n",
    "            do: bool (True) - if True images are normalized\n",
    "            \n",
    "            normalized_mean: (float)\n",
    "                set of precalculated means for the dataset. \n",
    "                The set size should be the same as the number of channels in the images.\n",
    "                \n",
    "            normalized_std: (float)\n",
    "                set of precalculated standard deviations for the dataset\n",
    "                The set size should be the same as the number of channels in the images.\n",
    "        \"\"\"\n",
    "        self._pt_normalize = do\n",
    "        self._pt_normalize_mean = torch.tensor(normalize_mean) if normalize_mean is not None else None\n",
    "        self._pt_normalize_std = torch.tensor(normalize_std) if normalize_std is not None else None\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def normalize_mean(self):\n",
    "        return self._pt__locked_normalize_mean    \n",
    "        \n",
    "    @property\n",
    "    def normalize_std(self):\n",
    "        return self._pt__locked_normalize_std    \n",
    "        \n",
    "    def _transforms(self, pre=True, train=True, standard=True, post=True, normalize=True):\n",
    "        t = super()._transforms(pre=pre, train=train, standard=standard, post=post)\n",
    "        if normalize and self._pt__locked_normalize_mean is not None and self._pt__locked_normalize_std is not None:\n",
    "            t.append(transforms.Normalize(mean=self._pt__locked_normalize_mean, \n",
    "                                          std=self._pt__locked_normalize_std))\n",
    "        return t\n",
    "    \n",
    "    def train_images_ds(self):\n",
    "        \"\"\"\n",
    "        returns a version of the train DataSet, for which normalization and post_transforms are turned off\n",
    "        in other words, this will return the images just before they are converted to tensors. \n",
    "        \"\"\"\n",
    "        return self._dset_indices(self._train_indices, self._transforms(post=False, normalize=False)).to_dataset()\n",
    "    \n",
    "    def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        \"\"\"\n",
    "        Shows a sample of rows*rows images from the training set.\n",
    "        \"\"\"\n",
    "        super()._show_batch( self.train_images_ds(), rows=rows, imgsize=imgsize, figsize=figsize)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_binary_folder(cls, folder, **kwargs):\n",
    "        \"\"\"\n",
    "        Construct an ImageDFrame from the filelist that is obtained from TorchVision's ImageFolder,\n",
    "        in other words, the subfolders are the class labels assigned to the files they contain.\n",
    "        \n",
    "        from_binary_folder assumes that we will attempt to use the dataset with a BCELoss functions\n",
    "        and put the target variable as float32 in a column (2D) vector \n",
    "        \"\"\"\n",
    "        try:\n",
    "            folder.samples\n",
    "        except:\n",
    "            folder = ImageFolder(root=folder)\n",
    "        r = ImageDFrame(folder.samples, columns=['filename', 'target'])\n",
    "        r.target = r.target.astype(np.float32)\n",
    "        r.classes = folder.classes\n",
    "        return r\n",
    "    \n",
    "    @classmethod\n",
    "    def from_image_folder(cls, folder, **kwargs):\n",
    "        \"\"\"\n",
    "        Construct an ImageDFrame from the filelist that is obtained from TorchVision's ImageFolder,\n",
    "        in other words, the subfolders are the class labels assigned to the files they contain.\n",
    "\n",
    "        from_image_folder assumes the data is used with a CrossEntropyLoss function\n",
    "        and puts the target variable as long in a row (1D) vector \n",
    "        \"\"\"\n",
    "        try:\n",
    "            folder.samples\n",
    "        except:\n",
    "            folder = ImageFolder(root=folder)\n",
    "        r = ImageDFrame(folder.samples, columns=['filename', 'target'])\n",
    "        r.target = r.target.astype(np.long)\n",
    "        r.classes = folder.classes\n",
    "        return r.columny(transpose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e9fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2aa98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

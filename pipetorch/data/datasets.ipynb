{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e4c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting datasets.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile datasets.py\n",
    "from .ptdataframe import PTDataFrame\n",
    "from .textcollection import TextCollection\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from pathlib import Path\n",
    "from getpass import getuser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import path\n",
    "import os\n",
    "from sklearn.datasets import load_boston, load_iris\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from functools import partial\n",
    "\n",
    "def path_user():\n",
    "    return Path.home() / '.pipetorchuser'\n",
    "\n",
    "def path_shared():\n",
    "    return Path.home() / '.pipetorch'\n",
    "    \n",
    "def get_filename(url):\n",
    "    fragment_removed = url.split(\"#\")[0]  # keep to left of first #\n",
    "    query_string_removed = fragment_removed.split(\"?\")[0]\n",
    "    scheme_removed = query_string_removed.split(\"://\")[-1].split(\":\")[-1]\n",
    "    if scheme_removed.find(\"/\") == -1:\n",
    "        filename = scheme_removed\n",
    "    else:\n",
    "        filename = os.path.basename(scheme_removed)\n",
    "    if '.' in filename:\n",
    "        filename = filename.rsplit( \".\", 1 )[ 0 ] + '.csv'\n",
    "    return filename\n",
    "    \n",
    "def read_excel(path, filename=None, alternativesource=None, sep=None, delimiter=None, **kwargs):\n",
    "    if filename is None:\n",
    "        filename = get_filename(path)\n",
    "    if (path_user() / filename).is_file():\n",
    "        return PTDataFrame.read_csv(path_user() / filename, **kwargs)\n",
    "    if (path_shared() / filename).is_file():\n",
    "        return PTDataFrame.read_csv(path_shared() / filename, **kwargs)\n",
    "    if alternativesource:\n",
    "        df = pd.read_excel(alternativesource())\n",
    "    else:\n",
    "        print('Downloading new file ' + path)\n",
    "        df = pd.read_excel(path, **kwargs)\n",
    "        df.columns = df.columns.str.replace(' ', '') \n",
    "    (path_user()).mkdir(exist_ok=True)\n",
    "    df.to_csv(path_user() / filename, index=False)\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def read_pd_csv(path, filename=None, alternativesource=None, sep=None, delimiter=None, **kwargs):\n",
    "    if sep:\n",
    "        kwargs['sep'] = sep\n",
    "    elif delimiter:\n",
    "        kwargs['sep'] = delimiter\n",
    "    if filename is None:\n",
    "        filename = get_filename(path)\n",
    "    if (path_user() / filename).is_file():\n",
    "        #print(str(Path.home() / '.pipetorchuser' / filename))\n",
    "        return pd.read_csv(path_user() / filename, **kwargs)\n",
    "    if (path_shared() / filename).is_file():\n",
    "        #print(str(Path.home() / '.pipetorch' / filename))\n",
    "        return pd.read_csv(path_shared() / filename, **kwargs)\n",
    "    if alternativesource:\n",
    "        df = alternativesource()\n",
    "    else:\n",
    "        print('Downloading new file ' + path)\n",
    "        df = pd.read_csv(path, **kwargs)\n",
    "    (path_user()).mkdir(exist_ok=True)\n",
    "    if 'sep' in kwargs:\n",
    "        df.to_csv(path_user() / filename, index=False, sep=kwargs['sep'])\n",
    "    else:\n",
    "        df.to_csv(path_user() / filename, index=False)\n",
    "    return df\n",
    "\n",
    "def read_csv(path, filename=None, alternativesource=None, sep=None, delimiter=None, **kwargs):\n",
    "    return PTDataFrame(read_pd_csv(path, filename=filename, alternativesource=alternativesource, sep=sep, delimiter=delimiter, **kwargs))\n",
    "\n",
    "def read_csv_file(filename, **kwargs):\n",
    "    return PTDataFrame(pd.read_csv(filename, **kwargs))\n",
    "\n",
    "def read_torchtext(torchtext_function):\n",
    "    try:\n",
    "        return torchtext_function(root=path_shared() / torchtext_function.__name__)\n",
    "    except:\n",
    "        return torchtext_function(root=path_user() / torchtext_function.__name__)\n",
    "\n",
    "def wine_quality():\n",
    "    return read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', delimiter=';')\n",
    "\n",
    "def telco_churn():\n",
    "    return read_csv('https://github.com/pmservice/wml-sample-models/raw/master/spark/customer-satisfaction-prediction/data/WA_Fn%20UseC_%20Telco%20Customer%20Churn.csv', filename='telco_churn.csv')\n",
    "\n",
    "def movie_ratings():\n",
    "    def read():\n",
    "        COLS = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "        return pd.read_csv(\"https://raw.githubusercontent.com/ChicagoBoothML/DATA___MovieLens___1M/master/ratings.dat\",sep='::', engine='python', names=COLS)\n",
    "    return read_csv(\"movielens1M.csv\", alternativesource=read)\n",
    "\n",
    "def movie_titles():\n",
    "    def read():\n",
    "        COLS = ['movie_id', 'title', 'genre']\n",
    "        return pd.read_csv(\"https://raw.githubusercontent.com/ChicagoBoothML/DATA___MovieLens___1M/master/movies.dat\",sep='::', engine='python', encoding=\"iso-8859-1\", names=COLS)\n",
    "    return read_csv(\"movies1M.csv\", alternativesource=read)\n",
    "    \n",
    "def dam_outflow():\n",
    "    try:\n",
    "        with open(\"/data/datasets/dam_water_data.pickle\", \"rb\") as myfile:\n",
    "            X_train, X_val, X_test, X_all, y_train, y_val, y_test, y_all = pickle.load(myfile)\n",
    "            train_indices = [ i for i, v in enumerate(X_all) if (X_train == v).any() ]\n",
    "            X_all = X_all.astype(np.float32)\n",
    "            y_all = y_all.astype(np.float32)\n",
    "            df = PTDataFrame(np.concatenate([X_all, y_all.reshape(-1, 1)], axis=1), columns=['waterlevel', 'outflow'])\n",
    "        return df\n",
    "    except:\n",
    "        print('This dataset is not online, but was taken from Andrew Ng\\'s Coursera course')\n",
    "\n",
    "def boston_housing_prices():\n",
    "    \"\"\"\n",
    "    Load the Boston Housing Prices dataset and return it as a Pandas Dataframe\n",
    "    \"\"\"\n",
    "    boston = load_boston()\n",
    "    df = pd.DataFrame(boston['data'] )\n",
    "    df.columns = boston['feature_names']\n",
    "    df['PRICE'] = boston['target']\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def iris():\n",
    "    iris=load_iris()\n",
    "    df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                      columns= iris['feature_names'] + ['target'])\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def bank_marketing():\n",
    "    return read_csv(\"https://github.com/llhthinker/MachineLearningLab/raw/master/UCI%20Bank%20Marketing%20Data%20Set/data/bank-additional/bank-additional-full.csv\", filename='bank_marketing.csv', sep=';')\n",
    "\n",
    "def auto_mpg():\n",
    "    return read_csv('https://raw.githubusercontent.com/joanby/python-ml-course/master/datasets/auto/auto-mpg.csv', na_values='?')\n",
    "\n",
    "def big_mart_sales():\n",
    "    return read_csv('https://raw.githubusercontent.com/akki8087/Big-Mart-Sales/master/Train.csv', filename='big_mart_sales.csv')\n",
    "\n",
    "def advertising_channels():\n",
    "    return read_csv('https://raw.githubusercontent.com/nguyen-toan/ISLR/master/dataset/Advertising.csv').iloc[:,1:]\n",
    "\n",
    "def titanic_survivors():\n",
    "    return read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "\n",
    "def diamonds():\n",
    "    return read_csv('https://raw.githubusercontent.com/SiphuLangeni/Diamond-Price-Prediction/master/Diamonds.csv')\n",
    "\n",
    "def indian_liver():\n",
    "    return read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00225/Indian%20Liver%20Patient%20Dataset%20(ILPD).csv')\n",
    "                   #names=[\"Age\", \"Gender\", \"Total Bilirubin\", \"Direct Bilirubin\", \"Alkphos Alkaline Phosphotase\", \"Sgpt Alamine Aminotransferase\", \"Sgot Aspartate Aminotransferase\", \"Total Protiens\", \"Albumin\", \"Albumin-Globulin Ratio\", \"Disease\"])\n",
    "\n",
    "def ames_housing():\n",
    "    return read_excel('http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls')\n",
    "    \n",
    "def flight_passengers():\n",
    "    import seaborn as sns\n",
    "    df = sns.load_dataset('flights')\n",
    "    #df['month'] = df.month.map({'Jan':0, 'Feb':1, 'Mar':2, 'Apr':3, 'May':4, 'Jun':5, 'Jul':6, 'Aug':7, 'Sep':8, 'Oct':9, 'Nov':10, 'Dec':11}).astype(np.float32)\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def rossmann():\n",
    "    def read():\n",
    "        df = pd.read_csv('https://raw.githubusercontent.com/sarthaksoni25/Rossmann-Store-Sales-Prediction/master/dataset/train.csv')\n",
    "        return df['Id', 'Store', 'Date', 'DayOfWeek', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Sales']\n",
    "    return read_csv('rossmann.csv', alternativesource=read)\n",
    "\n",
    "def california():\n",
    "    return read_csv('https://raw.githubusercontent.com/subhadipml/California-Housing-Price-Prediction/master/housing.csv', filename='california')\n",
    "                         \n",
    "def flights():\n",
    "    df = sns.load_dataset('flights')\n",
    "    df['month'] = df.month.map({'Jan':0, 'Feb':1, 'Mar':2, 'Apr':3, 'May':4, 'Jun':5, 'Jul':6, 'Aug':7, 'Sep':8, 'Oct':9, 'Nov':10, 'Dec':11}).astype(np.float32)\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def nyse50(**kwargs):\n",
    "    df = pd.read_csv('/data/datasets/nyse-top50.csv', **kwargs)\n",
    "    return PTDataFrame(df)\n",
    "    \n",
    "def housing_prices_kaggle_train(**kwargs):\n",
    "    return read_csv_file('/data/datasets/housing_prices_advanced/train.csv', **kwargs)\n",
    "    \n",
    "def housing_prices_kaggle_test(**kwargs):\n",
    "    return read_csv_file('/data/datasets/housing_prices_advanced/test.csv', **kwargs)\n",
    "\n",
    "def housing_prices_kaggle(**kwargs):\n",
    "    train = read_csv_file('/data/datasets/housing_prices_advanced/train.csv', **kwargs)\n",
    "    test = read_csv_file('/data/datasets/housing_prices_advanced/test.csv', **kwargs)\n",
    "    return PTDataFrame.from_train_test(train, test)\n",
    "\n",
    "def heart_disease_kaggle(**kwargs):\n",
    "    train = read_csv_file('/data/datasets/mlms1/train.csv', **kwargs)\n",
    "    test = read_csv_file('/data/datasets/mlms1/test_set.csv', **kwargs)\n",
    "    return PTDataFrame.from_train_test(train, test)\n",
    "    \n",
    "def occupancy():\n",
    "    \"\"\"\n",
    "    Loads the occupancy dataset. Note that this loader does not respect the original train/valid/test split.\n",
    "    \"\"\"\n",
    "    def read(i):\n",
    "        url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00357/occupancy_data.zip'\n",
    "        content = requests.get(url)\n",
    "\n",
    "        f = ZipFile(BytesIO(content.content))\n",
    "        with f.open(f.namelist()[i], 'r') as g:     \n",
    "            return pd.read_csv(g)\n",
    "    train = read_pd_csv('occupancy_train.csv', alternativesource=partial(read, 2))\n",
    "    valid = read_pd_csv('occupancy_valid.csv', alternativesource=partial(read, 0))\n",
    "    #test = read_pd_csv('occupancy_test.csv', alternativesource=partial(read, 1))\n",
    "    return PTDataFrame.from_dfs(train, valid)\n",
    "\n",
    "def ag_news(valid_perc=0.05, language='basic_english', min_freq=1, collate='pad', shuffle=True):\n",
    "    train_iter, test_iter = read_torchtext(AG_NEWS)\n",
    "    tc = TextCollection.from_iter(train_iter, None, test_iter, min_freq=min_freq, shuffle=shuffle).split(valid_perc).collate(collate)\n",
    "    return tc\n",
    "\n",
    "_ptdatasetslist = [('Indian Liver Disease', 'pt.indian_liver()', 'https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset)'),\n",
    "            ('Historial flight passengers', 'pt.flight_passengers()', 'From Seaborn library'),\n",
    "            ('Advertising channels', 'pt.advertising_channels()', 'https://www.kaggle.com/ashydv/advertising-dataset'),\n",
    "            ('Titanic survival', 'pt.titanic()', 'https://www.kaggle.com/c/titanic'),\n",
    "            ('Big Mart Sales', 'pt.big_mart_sales()', 'https://medium.com/total-data-science/big-mart-sales-data-science-projects-98919293c1b3'),\n",
    "            ('Auto MPG', 'pt.auto_mpg()', 'https://archive.ics.uci.edu/ml/datasets/auto+mpg'),\n",
    "            ('Bank Marketing', 'pt.bank_marketing()', 'https://archive.ics.uci.edu/ml/datasets/bank+marketing'),\n",
    "            ('Iris', 'pt.iris()', 'https://archive.ics.uci.edu/ml/datasets/iris'),\n",
    "            ('Boston Housing Prices', 'pt.boston_housing_prices()', 'https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html'),\n",
    "            ('Movie Ratings', 'pt.movie_ratings()', 'https://grouplens.org/datasets/movielens/1m/'),\n",
    "            ('Wine Quality', 'pt.wine_quality()', 'https://archive.ics.uci.edu/ml/datasets/wine+quality'),\n",
    "            ('Telco Churn', 'pt.telco_churn()', 'https://www.kaggle.com/blastchar/telco-customer-churn'),\n",
    "            ('Dam water outflow', 'pt.dam_outflow()', 'From Andrew Ng\\'s Coursera Course'),\n",
    "            ('Kaggle House Prices Competition', 'pt.house_prices()', 'http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls'),\n",
    "            ('Rossmann Store Sales', 'pt.rossmann()', 'https://www.kaggle.com/c/rossmann-store-sales'),\n",
    "            ('California Housing', 'pt.california()', 'https://www.kaggle.com/camnugent/california-housing-prices'),\n",
    "            ('Flights', 'pt.flights()', 'Example Dataset from the Seaborn library with the number of passengers per month'),\n",
    "            ('NYSE', 'pt.nyse50()', 'Crawl of the 2020 quotes of the 50 stocks with the highest turnover on the New York Stock Exchange'),\n",
    "            ('Room occupancy', 'pt.occupancy()', 'https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+'),\n",
    "            ('AG News', 'pt.ag_news()', 'https://pytorch.org/text/stable/datasets.html#ag-news')\n",
    "           ]\n",
    "datasets = pd.DataFrame(_ptdatasetslist, columns=['dataset', 'method', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e4952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting datasets.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile datasets.py\n",
    "from .ptdataframe import PTDataFrame\n",
    "from .textcollection import TextCollection\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from pathlib import Path\n",
    "from getpass import getuser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import path\n",
    "import os\n",
    "from sklearn.datasets import load_boston, load_iris\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from functools import partial\n",
    "from google_images_download import google_images_download\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image, ImageStat\n",
    "\n",
    "def _gis_args(keywords, output_directory=None, \n",
    "                 image_directory=None, limit=200, format='jpg', color_type='full-color', \n",
    "                 size='medium', type='photo', delay=0, **kwargs):\n",
    "    if output_directory is None:\n",
    "        output_directory = str(create_path(f'/tmp/{getuser()}/images'))\n",
    "    if image_directory is None:\n",
    "        image_directory = '_'.join(keywords.split())\n",
    "    arguments = {\"keywords\":keywords, \n",
    "                 \"limit\":limit, \"format\":format, \"color_type\":color_type, \"size\":size, \"type\":type, \n",
    "                 \"delay\":delay, \"image_directory\":image_directory, \n",
    "                 \"output_directory\":output_directory, \"chromedriver\":\"/usr/bin/chromedriver\" }\n",
    "    arguments.update(kwargs)\n",
    "    return arguments\n",
    "\n",
    "def crawl_images(keywords, output_directory=None, \n",
    "                 image_directory=None, limit=200, format='jpg', color_type='full-color', \n",
    "                 size='medium', type='photo', delay=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Downloads images through Google Image Search, \n",
    "    see https://google-images-download.readthedocs.io/en/latest/arguments.html \n",
    "    for info on the arguments. When no output_directory is given, the downloaded images\n",
    "    are stored in /tmp/<username>/images/<query>.\n",
    "    \"\"\"\n",
    "    kwargs = _gis_args(keywords, output_directory=output_directory, image_directory=image_directory, \n",
    "             limit=limit, format=format, color_type=color_type, size=size, type=type, delay=delay, \n",
    "             **kwargs)\n",
    "    response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "    paths = response.download(kwargs)   #passing the arguments to the function\n",
    "    \n",
    "def filter_images(keywords, folder=None, columns=4, height=200, width=200):\n",
    "    \"\"\"\n",
    "    Removes duplicate images and shows the remaining images so that the user can manually select\n",
    "    images to remove from the folder by pressing the DELETE button below.\n",
    "    \"\"\"\n",
    "    def on_click(button):\n",
    "        for r in rows:\n",
    "            if type(r) is widgets.HBox:\n",
    "                for c in r.children:\n",
    "                    checkbox = c.children[1]\n",
    "                    if checkbox.value:\n",
    "                        print(checkbox.description_tooltip)\n",
    "                        os.remove(checkbox.description_tooltip)\n",
    "\n",
    "    if folder is None:\n",
    "        folder = Path(f'/tmp/{getuser()}/images')\n",
    "    keywords = '_'.join(keywords.split())\n",
    "    imagefiles = [f for f in folder.glob(keywords + '/*')]\n",
    "    rows = []\n",
    "    cols = []\n",
    "    bymean = {}\n",
    "    for i, imgfile in enumerate(tqdm(imagefiles)):\n",
    "        row = i // columns\n",
    "        col = i % columns\n",
    "        img = Image.open(imgfile)\n",
    "        m = hash(tuple(ImageStat.Stat(img).mean))\n",
    "        buff = io.BytesIO()   \n",
    "        img.save(buff, format='JPEG')\n",
    "        if m in bymean:\n",
    "            os.remove(imgfile)\n",
    "        else:\n",
    "            bymean[m] = imgfile\n",
    "\n",
    "        image = widgets.Image( value=buff.getvalue(), width=width, height=height )\n",
    "        button = widgets.Checkbox( description='Delete', description_tooltip = str(imgfile) )\n",
    "        box = widgets.VBox([image, button])\n",
    "        cols.append(box)\n",
    "        if len(cols) == columns:\n",
    "            rows.append(widgets.HBox(cols))\n",
    "            cols = []\n",
    "                 \n",
    "    if len(cols) > 0:\n",
    "        rows.append(widgets.HBox(cols))\n",
    "    button = widgets.Button( description='Delete' )\n",
    "    button.on_click(on_click)\n",
    "    rows.append(button)\n",
    "    return widgets.VBox(rows)        \n",
    "\n",
    "def create_path(p, mode=0o777):\n",
    "    path = Path(p)\n",
    "    os.makedirs(path, mode, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def path_user():\n",
    "    return Path.home() / '.pipetorchuser'\n",
    "\n",
    "def path_shared():\n",
    "    return Path.home() / '.pipetorch'\n",
    "    \n",
    "def get_filename(url):\n",
    "    fragment_removed = url.split(\"#\")[0]  # keep to left of first #\n",
    "    query_string_removed = fragment_removed.split(\"?\")[0]\n",
    "    scheme_removed = query_string_removed.split(\"://\")[-1].split(\":\")[-1]\n",
    "    if scheme_removed.find(\"/\") == -1:\n",
    "        filename = scheme_removed\n",
    "    else:\n",
    "        filename = os.path.basename(scheme_removed)\n",
    "    if '.' in filename:\n",
    "        filename = filename.rsplit( \".\", 1 )[ 0 ] + '.csv'\n",
    "    return filename\n",
    "    \n",
    "def read_excel(path, filename=None, alternativesource=None, sep=None, delimiter=None, **kwargs):\n",
    "    if filename is None:\n",
    "        filename = get_filename(path)\n",
    "    if (path_user() / filename).is_file():\n",
    "        return PTDataFrame.read_csv(path_user() / filename, **kwargs)\n",
    "    if (path_shared() / filename).is_file():\n",
    "        return PTDataFrame.read_csv(path_shared() / filename, **kwargs)\n",
    "    if alternativesource:\n",
    "        df = pd.read_excel(alternativesource())\n",
    "    else:\n",
    "        print('Downloading new file ' + path)\n",
    "        df = pd.read_excel(path, **kwargs)\n",
    "        df.columns = df.columns.str.replace(' ', '') \n",
    "    (path_user()).mkdir(exist_ok=True)\n",
    "    df.to_csv(path_user() / filename, index=False)\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def read_pd_csv(path, filename=None, alternativesource=None, sep=None, delimiter=None, **kwargs):\n",
    "    if sep:\n",
    "        kwargs['sep'] = sep\n",
    "    elif delimiter:\n",
    "        kwargs['delimiter'] = delimiter\n",
    "    if filename is None:\n",
    "        filename = get_filename(path)\n",
    "    if (path_user() / filename).is_file():\n",
    "        #print(str(Path.home() / '.pipetorchuser' / filename))\n",
    "        return pd.read_csv(path_user() / filename, **kwargs)\n",
    "    if (path_shared() / filename).is_file():\n",
    "        #print(str(Path.home() / '.pipetorch' / filename))\n",
    "        return pd.read_csv(path_shared() / filename, **kwargs)\n",
    "    if alternativesource:\n",
    "        df = alternativesource()\n",
    "    else:\n",
    "        print('Downloading new file ' + path)\n",
    "        df = pd.read_csv(path, **kwargs)\n",
    "    (path_user()).mkdir(exist_ok=True)\n",
    "    df.to_csv(path_user() / filename, index=False)\n",
    "    return df\n",
    "\n",
    "def read_csv(path, filename=None, alternativesource=None, sep=None, delimiter=None, **kwargs):\n",
    "    return PTDataFrame(read_pd_csv(path, filename=filename, alternativesource=alternativesource, sep=sep, delimiter=delimiter, **kwargs))\n",
    "\n",
    "def read_torchtext(torchtext_function):\n",
    "    try:\n",
    "        return torchtext_function(root=path_shared() / torchtext_function.__name__)\n",
    "    except:\n",
    "        return torchtext_function(root=path_user() / torchtext_function.__name__)\n",
    "\n",
    "def wine_quality():\n",
    "    return read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', delimiter=';')\n",
    "\n",
    "def telco_churn():\n",
    "    return read_csv('https://github.com/pmservice/wml-sample-models/raw/master/spark/customer-satisfaction-prediction/data/WA_Fn%20UseC_%20Telco%20Customer%20Churn.csv', filename='telco_churn.csv')\n",
    "\n",
    "def movie_ratings():\n",
    "    def read():\n",
    "        COLS = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "        return pd.read_csv(\"https://raw.githubusercontent.com/ChicagoBoothML/DATA___MovieLens___1M/master/ratings.dat\",sep='::', engine='python', names=COLS)\n",
    "    return read_csv(\"movielens1M.csv\", alternativesource=read)\n",
    "\n",
    "def movie_titles():\n",
    "    def read():\n",
    "        COLS = ['movie_id', 'title', 'genre']\n",
    "        return pd.read_csv(\"https://raw.githubusercontent.com/ChicagoBoothML/DATA___MovieLens___1M/master/movies.dat\",sep='::', engine='python', encoding=\"iso-8859-1\", names=COLS)\n",
    "    return read_csv(\"movies1M.csv\", alternativesource=read)\n",
    "    \n",
    "def dam_outflow():\n",
    "    try:\n",
    "        with open(\"/data/datasets/dam_water_data.pickle\", \"rb\") as myfile:\n",
    "            X_train, X_val, X_test, X_all, y_train, y_val, y_test, y_all = pickle.load(myfile)\n",
    "            train_indices = [ i for i, v in enumerate(X_all) if (X_train == v).any() ]\n",
    "            X_all = X_all.astype(np.float32)\n",
    "            y_all = y_all.astype(np.float32)\n",
    "            df = PTDataFrame(np.concatenate([X_all, y_all.reshape(-1, 1)], axis=1), columns=['waterlevel', 'outflow'])\n",
    "        return df\n",
    "    except:\n",
    "        print('This dataset is not online, but was taken from Andrew Ng\\'s Coursera course')\n",
    "\n",
    "def boston_housing_prices():\n",
    "    \"\"\"\n",
    "    Load the Boston Housing Prices dataset and return it as a Pandas Dataframe\n",
    "    \"\"\"\n",
    "    boston = load_boston()\n",
    "    df = pd.DataFrame(boston['data'] )\n",
    "    df.columns = boston['feature_names']\n",
    "    df['PRICE'] = boston['target']\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def iris():\n",
    "    iris=load_iris()\n",
    "    df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                      columns= iris['feature_names'] + ['target'])\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def bank_marketing():\n",
    "    return read_csv(\"https://github.com/llhthinker/MachineLearningLab/raw/master/UCI%20Bank%20Marketing%20Data%20Set/data/bank-additional/bank-additional-full.csv\", filename='bank_marketing.csv', sep=';')\n",
    "\n",
    "def auto_mpg():\n",
    "    return read_csv('https://raw.githubusercontent.com/joanby/python-ml-course/master/datasets/auto/auto-mpg.csv')\n",
    "\n",
    "def big_mart_sales():\n",
    "    return read_csv('https://raw.githubusercontent.com/akki8087/Big-Mart-Sales/master/Train.csv', filename='big_mart_sales.csv')\n",
    "\n",
    "def advertising_channels():\n",
    "    return read_csv('https://raw.githubusercontent.com/nguyen-toan/ISLR/master/dataset/Advertising.csv').iloc[:,1:]\n",
    "\n",
    "def titanic_survivors():\n",
    "    return read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "\n",
    "def diamonds():\n",
    "    return read_csv('https://raw.githubusercontent.com/SiphuLangeni/Diamond-Price-Prediction/master/Diamonds.csv')\n",
    "\n",
    "def indian_liver():\n",
    "    return read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00225/Indian%20Liver%20Patient%20Dataset%20(ILPD).csv')\n",
    "                   #names=[\"Age\", \"Gender\", \"Total Bilirubin\", \"Direct Bilirubin\", \"Alkphos Alkaline Phosphotase\", \"Sgpt Alamine Aminotransferase\", \"Sgot Aspartate Aminotransferase\", \"Total Protiens\", \"Albumin\", \"Albumin-Globulin Ratio\", \"Disease\"])\n",
    "\n",
    "def ames_housing():\n",
    "    return read_excel('http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls')\n",
    "    \n",
    "def flight_passengers():\n",
    "    import seaborn as sns\n",
    "    df = sns.load_dataset('flights')\n",
    "    #df['month'] = df.month.map({'Jan':0, 'Feb':1, 'Mar':2, 'Apr':3, 'May':4, 'Jun':5, 'Jul':6, 'Aug':7, 'Sep':8, 'Oct':9, 'Nov':10, 'Dec':11}).astype(np.float32)\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def rossmann():\n",
    "    def read():\n",
    "        df = pd.read_csv('https://raw.githubusercontent.com/sarthaksoni25/Rossmann-Store-Sales-Prediction/master/dataset/train.csv')\n",
    "        return df['Id', 'Store', 'Date', 'DayOfWeek', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Sales']\n",
    "    return read_csv('rossmann.csv', alternativesource=read)\n",
    "\n",
    "def california():\n",
    "    return read_csv('https://raw.githubusercontent.com/subhadipml/California-Housing-Price-Prediction/master/housing.csv', filename='california')\n",
    "                         \n",
    "def flights():\n",
    "    df = sns.load_dataset('flights')\n",
    "    df['month'] = df.month.map({'Jan':0, 'Feb':1, 'Mar':2, 'Apr':3, 'May':4, 'Jun':5, 'Jul':6, 'Aug':7, 'Sep':8, 'Oct':9, 'Nov':10, 'Dec':11}).astype(np.float32)\n",
    "    return PTDataFrame(df)\n",
    "\n",
    "def nyse50(**kwargs):\n",
    "    df = pd.read_csv('/data/datasets/nyse-top50.csv', **kwargs)\n",
    "    return PTDataFrame(df)\n",
    "    \n",
    "def occupancy():\n",
    "    def read(i):\n",
    "        url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00357/occupancy_data.zip'\n",
    "        content = requests.get(url)\n",
    "\n",
    "        f = ZipFile(BytesIO(content.content))\n",
    "        with f.open(f.namelist()[i], 'r') as g:     \n",
    "            return pd.read_csv(g)\n",
    "    train = read_pd_csv('occupancy_train.csv', alternativesource=partial(read, 2))\n",
    "    valid = read_pd_csv('occupancy_valid.csv', alternativesource=partial(read, 0))\n",
    "    test = read_pd_csv('occupancy_test.csv', alternativesource=partial(read, 1))\n",
    "    return PTDataFrame.from_dfs(train, valid=valid, test=test)\n",
    "\n",
    "def ag_news(valid_perc=0.05, language='basic_english', min_freq=1, collate='pad', shuffle=True):\n",
    "    train_iter, test_iter = read_torchtext(AG_NEWS)\n",
    "    tc = TextCollection.from_iter(train_iter, None, test_iter, min_freq=min_freq, shuffle=shuffle).split(valid_perc).collate(collate)\n",
    "    return tc\n",
    "\n",
    "_ptdatasetslist = [('Indian Liver Disease', 'pt.indian_liver()', 'https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset)'),\n",
    "            ('Historial flight passengers', 'pt.flight_passengers()', 'From Seaborn library'),\n",
    "            ('Advertising channels', 'pt.advertising_channels()', 'https://www.kaggle.com/ashydv/advertising-dataset'),\n",
    "            ('Titanic survival', 'pt.titanic()', 'https://www.kaggle.com/c/titanic'),\n",
    "            ('Big Mart Sales', 'pt.big_mart_sales()', 'https://medium.com/total-data-science/big-mart-sales-data-science-projects-98919293c1b3'),\n",
    "            ('Auto MPG', 'pt.auto_mpg()', 'https://archive.ics.uci.edu/ml/datasets/auto+mpg'),\n",
    "            ('Bank Marketing', 'pt.bank_marketing()', 'https://archive.ics.uci.edu/ml/datasets/bank+marketing'),\n",
    "            ('Iris', 'pt.iris()', 'https://archive.ics.uci.edu/ml/datasets/iris'),\n",
    "            ('Boston Housing Prices', 'pt.boston_housing_prices()', 'https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html'),\n",
    "            ('Movie Ratings', 'pt.movie_ratings()', 'https://grouplens.org/datasets/movielens/1m/'),\n",
    "            ('Wine Quality', 'pt.wine_quality()', 'https://archive.ics.uci.edu/ml/datasets/wine+quality'),\n",
    "            ('Telco Churn', 'pt.telco_churn()', 'https://www.kaggle.com/blastchar/telco-customer-churn'),\n",
    "            ('Dam water outflow', 'pt.dam_outflow()', 'From Andrew Ng\\'s Coursera Course'),\n",
    "            ('Kaggle House Prices Competition', 'pt.house_prices()', 'http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls'),\n",
    "            ('Rossmann Store Sales', 'pt.rossmann()', 'https://www.kaggle.com/c/rossmann-store-sales'),\n",
    "            ('California Housing', 'pt.california()', 'https://www.kaggle.com/camnugent/california-housing-prices'),\n",
    "            ('Flights', 'pt.flights()', 'Example Dataset from the Seaborn library with the number of passengers per month'),\n",
    "            ('NYSE', 'pt.nyse50()', 'Crawl of the 2020 quotes of the 50 stocks with the highest turnover on the New York Stock Exchange'),\n",
    "            ('Room occupancy', 'pt.occupancy()', 'https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+'),\n",
    "            ('AG News', 'pt.ag_news()', 'https://pytorch.org/text/stable/datasets.html#ag-news')\n",
    "           ]\n",
    "datasets = pd.DataFrame(_ptdatasetslist, columns=['dataset', 'method', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

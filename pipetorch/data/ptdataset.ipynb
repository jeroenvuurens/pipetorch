{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209951df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ptdataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ptdataset.py        \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.groupby.generic import DataFrameGroupBy, SeriesGroupBy\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import copy\n",
    "import path\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def to_numpy(arr):\n",
    "    try:\n",
    "        return arr.data.cpu().numpy()\n",
    "    except: pass\n",
    "    try:\n",
    "        return arr.to_numpy()\n",
    "    except: pass\n",
    "    return arr\n",
    "\n",
    "class PTDS:\n",
    "    _metadata = ['_df', '_dfindices', '_pt_categoryx', '_pt_categoryy', '_pt_columny', '_pt_columnx', '_pt_transposey', '_pt_bias', '_pt_polynomials', '_pt_dtype', '_pt_sequence_window', '_pt_sequence_shift_y', '_pt_is_test']\n",
    "    _internal_names = pd.DataFrame._internal_names + [\"_pt__indices\"]\n",
    "    _internal_names_set = set(_internal_names)\n",
    "    \n",
    "    def to_ptdataframe(self):\n",
    "        cls = self._df.__class__\n",
    "        r = cls(self)\n",
    "\n",
    "        r._pt__categoryx = self._pt_categoryx\n",
    "        r._pt__categoryy = self._pt_categoryy\n",
    "        r._pt_columnx = self._pt_columnx\n",
    "        r._pt_columny = self._pt_columny\n",
    "        r._pt_transposey = self._pt_transposey\n",
    "        r._pt_bias = self._pt_bias\n",
    "        r._pt_polynomials = self._pt_polynomials\n",
    "        r._pt_sequence_window = self._pt_sequence_window\n",
    "        r._pt_sequence_shift_y = self._pt_sequence_shift_y\n",
    "        \n",
    "        r._pt__train = self\n",
    "        r._pt__full = self\n",
    "        r._pt__valid = None\n",
    "        r._pt__test = None\n",
    "        r._pt_indices = list(range(len(self)))\n",
    "        r._pt__train_indices = r._pt_indices\n",
    "        r._pt__valid_indices = []\n",
    "        r._pt__test_indices = []\n",
    "        r._pt_split = None\n",
    "        r._pt_random_state = None\n",
    "        r._pt_balance = None\n",
    "        r._pt_shuffle = False\n",
    "        return r\n",
    "\n",
    "    def _copy_meta(self, r):\n",
    "        r._df = self._df\n",
    "        r._dfindices = self._dfindices\n",
    "        r._pt_categoryx = self._pt_categoryx\n",
    "        r._pt_categoryy = self._pt_categoryy\n",
    "        r._pt_columny = self._pt_columny\n",
    "        r._pt_columnx = self._pt_columnx\n",
    "        r._pt_is_test = self._pt_is_test\n",
    "        r._pt_transposey = self._pt_transposey\n",
    "        r._pt_polynomials = self._pt_polynomials\n",
    "        r._pt_bias = self._pt_bias\n",
    "        r._pt_dtype = self._pt_dtype\n",
    "        r._pt_sequence_window = self._pt_sequence_window\n",
    "        r._pt_sequence_shift_y = self._pt_sequence_shift_y\n",
    "        return r\n",
    "    \n",
    "    def _ptdataset(self, data):\n",
    "        return self._copy_meta( PTDataSet(data) )\n",
    "    \n",
    "    def _not_nan(self, a):\n",
    "        a = np.isnan(a)\n",
    "        while len(a.shape) > 1:\n",
    "            a = np.any(a, -1)\n",
    "        return np.where(~a)[0]\n",
    "    \n",
    "    @property\n",
    "    def _dtype(self):\n",
    "        return self._pt_dtype\n",
    "    \n",
    "    @property\n",
    "    def indices(self):\n",
    "        try:\n",
    "            return self._pt__indices\n",
    "        except:\n",
    "            if self._pt_is_test:\n",
    "                self._pt__indices = self._not_nan(self._x_sequence)\n",
    "            else:\n",
    "                s = set(self._not_nan(self._y_transposed))\n",
    "                self._pt__indices = [ i for i in self._not_nan(self._x_sequence) if i in s]\n",
    "            return self._pt__indices\n",
    "    \n",
    "    @property\n",
    "    def _scalerx(self):\n",
    "        return self._df._scalerx\n",
    "        \n",
    "    @property\n",
    "    def _scalery(self):\n",
    "        return self._df._scalery\n",
    "\n",
    "    @property\n",
    "    def _categoryx(self):\n",
    "        return self._pt_categoryx\n",
    "        \n",
    "    @property\n",
    "    def _categoryy(self):\n",
    "        return self._pt_categoryy\n",
    "\n",
    "    @property\n",
    "    def _shift_y(self):\n",
    "        if self._pt_sequence_shift_y is not None:\n",
    "            return self._pt_sequence_shift_y\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    @property\n",
    "    def _sequence_window(self):\n",
    "        try:\n",
    "            if self._is_sequence:\n",
    "                return self._pt_sequence_window\n",
    "        except:pass\n",
    "        return 1\n",
    "    \n",
    "    @property\n",
    "    def _sequence_index_y(self):\n",
    "        return self._pt_sequence_window+self._shift_y-1\n",
    "\n",
    "    @property\n",
    "    def _columny(self):\n",
    "        return [ self.columns[-1] ] if self._pt_columny is None else self._pt_columny\n",
    "        \n",
    "    @property\n",
    "    def _transposey(self):\n",
    "        return True if self._pt_transposey is None else self._pt_transposey\n",
    "            \n",
    "    @property\n",
    "    def _columnx(self):\n",
    "        if self._pt_columnx is None:\n",
    "            return [ c for c in self.columns if c not in self._columny ]\n",
    "        return self._pt_columnx\n",
    "   \n",
    "    @property\n",
    "    def _polynomials(self):\n",
    "        return self._pt_polynomials\n",
    "       \n",
    "    @property\n",
    "    def _bias(self):\n",
    "        return self._pt_bias\n",
    "    \n",
    "    def _transform(self, scalers, array):\n",
    "        out = []\n",
    "        for i, scaler in enumerate(scalers):\n",
    "            if scaler is not None:\n",
    "                out.append(scaler.transform(array[:, i:i+1]))\n",
    "            else:\n",
    "                out.append(array[:, i:i+1])\n",
    "        return np.concatenate(out, axis=1)\n",
    "\n",
    "    def resample_rows(self, n=True):\n",
    "        r = self._ptdataset(self)\n",
    "        if n == True:\n",
    "            n = len(r)\n",
    "        if n < 1:\n",
    "            n = n * len(r)\n",
    "        return r.iloc[resample(list(range(len(r))), n_samples = int(n))]\n",
    "    \n",
    "    def interpolate_factor(self, factor=2, sortcolumn=None):\n",
    "        if not sortcolumn:\n",
    "            sortcolumn = self.columns[0]\n",
    "        df = self.sort_values(by=sortcolumn)\n",
    "        for i in range(factor):\n",
    "            i = df.rolling(2).sum()[1:] / 2.0\n",
    "            df = pd.concat([df, i], axis=0)\n",
    "            df = df.sort_values(by=sortcolumn)\n",
    "        return self._df._ptdataset(df).reset_index(drop=True)\n",
    "    \n",
    "    @property\n",
    "    def _x_category(self):\n",
    "        if self._is_sequence:\n",
    "            self = self.iloc[:-self._shift_y]\n",
    "        if self._categoryx is None:\n",
    "            return self[self._columnx]\n",
    "        r = copy.copy(self[self._columnx])\n",
    "        for c, cat in zip(r._columnx, r._categoryx):\n",
    "            if cat is not None:\n",
    "                r[c] = cat.transform(r[c])\n",
    "        return r\n",
    "    \n",
    "    @property\n",
    "    def _x_numpy(self):\n",
    "        return self._x_category.to_numpy()\n",
    "    \n",
    "    @property\n",
    "    def _x_polynomials(self):\n",
    "        try:\n",
    "            return self._polynomials.fit_transform(self._x_numpy)\n",
    "        except:\n",
    "            return self._x_numpy\n",
    "\n",
    "    @property\n",
    "    def _x_scaled(self):\n",
    "        if len(self) > 0:\n",
    "            return self._transform(self._scalerx, self._x_polynomials)\n",
    "        return self._x_polynomials\n",
    "            \n",
    "    @property\n",
    "    def _x_biased(self):\n",
    "        a = self._x_scaled\n",
    "        if self._bias:\n",
    "            return np.concatenate([np.ones((len(a),1)), a], axis=1)\n",
    "        return a\n",
    "    \n",
    "    @property\n",
    "    def _x_sequence(self):\n",
    "        if not self._is_sequence:\n",
    "            return self._x_biased\n",
    "        X = self._x_biased\n",
    "        window = self._sequence_window\n",
    "        len_seq_mode = max(0, len(X) - window + 1)\n",
    "        return np.concatenate([np.expand_dims(X[ii:ii+window], axis=0) for ii in range(len_seq_mode)], axis=0)        \n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._x_sequence[self.indices]\n",
    "\n",
    "    @property\n",
    "    def X_tensor(self):\n",
    "        import torch\n",
    "        if self._dtype is None:\n",
    "            return torch.tensor(self.X).type(torch.FloatTensor)\n",
    "        else:\n",
    "            return torch.tensor(self.X)\n",
    "\n",
    "    @property\n",
    "    def y_tensor(self):\n",
    "        import torch\n",
    "        if self._dtype is None:\n",
    "            return torch.tensor(self.y).type(torch.FloatTensor)\n",
    "        else:\n",
    "            return torch.tensor(self.y)\n",
    " \n",
    "    @property\n",
    "    def _is_sequence(self):\n",
    "        return self._pt_sequence_window is not None\n",
    "        \n",
    "    @property\n",
    "    def tensors(self):\n",
    "        return self.X_tensor, self.y_tensor\n",
    "            \n",
    "    @property\n",
    "    def _range_y(self):\n",
    "        stop = len(self) if self._shift_y >= 0 else len(self) + self._shift_y\n",
    "        start = min(stop, self._sequence_window + self._shift_y - 1)\n",
    "        return slice(start, stop)\n",
    "        \n",
    "    @property\n",
    "    def _y_category(self):\n",
    "        if self._is_sequence:\n",
    "            self = self.iloc[self._range_y]\n",
    "        if self._categoryy is None:\n",
    "            return self[self._columny]\n",
    "        r = copy.copy(self[self._columny])\n",
    "        for c, cat in zip(r._columny, r._categoryy):\n",
    "            if cat is not None:\n",
    "                r[c] = cat.transform(r[c])\n",
    "        return r\n",
    "    \n",
    "    @property\n",
    "    def _y_numpy(self):\n",
    "        return self._y_category.to_numpy()\n",
    "    \n",
    "    @property\n",
    "    def _y_scaled(self):\n",
    "        if len(self) > 0:\n",
    "            return self._transform(self._scalery, self._y_numpy)\n",
    "        return self._y_numpy\n",
    "            \n",
    "    @property\n",
    "    def _y_transposed(self):\n",
    "        return self._y_scaled.squeeze() if self._transposey else self._y_scaled\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y_transposed[self.indices]\n",
    "    \n",
    "    def replace_y(self, y_pred):\n",
    "        y_pred = to_numpy(y_pred(self.X)) if callable(y_pred) else to_numpy(y_pred)\n",
    "        y_pred = self.inverse_transform_y(y_pred)\n",
    "        offset = self._range_y.start\n",
    "        indices = [ i + offset for i in self.indices ]\n",
    "        assert len(y_pred) == len(indices), f'The number of predictions ({len(y_pred)}) does not match the number of samples ({len(indices)})'\n",
    "        r = copy.deepcopy(self)\n",
    "        r[self._columny] = np.NaN\n",
    "        columns = [r.columns.get_loc(c) for c in self._columny]\n",
    "        r.iloc[indices, columns] = y_pred.values\n",
    "        return r\n",
    "    \n",
    "    def to_dataset(self):\n",
    "        \"\"\"\n",
    "        returns: a list with a train, valid and test DataSet. Every DataSet contains an X and y, where the \n",
    "        input data matrix X contains all columns but the last, and the target y contains the last column\n",
    "        columns: list of columns to convert, the last column is always the target. default=None means all columns.\n",
    "        \"\"\"\n",
    "        from torch.utils.data import TensorDataset\n",
    "        return TensorDataset(*self.tensors)\n",
    "    \n",
    "    def predict(self, predict, drop=True):\n",
    "        y_pred = predict(self.X)\n",
    "        if drop:\n",
    "            return self._df.inverse_transform(self.X, y_pred)\n",
    "        return self._df.inverse_transform(self.X, self.y, y_pred)\n",
    "    \n",
    "    def add_column(self, y_pred, *columns):\n",
    "        y_pred = to_numpy(y_pred)\n",
    "        offset = self._range_y.start\n",
    "        indices = [ i + offset for i in self.indices ]\n",
    "\n",
    "        assert len(y_pred) == len(indices), f'The number of predictions ({len(y_pred)}) does not match the number of samples ({len(indices)})'\n",
    "        r = copy.deepcopy(self)\n",
    "        y_pred = self.inverse_transform_y(y_pred)\n",
    "        if len(columns) == 0:\n",
    "            columns = [ c + '_pred' for c in self._columny ]\n",
    "        for c in columns:\n",
    "            r[c] = np.NaN\n",
    "        columns = [r.columns.get_loc(c) for c in columns]\n",
    "        r.iloc[indices, columns] = y_pred.values\n",
    "        return r\n",
    "\n",
    "    def inverse_transform_y(self, y_pred):\n",
    "        return self._df.inverse_transform_y(y_pred)\n",
    "    \n",
    "    def line(self, x=None, y=None, xlabel = None, ylabel = None, title = None, **kwargs ):\n",
    "        self._df.evaluate().line(x=x, y=y, xlabel=xlabel, ylabel=ylabel, title=title, df=self, **kwargs)\n",
    "    \n",
    "    def scatter(self, x=None, y=None, xlabel = None, ylabel = None, title = None, **kwargs ):\n",
    "        self._df.evaluate().scatter(x=x, y=y, xlabel=xlabel, ylabel=ylabel, title=title, df=self, **kwargs)\n",
    "    \n",
    "    def scatter2d_class(self, x1=None, x2=None, y=None, xlabel=None, ylabel=None, title=None, loc='upper right', noise=0, **kwargs):\n",
    "        self._df.evaluate().scatter2d_class(x1=x1, x2=x2, y=y, xlabel=xlabel, ylabel=ylabel, title=title, loc=loc, noise=noise, df=self, **kwargs)\n",
    "\n",
    "    def scatter2d_color(self, x1=None, x2=None, c=None, xlabel=None, ylabel=None, title=None, noise=0, **kwargs):\n",
    "        self._df.evaluate().scatter2d_color(x1=x1, x2=x2, c=c, xlabel=xlabel, ylabel=ylabel, title=title, noise=noise, df=self, **kwargs)\n",
    "\n",
    "    def scatter2d_size(self, x1=None, x2=None, s=None, xlabel=None, ylabel=None, title=None, noise=0, **kwargs):\n",
    "        self._df.evaluate().scatter2d_size(x1=x1, x2=x2, s=s, xlabel=xlabel, ylabel=ylabel, title=title, noise=noise, df=self, **kwargs)\n",
    "\n",
    "    def plot_boundary(self, predict):\n",
    "        self._df.evaluate().plot_boundary(predict)\n",
    "        \n",
    "    def plot_contour(self, predict):\n",
    "        self._df.evaluate().plot_contour(predict)\n",
    "\n",
    "class PTDataSet(pd.DataFrame, PTDS):\n",
    "    _metadata = PTDS._metadata\n",
    "    _internal_names = PTDS._internal_names\n",
    "    _internal_names_set = PTDS._internal_names_set\n",
    "    \n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return PTDataSet\n",
    "           \n",
    "    @classmethod\n",
    "    def from_ptdataframe(cls, data, df, dfindices):\n",
    "        r = cls(data)\n",
    "        r._df = df\n",
    "        r._dfindices = dfindices\n",
    "        r._pt_categoryx = df._categoryx\n",
    "        r._pt_categoryy = df._categoryy\n",
    "        r._pt_columny = df._columny\n",
    "        r._pt_columnx = df._columnx\n",
    "        r._pt_transposey = df._transposey\n",
    "        r._pt_polynomials = df._pt_polynomials\n",
    "        r._pt_bias = df._pt_bias\n",
    "        r._pt_dtype = df._pt_dtype\n",
    "        r._pt_is_test = False\n",
    "        r._pt_sequence_window = df._pt_sequence_window\n",
    "        r._pt_sequence_shift_y = df._pt_sequence_shift_y\n",
    "        return r\n",
    "    \n",
    "    @classmethod\n",
    "    def df_to_testset(cls, data, df, dfindices):\n",
    "        r = cls.from_ptdataframe(data, df, dfindices)\n",
    "        r._pt_is_test = True\n",
    "        return r\n",
    "    \n",
    "    def groupby(self, by, axis=0, level=None, as_index=True, sort=True, group_keys=True, observed=False, dropna=True):\n",
    "        r = super().groupby(by, axis=axis, level=level, as_index=as_index, sort=sort, group_keys=group_keys, observed=observed, dropna=dropna)\n",
    "        return self._copy_meta( PTGroupedDataSet(r) )\n",
    "\n",
    "class PTGroupedDataSetSeries(SeriesGroupBy, PTDS):\n",
    "    _metadata = PTDS._metadata\n",
    "    #_internal_names = PTDS._internal_names\n",
    "    #_internal_names_set = PTDS._internal_names_set\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return PTGroupedDataSetSeries\n",
    "    \n",
    "    @property\n",
    "    def _constructor_expanddim(self):\n",
    "        return PTGroupedDataFrame\n",
    "    \n",
    "class PTGroupedDataSet(DataFrameGroupBy, PTDS):\n",
    "    _metadata = PTDS._metadata\n",
    "    #_internal_names = PTDS._internal_names\n",
    "    #_internal_names_set = PTDS._internal_names_set\n",
    "\n",
    "    def __init__(self, data=None):\n",
    "        super().__init__(obj=data.obj, keys=data.keys, axis=data.axis, level=data.level, grouper=data.grouper, exclusions=data.exclusions,\n",
    "                selection=data._selection, as_index=data.as_index, sort=data.sort, group_keys=data.group_keys,\n",
    "                observed=data.observed, mutated=data.mutated, dropna=data.dropna)\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return PTGroupedDataSet\n",
    "    \n",
    "    @property\n",
    "    def _constructor_sliced(self):\n",
    "        return PTGroupedDataSetSeries\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for group, subset in super().__iter__():\n",
    "            yield group, self._copy_meta(subset)\n",
    "    \n",
    "    def astype(self, dtype, copy=True, errors='raise'):\n",
    "        PTDataSet.astype(self, dtype, copy=copy, errors=errors)\n",
    "\n",
    "    def get_group(self, name, obj=None):\n",
    "        return self._ptdataset( super().get_group(name, obj=obj) )\n",
    "        \n",
    "    def to_dataset(self):\n",
    "        from torch.utils.data import ConcatDataset\n",
    "        dss = []\n",
    "        for key, group in self:\n",
    "            dss.append( group.to_dataset())\n",
    "\n",
    "        return ConcatDataset(dss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176777a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

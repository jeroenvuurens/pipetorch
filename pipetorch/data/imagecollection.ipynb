{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imagecollection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imagecollection.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST, ImageFolder, CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from IPython.core import pylabtools\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from IPython import get_ipython\n",
    "from google_images_download import google_images_download\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image, ImageStat\n",
    "from getpass import getuser\n",
    "from ..evaluate.evaluate import Evaluator\n",
    "\n",
    "ipython = get_ipython()\n",
    "back2gui = { b:g for g, b in pylabtools.backends.items() }\n",
    "\n",
    "class plt_gui:\n",
    "    def __init__(self, gui):\n",
    "        self.gui = gui\n",
    "\n",
    "    def __enter__(self):\n",
    "        backend = matplotlib.get_backend()\n",
    "        self.old_gui = back2gui[backend]\n",
    "        ipython.magic('matplotlib ' + self.gui)\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        ipython.magic('matplotlib ' + self.old_gui)\n",
    "\n",
    "class plt_inline(plt_gui):\n",
    "    def __init__(self):\n",
    "        super().__init__('inline')\n",
    "\n",
    "class plt_notebook(plt_gui):\n",
    "    def __init__(self):\n",
    "        super().__init__('notebook')\n",
    "\n",
    "def subplots(rows, cols, imgsize=4, figsize=None, title=None, **kwargs):\n",
    "    \"Like `plt.subplots` but with consistent axs shape, `kwargs` passed to `fig.suptitle` with `title`\"\n",
    "    if figsize is None:\n",
    "        figsize = (imgsize*cols, imgsize*rows)\n",
    "    fig, axs = plt.subplots(rows,cols,figsize=figsize)\n",
    "    if rows==cols==1:\n",
    "        axs = [[axs]]\n",
    "    elif (rows==1 and cols!=1) or (cols==1 and rows!=1):\n",
    "        axs = [axs]\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, **kwargs)\n",
    "    return np.array(axs)\n",
    "\n",
    "def sample(self, device=None):\n",
    "    X, y = self.one_batch()\n",
    "    if device is not None:\n",
    "        return X.to(device), y.to(device)\n",
    "    return X, y\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Image dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, transform=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super.__init__(*args, **kwargs)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super.__getitem__(idx)\n",
    "\n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "\n",
    "        return item\n",
    "\n",
    "class image_databunch:\n",
    "    def __init__(self, train_ds, valid_ds, batch_size=32, valid_batch_size=None, shuffle=True, num_workers=0, \n",
    "                 pin_memory=False, valid_pin_memory=None, normalized_mean=None, normalized_std=None):\n",
    "        self.train_ds = train_ds\n",
    "        self.valid_ds = valid_ds\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_batch_size = batch_size if valid_batch_size is None else valid_batch_size\n",
    "        self.valid_pin_memory = pin_memory if valid_pin_memory is None else valid_pin_memory\n",
    "        self.num_workers = num_workers\n",
    "        self.shuffle = shuffle\n",
    "        self.pin_memory = pin_memory\n",
    "        self.normalized_mean = normalized_mean\n",
    "        self.normalized_std = normalized_std\n",
    "\n",
    "    @staticmethod\n",
    "    def balance(X, y):\n",
    "        indices = [np.where(y==l)[0] for l in np.unique(y)]\n",
    "        classlengths = [len(i) for i in indices]\n",
    "        n = max(classlengths)\n",
    "        mask = np.hstack([np.random.choice(i, n-l, replace=True) for l,i in zip(classlengths, indices)])\n",
    "        indices = np.hstack([mask, range(len(y))])\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def to(self, device):\n",
    "        try:\n",
    "            self.train_ds.data.to(device)\n",
    "        except: pass\n",
    "        try:\n",
    "            self.train_ds.targets.to(device)\n",
    "        except: pass\n",
    "        try:\n",
    "            self.valid_ds.data.to(device)\n",
    "        except: pass\n",
    "        try:\n",
    "            self.valid_ds.targets.to(device)\n",
    "        except: pass\n",
    "        self.device=device\n",
    "        return self\n",
    "\n",
    "    def cpu(self):\n",
    "        return self.to(torch.device('cpu'))\n",
    "\n",
    "    def gpu(self):\n",
    "        return self.to(torch.device('cuda:0'))\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "\n",
    "    @batch_size.setter\n",
    "    def batch_size(self, value):\n",
    "        self._batch_size = min(value, len(self.train_ds))\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def num_workers(self):\n",
    "        return self._num_workers\n",
    "\n",
    "    @num_workers.setter\n",
    "    def num_workers(self, value):\n",
    "        self._num_workers = value\n",
    "        self.reset()\n",
    "\n",
    "    def evaluate(self, *metrics):\n",
    "        #assert len(metrics) > 0, 'You need to provide at least one metric for the evaluation'\n",
    "        return Evaluator(self, *metrics)\n",
    "\n",
    "    @property\n",
    "    def train_dl(self):\n",
    "        try:\n",
    "            return self._train_dl\n",
    "        except:\n",
    "            self._train_dl = DataLoader(self.train_ds, num_workers=self.num_workers, shuffle=self.shuffle, batch_size=self.batch_size, pin_memory=self.pin_memory)\n",
    "            return self._train_dl\n",
    "\n",
    "    @train_dl.setter\n",
    "    def train_dl(self, dl):\n",
    "        self._train_dl = dl\n",
    "\n",
    "    @property\n",
    "    def valid_dl(self):\n",
    "        try:\n",
    "            return self._valid_dl\n",
    "        except:\n",
    "            self._valid_dl = DataLoader(self.valid_ds, shuffle=False, num_workers=self.num_workers, batch_size=self.valid_batch_size, pin_memory=self.valid_pin_memory)\n",
    "            return self._valid_dl\n",
    "\n",
    "    @valid_dl.setter\n",
    "    def valid_dl(self, dl):\n",
    "        self._valid_dl = dl\n",
    "\n",
    "    @property\n",
    "    def train_X(self):\n",
    "        return self.train_ds.data\n",
    "\n",
    "    @property\n",
    "    def train_y(self):\n",
    "        return self.train_ds.targets\n",
    "\n",
    "    @property\n",
    "    def valid_X(self):\n",
    "        return self.valid_ds.data\n",
    "\n",
    "    @property\n",
    "    def valid_y(self):\n",
    "        return self.valid_ds.targets\n",
    "\n",
    "    @property\n",
    "    def train_numpy(self):\n",
    "        return to_numpy(self.train_X), to_numpy(self.train_y)\n",
    "\n",
    "    @property\n",
    "    def valid_numpy(self):\n",
    "        return to_numpy(self.valid_X), to_numpy(self.valid_y)\n",
    "\n",
    "    def sample(self, device=None):\n",
    "        X, y = next(iter(self.train_dl))\n",
    "        if device is not None:\n",
    "            return X.to(device), y.to(device)\n",
    "        return X, y\n",
    "\n",
    "    def reset(self):\n",
    "        try:\n",
    "            del self.valid_dl\n",
    "        except: pass\n",
    "        try:\n",
    "            del self._train_dl\n",
    "        except: pass\n",
    "\n",
    "    def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        with plt_inline():\n",
    "            old_backend = matplotlib.get_backend()\n",
    "            Xs, ys = next(iter(self.train_dl))\n",
    "            Xs = Xs[:rows*rows]\n",
    "            ys = ys[:rows*rows]\n",
    "            axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)\n",
    "            invnormalize = self.inv_normalize()\n",
    "            for x,y,ax in zip(Xs, ys, axs.flatten()):\n",
    "                x = x.cpu()\n",
    "                x = invnormalize(x)\n",
    "                #x = (1/(2*2.25)) * x / 0.25 + 0.5\n",
    "                im = transforms.ToPILImage()(x).convert(\"RGB\")\n",
    "                im = transforms.Resize([100,100])(im)\n",
    "                ax.imshow(im)\n",
    "                ax.set_title(f'y={y}')\n",
    "            for ax in axs.flatten()[len(Xs):]:\n",
    "                ax.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "   \n",
    "    @classmethod\n",
    "    def get_transformations_train(cls, size=224, crop_size=None, crop_padding=None, color_jitter=None, rotate=None, do_flip=True, normalize_mean=None, normalize_std=None):\n",
    "        return cls.get_transformations(size=size, crop_size=crop_size, crop_padding=crop_padding, color_jitter=color_jitter, rotate=rotate, do_flip=do_flip, normalize_mean=normalize_mean, normalize_std=normalize_std)\n",
    "\n",
    "    @classmethod\n",
    "    def get_transformations(cls, size=224, crop_size=None, crop_padding=None, color_jitter=None, rotate=None, do_flip=None, normalize_mean=None, normalize_std=None):\n",
    "        t = []\n",
    "        if rotate is not None:\n",
    "            t.append(transforms.RandomRotation(rotate))\n",
    "        if color_jitter is not None:\n",
    "            t.append(transforms.ColorJitter((*color_jitter)))\n",
    "        if crop_size is not None or crop_padding is not None:\n",
    "            if crop_size is None:\n",
    "                crop_size = size\n",
    "            if crop_padding is None:\n",
    "                crop_padding = 0\n",
    "            #t.append(Resize(crop_size + 2 * crop_padding))\n",
    "            t.append(transforms.RandomCrop(crop_size, padding=crop_padding, pad_if_needed=True))\n",
    "        if size is not None:\n",
    "            t.append(transforms.Resize([size,size]))\n",
    "        if do_flip:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        t.append(transforms.ToTensor())\n",
    "        if normalize_mean is not None and normalize_std is not None:\n",
    "            t.append(transforms.Normalize(mean=normalize_mean, std=normalize_std))\n",
    "        return transforms.Compose( t )\n",
    "\n",
    "    def inv_normalize(self):\n",
    "        if self.normalized_std is not None and self.normalized_mean is not None:\n",
    "            return transforms.Normalize(mean=tuple(-m/s for m, s in zip(self.normalized_mean, self.normalized_std)), std=tuple(1/s for s in self.normalized_std))\n",
    "        try:\n",
    "            for l in self.train_ds.transform.transforms:\n",
    "                if type(l) == transforms.Normalize:\n",
    "                    return transforms.Normalize(mean=tuple(-m/s for m, s in zip(l.mean, l.std)), std=tuple(1/s for s in l.std))\n",
    "        except:pass\n",
    "        try:\n",
    "            for l in self.train_ds.dataset.transform.transforms:\n",
    "                if type(l) == transforms.Normalize:\n",
    "                    return transforms.Normalize(mean=tuple(-m/s for m, s in zip(l.mean, l.std)), std=tuple(1/s for s in l.std))\n",
    "        except:pass\n",
    "        \n",
    "        return lambda x:x\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_ds(ds):\n",
    "        try:\n",
    "            ds1 = TransformableDataset(ds, transforms.ToTensor())\n",
    "            ds1[0][0].shape[0]\n",
    "            return ds1\n",
    "        except:\n",
    "            return ds\n",
    "    \n",
    "    @staticmethod\n",
    "    def channels(ds):\n",
    "        return tensor_ds(ds)[0][0].shape[0]\n",
    "    \n",
    "    @classmethod\n",
    "    def train_normalize(cls, ds):\n",
    "        ds = tensor_ds(ds)\n",
    "        channels = channels(ds)\n",
    "        total_mean = []\n",
    "        total_std = []\n",
    "        for c in range(channels):\n",
    "            s = torch.cat([X[c].view(-1) for X, y in ds])\n",
    "            total_mean.append(s.mean())\n",
    "            total_std.append(s.std())\n",
    "        return tuple(total_mean), tuple(total_std) \n",
    "    \n",
    "    @classmethod\n",
    "    def from_image_folder(cls, path, valid_size=0.2, target_transform=None, size=224, crop_size=None, crop_padding=None, color_jitter=None, rotate=None, do_flip=None, normalize_mean=None, normalize_std=None, normalize=False, **kwargs):\n",
    "        ds = ImageFolder(root=path, target_transform=target_transform)\n",
    "        split = int((1-valid_size) * len(ds))\n",
    "        indices = list(range(len(ds)))\n",
    "        np.random.shuffle(indices)\n",
    "        train_idx, valid_idx = indices[:split], indices[split:]\n",
    "        if normalize:\n",
    "            assert normalize_mean is None and normalize_std is None, 'You cannot set normalize=True and give the mean or std'\n",
    "            normalize_mean, normalize_std = cls.train_normalize(Subset(ds, train_idx))\n",
    "        train_transforms = cls.get_transformations_train(size=size, crop_size=crop_size, crop_padding=crop_padding, color_jitter=color_jitter, rotate=rotate, do_flip=do_flip, normalize_mean=normalize_mean, normalize_std=normalize_std)\n",
    "        valid_transforms = cls.get_transformations(size=size, normalize_mean=normalize_mean, normalize_std=normalize_std)\n",
    "        train_ds = TransformableDataset(Subset(ds, train_idx), train_transforms)\n",
    "        valid_ds = TransformableDataset(Subset(ds, valid_idx), valid_transforms)\n",
    "        return cls(train_ds, valid_ds, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_image_folders(cls, trainpath, validpath, size=None, transform=None, target_transform=None, **kwargs):\n",
    "        if type(transform) is int:\n",
    "            train_transforms = cls.get_transformations_train(size=transform)\n",
    "            valid_transforms = cls.get_transformations(size=transform)\n",
    "        elif type(transform) is dict:\n",
    "            train_transforms = cls.get_transformations_train(**transform)\n",
    "            valid_transforms = cls.get_transformations(**transform)\n",
    "        elif type(transform) is tuple:\n",
    "            train_transforms, valid_transforms = transform\n",
    "        elif transform is None:\n",
    "            train_transforms = transforms.Compose( [transforms.ToTensor()] )\n",
    "            valid_transforms = train_transforms\n",
    "        else:\n",
    "            train_transforms = transform\n",
    "            valid_transforms = transform\n",
    " \n",
    "        train_ds = ImageFolder(root=trainpath, transform=train_transforms, target_transform=target_transform)\n",
    "        valid_ds = ImageFolder(root=validpath, transform=valid_transforms, target_transform=target_transform)\n",
    "        return cls(train_ds, valid_ds, **kwargs)\n",
    "\n",
    "class TransformableDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.dataset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)    \n",
    "    \n",
    "class Resize(object):\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        old_size = img.size  # old_size[0] is in (width, height) format\n",
    "\n",
    "        ratio = float(self.size)/min(old_size)\n",
    "        new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "        return img.resize(new_size, resample=self.interpolation)\n",
    "    \n",
    "class FastCIFAR(CIFAR10):\n",
    "    def __init__(self, root='/data/datasets/cifarnew/', train=True, transform=None, device=None, size=None, **kwargs):\n",
    "        super().__init__(root=root, train=train, **kwargs)\n",
    "        self.transform=transform\n",
    "        # Scale data to [0,1]\n",
    "        self.data = torch.tensor(self.data).float().div(255)\n",
    "        self.data = self.data.permute(0, 3, 1, 2)\n",
    "        if size is not None:\n",
    "            self.data = F.interpolate(self.data, (3, size, size))\n",
    "        # Normalize it with the usual MNIST mean and std\n",
    "        self.data[:,0] = self.data[:,0].sub_(0.4057).div_(0.2039)\n",
    "        self.data[:,1] = self.data[:,1].sub_(0.5112).div_(0.2372)\n",
    "        self.data[:,2] = self.data[:,2].sub_(0.5245).div_(0.3238)\n",
    "        self.targets = torch.tensor(self.targets)\n",
    "        # Put both data and targets on GPU in advance\n",
    "        if device is not None:\n",
    "            self.data, self.targets = self.data.to(device), self.targets.to(device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target  \n",
    "    \n",
    "class FastMNIST(MNIST):\n",
    "    def __init__(self, *args, transform=None, device=torch.device('cuda:0'), size=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.transform=transform\n",
    "        # Scale data to [0,1]\n",
    "        self.data = self.data.unsqueeze(1).float().div(255)\n",
    "        if size is not None:\n",
    "            self.data = F.interpolate(self.data, (size, size))\n",
    "        # Normalize it with the usual MNIST mean and std\n",
    "        self.data = self.data.sub_(0.1307).div_(0.3081)\n",
    "        # Put both data and targets on GPU in advance\n",
    "        if device is not None:\n",
    "            self.data, self.targets = self.data.to(device), self.targets.to(device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "class FastMNIST3(FastMNIST):\n",
    "    def __init__(self, *args, transform=None, device=torch.device('cuda:0'), size=None, **kwargs):\n",
    "        super().__init__(*args, transform=None, device=torch.device('cuda:0'), **kwargs)\n",
    "        self.size = size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        if self.size is not None:\n",
    "            img = F.interpolate(img.unsqueeze(0), (self.size, self.size)).squeeze(0)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        img = torch.cat([img, img, img], axis=0)\n",
    "        return img, target\n",
    "\n",
    "def mnist(path='/data/datasets/mnist2', batch_size=64, transform=None, size=None, **kwargs):\n",
    "    train_ds = FastMNIST(path, transform=transform, train=True, size=size, **kwargs)\n",
    "    valid_ds = FastMNIST(path, transform=transform, train=False, size=size, **kwargs)\n",
    "    db = image_databunch(train_ds, valid_ds, batch_size=batch_size, \n",
    "                         normalized_mean=(0.1307,), normalized_std=(0.3081,))\n",
    "    return db\n",
    "\n",
    "def mnist3(path='/data/datasets/mnist2', batch_size=64, size=None, transform=None, **kwargs):\n",
    "    train_ds = FastMNIST3(path, transform=transform, train=True, size=size, **kwargs)\n",
    "    valid_ds = FastMNIST3(path, transform=transform, train=False, size=size, **kwargs)\n",
    "    db = image_databunch(train_ds, valid_ds, batch_size=batch_size, \n",
    "                         normalized_mean=(0.1307, 0.1307, 0.1307), normalized_std=(0.3081, 0.3081, 0.3081))\n",
    "    return db\n",
    "\n",
    "def cifar(path='/data/datasets/cifarnew/', batch_size=64, size=None, transform=None, **kwargs):\n",
    "    train_ds = FastCIFAR(root=path, transform=transform, train=True, size=size, **kwargs)\n",
    "    valid_ds = FastCIFAR(root=path, transform=transform, train=False, size=size, **kwargs)\n",
    "    db = image_databunch(train_ds, valid_ds, batch_size=batch_size, \n",
    "                         normalized_mean=(0.4057, 0.5112, 0.5245), normalized_std=(0.2039, 0.2372, 0.3238))\n",
    "    return db\n",
    "\n",
    "def create_path(p, mode=0o777):\n",
    "    path = Path(p)\n",
    "    os.makedirs(path, mode, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def image_folder():\n",
    "    return f'/tmp/{getuser()}/images'\n",
    "\n",
    "def _gis_args(keywords, output_directory=None, \n",
    "                 image_directory=None, limit=200, format='jpg', color_type='full-color', \n",
    "                 size='medium', type='photo', delay=0, **kwargs):\n",
    "    if output_directory is None:\n",
    "        output_directory = str(create_path(image_folder()))\n",
    "    if image_directory is None:\n",
    "        image_directory = '_'.join(keywords.split())\n",
    "    arguments = {\"keywords\":keywords, \n",
    "                 \"limit\":limit, \"format\":format, \"color_type\":color_type, \"size\":size, \"type\":type, \n",
    "                 \"delay\":delay, \"image_directory\":image_directory, \n",
    "                 \"output_directory\":output_directory, \"chromedriver\":\"/usr/bin/chromedriver\" }\n",
    "    arguments.update(kwargs)\n",
    "    return arguments\n",
    "\n",
    "def crawl_images(keywords, output_directory=None, \n",
    "                 image_directory=None, limit=200, format='jpg', color_type='full-color', \n",
    "                 size='medium', type='photo', delay=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Downloads images through Google Image Search, \n",
    "    see https://google-images-download.readthedocs.io/en/latest/arguments.html \n",
    "    for info on the arguments. When no output_directory is given, the downloaded images\n",
    "    are stored in /tmp/<username>/images/<query>.\n",
    "    \"\"\"\n",
    "    kwargs = _gis_args(keywords, output_directory=output_directory, image_directory=image_directory, \n",
    "             limit=limit, format=format, color_type=color_type, size=size, type=type, delay=delay, \n",
    "             **kwargs)\n",
    "    response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "    paths = response.download(kwargs)   #passing the arguments to the function\n",
    "    \n",
    "def filter_images(keywords, folder=None, columns=4, height=200, width=200):\n",
    "    \"\"\"\n",
    "    Removes duplicate images and shows the remaining images so that the user can manually select\n",
    "    images to remove from the folder by pressing the DELETE button below.\n",
    "    \"\"\"\n",
    "    def on_click(button):\n",
    "        for r in rows:\n",
    "            if type(r) is widgets.HBox:\n",
    "                for c in r.children:\n",
    "                    checkbox = c.children[1]\n",
    "                    if checkbox.value:\n",
    "                        print(checkbox.description_tooltip)\n",
    "                        os.remove(checkbox.description_tooltip)\n",
    "\n",
    "    if folder is None:\n",
    "        folder = Path(image_folder())\n",
    "    keywords = '_'.join(keywords.split())\n",
    "    imagefiles = [f for f in folder.glob(keywords + '/*')]\n",
    "    rows = []\n",
    "    cols = []\n",
    "    bymean = {}\n",
    "    for i, imgfile in enumerate(tqdm(imagefiles)):\n",
    "        row = i // columns\n",
    "        col = i % columns\n",
    "        img = Image.open(imgfile)\n",
    "        m = hash(tuple(ImageStat.Stat(img).mean))\n",
    "        buff = io.BytesIO()   \n",
    "        img.save(buff, format='JPEG')\n",
    "        if m in bymean:\n",
    "            os.remove(imgfile)\n",
    "        else:\n",
    "            bymean[m] = imgfile\n",
    "\n",
    "        image = widgets.Image( value=buff.getvalue(), width=width, height=height )\n",
    "        button = widgets.Checkbox( description='Delete', description_tooltip = str(imgfile) )\n",
    "        box = widgets.VBox([image, button])\n",
    "        cols.append(box)\n",
    "        if len(cols) == columns:\n",
    "            rows.append(widgets.HBox(cols))\n",
    "            cols = []\n",
    "                 \n",
    "    if len(cols) > 0:\n",
    "        rows.append(widgets.HBox(cols))\n",
    "    button = widgets.Button( description='Delete' )\n",
    "    button.on_click(on_click)\n",
    "    rows.append(button)\n",
    "    return widgets.VBox(rows)        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

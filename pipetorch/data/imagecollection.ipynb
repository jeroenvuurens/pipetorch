{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imagecollection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imagecollection.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST, ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from IPython.core import pylabtools\n",
    "from pathlib2 import Path\n",
    "import sys\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "back2gui = { b:g for g, b in pylabtools.backends.items() }\n",
    "\n",
    "class plt_gui:\n",
    "    def __init__(self, gui):\n",
    "        self.gui = gui\n",
    "\n",
    "    def __enter__(self):\n",
    "        backend = matplotlib.get_backend()\n",
    "        self.old_gui = back2gui[backend]\n",
    "        ipython.magic('matplotlib ' + self.gui)\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        ipython.magic('matplotlib ' + self.old_gui)\n",
    "\n",
    "class plt_inline(plt_gui):\n",
    "    def __init__(self):\n",
    "        super().__init__('inline')\n",
    "\n",
    "class plt_notebook(plt_gui):\n",
    "    def __init__(self):\n",
    "        super().__init__('notebook')\n",
    "\n",
    "def subplots(rows, cols, imgsize=4, figsize=None, title=None, **kwargs):\n",
    "    \"Like `plt.subplots` but with consistent axs shape, `kwargs` passed to `fig.suptitle` with `title`\"\n",
    "    if figsize is None:\n",
    "        figsize = (imgsize*cols, imgsize*rows)\n",
    "    fig, axs = plt.subplots(rows,cols,figsize=figsize)\n",
    "    if rows==cols==1:\n",
    "        axs = [[axs]]\n",
    "    elif (rows==1 and cols!=1) or (cols==1 and rows!=1):\n",
    "        axs = [axs]\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, **kwargs)\n",
    "    return np.array(axs)\n",
    "\n",
    "def sample(self, device=None):\n",
    "    X, y = self.one_batch()\n",
    "    if device is not None:\n",
    "        return X.to(device), y.to(device)\n",
    "    return X, y\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Image dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, transform=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super.__init__(*args, **kwargs)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super.__getitem__(idx)\n",
    "\n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "\n",
    "        return item\n",
    "\n",
    "class image_databunch:\n",
    "    def __init__(self, train_ds, valid_ds, batch_size=32, valid_batch_size=None, shuffle=True, num_workers=0, pin_memory=False, valid_pin_memory=None, device=torch.device('cuda:0')):\n",
    "        self.train_ds = train_ds\n",
    "        self.valid_ds = valid_ds\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_batch_size = batch_size if valid_batch_size is None else valid_batch_size\n",
    "        self.valid_pin_memory = pin_memory if valid_pin_memory is None else valid_pin_memory\n",
    "        self.num_workers = num_workers\n",
    "        self.shuffle = shuffle\n",
    "        self.pin_memory = pin_memory\n",
    "        self.to( device )\n",
    "\n",
    "    @staticmethod\n",
    "    def balance(X, y):\n",
    "        indices = [np.where(y==l)[0] for l in np.unique(y)]\n",
    "        classlengths = [len(i) for i in indices]\n",
    "        n = max(classlengths)\n",
    "        mask = np.hstack([np.random.choice(i, n-l, replace=True) for l,i in zip(classlengths, indices)])\n",
    "        indices = np.hstack([mask, range(len(y))])\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def to(self, device):\n",
    "        try:\n",
    "            self.train_ds.data.to(device)\n",
    "        except: pass\n",
    "        try:\n",
    "            self.train_ds.targets.to(device)\n",
    "        except: pass\n",
    "        try:\n",
    "            self.valid_ds.data.to(device)\n",
    "        except: pass\n",
    "        try:\n",
    "            self.valid_ds.targets.to(device)\n",
    "        except: pass\n",
    "        self.device=device\n",
    "        return self\n",
    "\n",
    "    def cpu(self):\n",
    "        return self.to(torch.device('cpu'))\n",
    "\n",
    "    def gpu(self):\n",
    "        return self.to(torch.device('cuda:0'))\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "\n",
    "    @batch_size.setter\n",
    "    def batch_size(self, value):\n",
    "        self._batch_size = min(value, len(self.train_ds))\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def num_workers(self):\n",
    "        return self._num_workers\n",
    "\n",
    "    @num_workers.setter\n",
    "    def num_workers(self, value):\n",
    "        self._num_workers = value\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def train_dl(self):\n",
    "        try:\n",
    "            return self._train_dl\n",
    "        except:\n",
    "            self._train_dl = DataLoader(self.train_ds, num_workers=self.num_workers, shuffle=self.shuffle, batch_size=self.batch_size, pin_memory=self.pin_memory)\n",
    "            return self._train_dl\n",
    "\n",
    "    @train_dl.setter\n",
    "    def train_dl(self, dl):\n",
    "        self._train_dl = dl\n",
    "\n",
    "    @property\n",
    "    def valid_dl(self):\n",
    "        try:\n",
    "            return self._valid_dl\n",
    "        except:\n",
    "            self._valid_dl = DataLoader(self.valid_ds, shuffle=False, num_workers=self.num_workers, batch_size=self.valid_batch_size, pin_memory=self.valid_pin_memory)\n",
    "            return self._valid_dl\n",
    "\n",
    "    @valid_dl.setter\n",
    "    def valid_dl(self, dl):\n",
    "        self._valid_dl = dl\n",
    "\n",
    "    @property\n",
    "    def train_X(self):\n",
    "        return self.train_ds.data\n",
    "\n",
    "    @property\n",
    "    def train_y(self):\n",
    "        return self.train_ds.targets\n",
    "\n",
    "    @property\n",
    "    def valid_X(self):\n",
    "        return self.valid_ds.data\n",
    "\n",
    "    @property\n",
    "    def valid_y(self):\n",
    "        return self.valid_ds.targets\n",
    "\n",
    "    @property\n",
    "    def train_numpy(self):\n",
    "        return to_numpy(self.train_X), to_numpy(self.train_y)\n",
    "\n",
    "    @property\n",
    "    def valid_numpy(self):\n",
    "        return to_numpy(self.valid_X), to_numpy(self.valid_y)\n",
    "\n",
    "    def sample(self, device=None):\n",
    "        X, y = next(iter(self.train_dl))\n",
    "        if device is not None:\n",
    "            return X.to(device), y.to(device)\n",
    "        return X, y\n",
    "\n",
    "    def reset(self):\n",
    "        try:\n",
    "            del self.valid_dl\n",
    "        except: pass\n",
    "        try:\n",
    "            del self._train_dl\n",
    "        except: pass\n",
    "\n",
    "    def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        with plt_inline():\n",
    "            old_backend = matplotlib.get_backend()\n",
    "            Xs, ys = next(iter(self.train_dl))\n",
    "            Xs = Xs[:rows*rows]\n",
    "            ys = ys[:rows*rows]\n",
    "            axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)\n",
    "            invnormalize = self.inv_normalize()\n",
    "            for x,y,ax in zip(Xs, ys, axs.flatten()):\n",
    "                x = x.cpu()\n",
    "                x = invnormalize(x)\n",
    "                #x = (1/(2*2.25)) * x / 0.25 + 0.5\n",
    "                im = transforms.ToPILImage()(x).convert(\"RGB\")\n",
    "                im = transforms.Resize([100,100])(im)\n",
    "                ax.imshow(im)\n",
    "                ax.set_title(f'y={y}')\n",
    "            for ax in axs.flatten()[len(Xs):]:\n",
    "                ax.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    @classmethod\n",
    "    def get_transformations(cls, size=224, do_flip=True):\n",
    "        t = []\n",
    "        if size is not None:\n",
    "            t.append(transforms.Resize([size,size]))\n",
    "        if do_flip:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        t.append(transforms.ToTensor())\n",
    "        t.append(transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)))\n",
    "        return transforms.Compose( t )\n",
    "\n",
    "    def inv_normalize(self):\n",
    "        try:\n",
    "            for l in self.train_ds.transform.transforms:\n",
    "                if type(l) == transforms.Normalize:\n",
    "                    return transforms.Normalize(mean=tuple(-m/s for m, s in zip(l.mean, l.std)), std=tuple(1/s for s in l.std))\n",
    "        except:pass\n",
    "        try:\n",
    "            for l in self.train_ds.dataset.transform.transforms:\n",
    "                if type(l) == transforms.Normalize:\n",
    "                    return transforms.Normalize(mean=tuple(-m/s for m, s in zip(l.mean, l.std)), std=tuple(1/s for s in l.std))\n",
    "        except:pass\n",
    "        return lambda x:x\n",
    "\n",
    "    @classmethod\n",
    "    def from_image_folder(cls, path, size=None, transforms=None, valid_size=0.2, **kwargs):\n",
    "        if transforms is None:\n",
    "            if size is None:\n",
    "                size=224\n",
    "            transforms = cls.get_transformations(size=size)\n",
    "        else:\n",
    "            assert size is None, 'Specify size through get_transforms'\n",
    "        ds = ImageFolder(root=path, transform=transforms)\n",
    "        valid_len = int(valid_size * len(ds))\n",
    "        train_len = len(ds) - valid_len\n",
    "        train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "        return cls(train_ds, valid_ds, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_image_folders(cls, trainpath, validpath, size=None, transforms=None, **kwargs):\n",
    "        if transforms is None:\n",
    "            if size is None:\n",
    "                size=224\n",
    "            transforms = cls.get_transformations(size=size)\n",
    "        else:\n",
    "            assert size is None, 'Specify size through get_transforms'\n",
    "        train_ds = ImageFolder(root=trainpath, transform=transforms)\n",
    "        valid_ds = ImageFolder(root=validpath, transform=transforms)\n",
    "        return cls(train_ds, valid_ds, **kwargs)\n",
    "\n",
    "class FastMNIST(MNIST):\n",
    "    def __init__(self, *args, transform=None, device=torch.device('cuda:0'), size=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Scale data to [0,1]\n",
    "        self.data = self.data.unsqueeze(1).float().div(255)\n",
    "        if size is not None:\n",
    "            self.data = F.interpolate(self.data, (size, size))\n",
    "        # Normalize it with the usual MNIST mean and std\n",
    "        self.data = self.data.sub_(0.1307).div_(0.3081)\n",
    "        # Put both data and targets on GPU in advance\n",
    "        if device is not None:\n",
    "            self.data, self.targets = self.data.to(device), self.targets.to(device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "class FastMNIST3(MNIST):\n",
    "    def __init__(self, *args, transform=None, device=None, size=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Scale data to [0,1]\n",
    "        self.data = self.data.unsqueeze(1).float().div(255)\n",
    "        if size is not None:\n",
    "            self.data = F.interpolate(self.data, (size, size))\n",
    "        # Normalize it with the usual MNIST mean and std\n",
    "        self.data = self.data.sub_(0.1307).div_(0.3081)\n",
    "        # Put both data and targets on GPU in advance\n",
    "        if device is not None:\n",
    "            self.data, self.targets = self.data.to(device), self.targets.to(device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        img = torch.cat([img, img, img], axis=0)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "def mnist(path='/data/datasets/mnist2', num_workers=0, batch_size=64, transform=None, **kwargs):\n",
    "    train_ds = FastMNIST(path, transform=transform, train=True, **kwargs)\n",
    "    valid_ds = FastMNIST(path, transform=transform, train=False, **kwargs)\n",
    "    db = image_databunch(train_ds, valid_ds, num_workers=num_workers, batch_size=batch_size)\n",
    "    return db\n",
    "\n",
    "def mnist3(path='/data/datasets/mnist2', num_workers=0, batch_size=64, transform=None, **kwargs):\n",
    "    train_ds = FastMNIST3(path, transform=transform, train=True, **kwargs)\n",
    "    valid_ds = FastMNIST3(path, transform=transform, train=False, **kwargs)\n",
    "    db = image_databunch(train_ds, valid_ds, num_workers=num_workers, batch_size=batch_size)\n",
    "    return db\n",
    "\n",
    "def mnist3old(path='/data/datasets/mnist', num_workers=0, batch_size=64, size=28, **kwargs):\n",
    "    return image_databunch.from_image_folder(path, transforms=image_databunch.get_transformations(do_flip=False, size=size), num_workers=num_workers, **kwargs)\n",
    "\n",
    "def cifar(path='/data/datasets/mnist', num_workers=0, batch_size=64, **kwargs):\n",
    "    return image_databunch.from_image_folder(path, transforms=image_databunch.get_transformations(do_flip=False, size=28), num_workers=num_workers, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

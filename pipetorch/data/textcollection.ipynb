{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting textcollection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile textcollection.py\n",
    "from torchtext.data.utils import get_tokenizer, ngrams_iterator\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data.dataset import random_split\n",
    "from .databunch import Databunch\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "class TextCollection:\n",
    "    def __init__(self, train_iter, valid_iter, test_iter=None, language='basic_english', min_freq=1, vocab=None, \n",
    "                 labels = None, batch_size = 32, shuffle=True, specials=('<unk>', '<pad>')):\n",
    "        self._train_iter = train_iter\n",
    "        self._valid_iter = valid_iter\n",
    "        self._test_iter = test_iter\n",
    "        self.language = language\n",
    "        self.min_freq = min_freq\n",
    "        self.vocab = vocab\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.specials = specials\n",
    "        self.__collate = None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_iter(cls, train_iter, valid_iter, test_iter=None, language='basic_english', min_freq=1, vocab=None, \n",
    "                 labels = None, batch_size = 32, shuffle=True, specials=('<unk>', '<pad>'), collate=None):\n",
    "        r = cls(train_iter, valid_iter, test_iter=test_iter, language=language, min_freq=min_freq, vocab=vocab, \n",
    "                 labels = labels, batch_size = batch_size, shuffle=shuffle, specials=specials)\n",
    "        if collate is not None:\n",
    "            r = r.collate(collate)\n",
    "        return r\n",
    "    \n",
    "    @property\n",
    "    def _collate(self):\n",
    "        return self.__collate\n",
    "    \n",
    "    def collate(self, collate):\n",
    "        if collate == 'offset':\n",
    "            return OffsetTextCollection(self._train_iter, self._valid_iter, test_iter=self._test_iter, \n",
    "                    language=self.language, min_freq=self.min_freq, vocab=self.vocab, labels = self.labels, \n",
    "                    batch_size = self.batch_size, shuffle=self.shuffle, specials=self.specials)\n",
    "        if collate == 'pad':\n",
    "            return PaddedTextCollection(self._train_iter, self._valid_iter, test_iter=self._test_iter,  \n",
    "                    language=self.language, min_freq=self.min_freq, vocab=self.vocab, labels = self.labels, \n",
    "                    batch_size = self.batch_size, shuffle=self.shuffle, specials=self.specials)\n",
    "        r = TextCollection(self._train_iter, self._valid_iter, test_iter=self._test_iter,  \n",
    "                    language=self.language, min_freq=self.min_freq, vocab=self.vocab, labels = self.labels, \n",
    "                    batch_size = self.batch_size, shuffle=self.shuffle, specials=self.specials)\n",
    "        r.__collate = collate\n",
    "        return r   \n",
    "    \n",
    "    def split(self, valid_perc, test_perc=None):\n",
    "        r = copy.copy(self)\n",
    "        test_count = 0 if test_perc is None else round(test_perc * len(r._train_iter))\n",
    "        valid_count = round(valid_perc * len(r._train_iter))\n",
    "        train_count = len(r._train_iter) - test_count - valid_count\n",
    "        print(len(r._train_iter), train_count, valid_count, test_count)\n",
    "        train_iter, valid_iter, test_iter = random_split(list(r._train_iter), [train_count, valid_count, test_count])\n",
    "        r._train_iter = train_iter\n",
    "        r._valid_iter = valid_iter\n",
    "        if test_perc is not None:\n",
    "            r._test_iter = test_iter\n",
    "        return r\n",
    "        \n",
    "    @property\n",
    "    def language(self):\n",
    "        return self._language\n",
    "        \n",
    "    @language.setter\n",
    "    def language(self, value):\n",
    "        if value is not None:\n",
    "            self._language = value\n",
    "        \n",
    "    @property\n",
    "    def min_freq(self):\n",
    "        return self._min_freq\n",
    "        \n",
    "    @min_freq.setter\n",
    "    def min_freq(self, value):\n",
    "        if value is not None:\n",
    "            self._min_freq = value\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "        \n",
    "    @batch_size.setter\n",
    "    def batch_size(self, value):\n",
    "        if value is not None:\n",
    "            self._batch_size = value\n",
    "\n",
    "    @property\n",
    "    def shuffle(self):\n",
    "        return self._shuffle\n",
    "        \n",
    "    @shuffle.setter\n",
    "    def shuffle(self, value):\n",
    "        if value is not None:\n",
    "            self._shuffle = value\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        try:\n",
    "            return self._train\n",
    "        except:\n",
    "            self._train = TextDataSet(self._train_iter)\n",
    "            return self._train\n",
    "        \n",
    "    @property\n",
    "    def valid(self):\n",
    "        try:\n",
    "            return self._valid\n",
    "        except:\n",
    "            self._valid = TextDataSet(self._valid_iter)\n",
    "            return self._valid\n",
    "        \n",
    "    @property\n",
    "    def test(self):\n",
    "        try:\n",
    "            return self._test\n",
    "        except:\n",
    "            self._test = TextDataSet(self._test_iter)\n",
    "            return self._test\n",
    "    \n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        try:\n",
    "            return self._tokenizer\n",
    "        except:\n",
    "            self._tokenizer = get_tokenizer(self.language)\n",
    "            return self._tokenizer\n",
    "        \n",
    "    @property\n",
    "    def vocab(self):\n",
    "        try:\n",
    "            return self._vocab\n",
    "        except:\n",
    "            self._build_vocab()\n",
    "            return self._vocab\n",
    "    \n",
    "    @property\n",
    "    def labels(self):\n",
    "        try:\n",
    "            return self._labels\n",
    "        except:\n",
    "            self._build_vocab()\n",
    "            return self._labels\n",
    "\n",
    "    @labels.setter\n",
    "    def labels(self, value):\n",
    "        if value is not None:\n",
    "            self._labels = value\n",
    "            \n",
    "    @vocab.setter\n",
    "    def vocab(self, value):\n",
    "        if value is not None:\n",
    "            self._vocab = value\n",
    "    \n",
    "    def decode_sentence_index(self, words, index):\n",
    "        return self.decode_sentence(words[index])\n",
    "    \n",
    "    def decode_sentence(self, words):\n",
    "        return ' '.join([ self.vocab.itos[w] for w in words])\n",
    "\n",
    "    def encode_sentence(self, sentence):\n",
    "        return self.vocab.lookup_indices(self.tokenizer(sentence))\n",
    "\n",
    "    def _build_vocab(self):\n",
    "        counter_line = Counter()\n",
    "        labels = Counter()\n",
    "        for (label, line) in self.train:\n",
    "            counter_line.update(self.tokenizer(line))\n",
    "            labels[label] += 1\n",
    "        self._vocab = Vocab(counter_line, specials=self.specials, min_freq=self.min_freq)\n",
    "        self._labels = LabelSet(labels)\n",
    "        \n",
    "    def to_databunch(self, batch_size=None, shuffle=True, vocab=None, labels=None, min_freq=None, language=None, offset=None, balance=False, collate=None, **kwargs):\n",
    "        r = copy.copy(self)\n",
    "        r.batch_size = batch_size\n",
    "        r.shuffle = shuffle\n",
    "        r.vocab = vocab\n",
    "        r.labels = labels\n",
    "        r.min_freq = min_freq\n",
    "        r.language = language\n",
    "        r.offset = offset\n",
    "        if collate is not None:\n",
    "            r = r.collate(collate)\n",
    "        return Databunch(None, r.train, r.valid, r.test, batch_size=r.batch_size, valid_batch_size=r.batch_size, shuffle=r.shuffle, collate=r._collate, **kwargs)\n",
    "    \n",
    "class PaddedTextCollection(TextCollection):\n",
    "    def _collate(self, batch):\n",
    "        label_list, text_list = [], []\n",
    "        for (_label, _text) in batch:\n",
    "            label_list.append(self.labels[_label])\n",
    "            processed_text = torch.tensor(self.encode_sentence(_text), dtype=torch.int64)\n",
    "            text_list.append(processed_text)\n",
    "        label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "        text_list = pad_sequence(text_list, batch_first=True, padding_value=self.vocab.stoi['<pad>'])\n",
    "        return text_list, label_list\n",
    "\n",
    "    def decode_sentence_index(self, words, index):\n",
    "        return super().decode_sentence(words[index].squeeze())\n",
    "        \n",
    "    def decode_sentences(self, words):\n",
    "        return [ self.decode_sentence(words, i) for i in range(len(words))]\n",
    "    \n",
    "class OffsetTextCollection(TextCollection):\n",
    "    def _collate(self, batch):\n",
    "        label_list, text_list, offsets = [], [], [0]\n",
    "        for (_label, _text) in batch:\n",
    "            label_list.append(self.labels[_label])\n",
    "            processed_text = torch.tensor(self.encode_sentence(_text), dtype=torch.int64)\n",
    "            text_list.append(processed_text)\n",
    "            offsets.append(processed_text.size(0))\n",
    "        label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "        offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "        text_list = torch.cat(text_list)\n",
    "        return text_list, offsets, label_list\n",
    "\n",
    "    def decode_sentence_index(self, words, offsets, index):\n",
    "        start = offsets[index]\n",
    "        end = offsets[index+1] if index < len(offsets)-1 else len(words)\n",
    "        return super().decode_sentence(words[start:end])\n",
    "        \n",
    "    def decode_sentences(self, words, offsets):\n",
    "        return [ self.decode_sentence(words, offsets, i) for i in range(len(offsets))]\n",
    "    \n",
    "class LabelSet:\n",
    "    def __init__(self, labels):\n",
    "        self.labels = labels\n",
    "        self._itol = list(labels.keys())\n",
    "        self._ltoi = {l:i for i, l in enumerate(self._itol)}\n",
    "        \n",
    "    def __getitem__(self, label):\n",
    "        return self._ltoi[label]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._itol)\n",
    "    \n",
    "    def lookup_labels(self, labels):\n",
    "        return [self._ltoi[l] for l in labels]\n",
    "    \n",
    "    def lookup_ints(self, ints):\n",
    "        return [self._itol[i] for i in ints]\n",
    "\n",
    "class TextDataSet:\n",
    "    def __init__(self, it):\n",
    "        self.data = list(it)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data.__getitem__(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

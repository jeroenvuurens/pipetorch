{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dd8d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imagedframe.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imagedframe.py\n",
    "from ..data.dframe import DFrame, Databunch\n",
    "from ..data.kagglereader import Kaggle\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageStat\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def LoadImage(fp):\n",
    "    return Image.open(fp[0])\n",
    "\n",
    "def LoadImageFast(fp):\n",
    "    import pyvips\n",
    "    image = pyvips.Image.new_from_file(fp[0], access=\"sequential\")\n",
    "    image = image.colourspace(\"srgb\")\n",
    "    mem_img = image.write_to_memory()\n",
    "    return np.frombuffer(mem_img, dtype=np.uint8).reshape(image.height, image.width, 3)\n",
    "\n",
    "def _subplots(rows, cols, imgsize=4, figsize=None, title=None, **kwargs):\n",
    "    \"Like `plt.subplots` but with consistent axs shape, `kwargs` passed to `fig.suptitle` with `title`\"\n",
    "    if figsize is None:\n",
    "        figsize = (imgsize*cols, imgsize*rows)\n",
    "    fig, axs = plt.subplots(rows,cols,figsize=figsize)\n",
    "    if rows==cols==1:\n",
    "        axs = [[axs]]\n",
    "    elif (rows==1 and cols!=1) or (cols==1 and rows!=1):\n",
    "        axs = [axs]\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, **kwargs)\n",
    "    return np.array(axs)\n",
    "\n",
    "def _show_batch(ds, rows=3, imgsize=(20,20), figsize=(10,10), classes=None, normalized_mean=None, normalized_std=None):\n",
    "    inv_normalizer = lambda x:x\n",
    "    if normalized_std is not None and normalized_mean is not None:\n",
    "            inv_normalizer = transforms.Normalize(mean=tuple(-m/s for m, s in zip(normalized_mean, normalized_std)), std=tuple(1/s for s in normalized_std))\n",
    "\n",
    "    axs = _subplots(rows, rows, imgsize=imgsize, figsize=figsize).flatten()\n",
    "\n",
    "    for i, ax in enumerate(axs):\n",
    "        img, y = ds[random.randrange(0, len(ds))]\n",
    "        img = transforms.Resize([100,100])(img)\n",
    "        img = inv_normalizer(img)\n",
    "        try:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        except: pass\n",
    "        try:\n",
    "            img = img.numpy()\n",
    "#                 if img.shape[0] == 1:\n",
    "#                     img = img.squeeze(axis=0)\n",
    "#                 elif img.shape[0] == 3:\n",
    "#                     img = img.permute(1, 2, 0)\n",
    "        except: pass\n",
    "        if img.shape[0] == 1:\n",
    "            img = img.squeeze(axis=0)\n",
    "        elif img.shape[0] == 3:\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "        img = np.clip(img, 0, 1)    \n",
    "        ax.imshow(img)\n",
    "        try:\n",
    "            y = classes[int(y)]\n",
    "        except:\n",
    "            raise\n",
    "        ax.set_title(f'y={y}')\n",
    "    for ax in axs.flatten()[i:]:\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "class ImageDatabunch(Databunch):\n",
    "    def __init__(self, train_ds, valid_ds=None, test_ds=None, batch_size=32, \n",
    "                 valid_batch_size=None, num_workers=2, shuffle=True, pin_memory=False, \n",
    "                 balance=False, collate=None, \n",
    "                 normalized_mean=None, normalized_std=None, classes=None):\n",
    "        if valid_batch_size is None:\n",
    "            valid_batch_size = batch_size\n",
    "        try:\n",
    "            self.classes = classes or train_ds.classes\n",
    "        except:\n",
    "            try:\n",
    "                self.classes = classes or train_ds.dataset.classes\n",
    "            except: pass\n",
    "        try:\n",
    "            self.normalized_mean = normalized_mean or train_ds.normalized_mean\n",
    "            self.normalized_std = normalized_std or train_ds.normalized_std\n",
    "        except:\n",
    "            try:\n",
    "                self.normalized_mean = normalized_mean or train_ds.dataset.normalized_mean\n",
    "                self.normalized_std = normalized_std or train_ds.dataset.normalized_std\n",
    "            except: pass\n",
    "        super().__init__(None, train_ds, valid_ds=valid_ds, test_ds=test_ds, batch_size=batch_size, \n",
    "                         valid_batch_size=valid_batch_size, num_workers=num_workers, shuffle=shuffle, \n",
    "                         pin_memory=pin_memory, balance=balance, collate=collate)\n",
    "\n",
    "    @classmethod\n",
    "    def from_train_test_ds(cls, train_valid_ds, test_ds, valid_perc=0.2, \n",
    "                           batch_size=32, valid_batch_size=None, \n",
    "                           num_workers=2, shuffle=True, pin_memory=False, balance=False, collate=None,\n",
    "                           classes=None, normalized_mean=None, normalized_std=None):\n",
    "        valid_length = int(valid_perc * len(train_valid_ds))\n",
    "        train_length = len(train_valid_ds) - valid_length\n",
    "        if shuffle:\n",
    "            train_ds, valid_ds = random_split(train_valid_ds, [train_length, valid_length])\n",
    "        else:\n",
    "            train_ds = train_valid_ds[train_length]\n",
    "            valid_ds = train_valid_ds[valid_length]\n",
    "        return cls(train_ds, valid_ds, test_ds, batch_size=batch_size, \n",
    "                   valid_batch_size=valid_batch_size, num_workers=num_workers, shuffle=shuffle, \n",
    "                   pin_memory=pin_memory, balance=balance, collate=collate, classes=classes,\n",
    "                   normalized_mean=normalized_mean, normalized_std=normalized_std)\n",
    "        \n",
    "    def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        try:\n",
    "            _show_batch( self.train_ds, rows=rows, imgsize=imgsize, figsize=figsize, classes=self.classes,\n",
    "                       normalized_mean=self.normalized_mean, normalized_std=self.normalized_std)\n",
    "        except:\n",
    "            _show_batch( self.train_ds, rows=rows, imgsize=imgsize, figsize=figsize, classes=self.classes)\n",
    "            \n",
    "\n",
    "class ImageDFrame(DFrame):\n",
    "    _metadata = DFrame._metadata + ['_pt_dataset_transforms', '_pt_normalize', '_pt_normalized_mean', '_pt_normalized_std',\n",
    "                                    '_pt_classes', '_pt_class_to_idx']\n",
    "\n",
    "    _internal_names = DFrame._internal_names + ['_pt__locked_normalized_mean', '_pt__locked_normalized_std']\n",
    "    \n",
    "    _internal_names_set = set( _internal_names )\n",
    "    \n",
    "    def __init__(self, data, *args, classes=None, **kwargs):\n",
    "        super().__init__(data, *args, **kwargs)\n",
    "        self._pt_dtype = str\n",
    "        self._pt__locked_normalized_mean = None\n",
    "        self._pt__locked_normalized_std = None\n",
    "        self.normalize()\n",
    "        self._pt_classes = classes\n",
    "        \n",
    "    @classmethod\n",
    "    def read_from_kaggle(cls, dataset, filename=None, shared=False, force=False, **kwargs):\n",
    "        k = Kaggle(dataset, shared=shared)\n",
    "        if force:\n",
    "            k.remove_user()\n",
    "        folder = k.file(filename)\n",
    "        subfolders = len([ 1 for file in folder.glob('**/*') if file.is_dir() ])\n",
    "        if subfolders > 1:\n",
    "            return cls.from_image_folder(folder)\n",
    "        else:\n",
    "            return cls.from_image_files(folder, **kwargs)\n",
    "\n",
    "    def to_databunch(self, datasetclass=None, batch_size=32, valid_batch_size=None, \n",
    "                     num_workers=0, shuffle=True, pin_memory=False, \n",
    "                     balance=False, collate=None):\n",
    "        return ImageDatabunch(*self.to_datasets(datasetclass=datasetclass), \n",
    "                         batch_size=batch_size, valid_batch_size=valid_batch_size,\n",
    "                         num_workers=num_workers, shuffle=shuffle, \n",
    "                         pin_memory=pin_memory, balance=balance, collate=collate, classes=self.classes,\n",
    "                         normalized_mean=self.normalized_mean, normalized_std=self.normalized_std)  \n",
    "    \n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ImageDFrame\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._pt_classes\n",
    "    \n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return self._pt_class_to_idx\n",
    "    \n",
    "    @classes.setter\n",
    "    def classes(self, value):\n",
    "        if value is not None:\n",
    "            self._pt_classes = value\n",
    "            self._pt_class_to_idx = { c:i for i, c in enumerate(value) }\n",
    "    \n",
    "    def _dataset_pre_transforms(self):\n",
    "        return [ LoadImage ]\n",
    "    \n",
    "    def _dataset_post_transforms(self):\n",
    "        return [ transforms.ToTensor() ]\n",
    "    \n",
    "    def _train_transformation_parameters(self, train_dset):\n",
    "        \"\"\"\n",
    "        This will be called from DFrame when the datasets are consructed on the train dataset.\n",
    "        \"\"\"\n",
    "        if self._pt_normalize:\n",
    "            if self._pt_normalized_mean is None or self._pt_normalized_std is None:\n",
    "                n = 0\n",
    "                sample = range(len(train_set)) if len(train_dset) < 100 else random.sample(range(len(train_dset)), min(100, len(train_dset)))\n",
    "                dset = train_dset.to_dataset()\n",
    "                for i in sample:\n",
    "                    x, y = dset[i]\n",
    "                    try:\n",
    "                        channels\n",
    "                    except:\n",
    "                        channels = len(x)\n",
    "                        x1 = [0.0 for i in range(channels)]\n",
    "                        x2 = [0.0 for i in range(channels)]\n",
    "\n",
    "                    for c in range(channels):\n",
    "                        x1[c] += x[c].view(-1).sum()\n",
    "                        x2[c] += (x[c].view(-1) ** 2).sum()\n",
    "                    n = n + x[0].shape[0] * x[0].shape[1]\n",
    "                sd = np.zeros(channels)\n",
    "                mean = np.zeros(channels)\n",
    "                for c in range(channels):\n",
    "                    sd[c] = np.sqrt(((n * x2[c]) - (x1[c] * x1[c])).numpy() / (n * (n - 1)))\n",
    "                    mean[c] = (x1[c] * x1[c]).numpy() / (n * (n - 1))\n",
    "                self._pt__locked_normalized_mean = torch.tensor(mean) \n",
    "                self._pt__locked_normalized_std = torch.tensor(sd)\n",
    "                \n",
    "            else:\n",
    "                self._pt__locked_normalized_mean = self._pt_normalized_mean\n",
    "                self._pt__locked_normalized_std = self._pt_normalized_std\n",
    "            return True\n",
    "\n",
    "    def normalize(self, do=True, normalized_mean=None, normalized_std=None):\n",
    "        \"\"\"\n",
    "        Normalize the images. You can either supply normalize with a precalculated mean and standard\n",
    "        deviation per channel, or pass True to automatically calculate these parameters on the \n",
    "        training set. This will require an additional pass over the training set.\n",
    "        \n",
    "        Arguments:\n",
    "            do: bool (True) - if True images are normalized\n",
    "            \n",
    "            normalized_mean: (float)\n",
    "                set of precalculated means for the dataset. \n",
    "                The set size should be the same as the number of channels in the images.\n",
    "                \n",
    "            normalized_std: (float)\n",
    "                set of precalculated standard deviations for the dataset\n",
    "                The set size should be the same as the number of channels in the images.\n",
    "        \"\"\"\n",
    "        self._pt_normalize = do\n",
    "        self._pt_normalized_mean = torch.tensor(normalized_mean) if normalized_mean is not None else None\n",
    "        self._pt_normalized_std = torch.tensor(normalized_std) if normalized_std is not None else None\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def normalized_mean(self):\n",
    "        return self._pt__locked_normalized_mean    \n",
    "        \n",
    "    @normalized_mean.setter\n",
    "    def normalized_mean(self, value):\n",
    "        self._pt__locked_normalized_mean = value\n",
    "    \n",
    "    @property\n",
    "    def normalized_std(self):\n",
    "        return self._pt__locked_normalized_std\n",
    "    \n",
    "    @normalized_std.setter\n",
    "    def normalized_std(self, value):\n",
    "        self._pt__locked_normalized_std = value\n",
    "        \n",
    "    def _dataset_transforms(self, pre=True, train=True, standard=True, post=True, normalize=True):\n",
    "        t = super()._dataset_transforms(pre=pre, train=train, standard=standard, post=post)\n",
    "        if normalize and self._pt__locked_normalized_mean is not None and self._pt__locked_normalized_std is not None:\n",
    "            t.append(transforms.Normalize(mean=self._pt__locked_normalized_mean, \n",
    "                                          std=self._pt__locked_normalized_std))\n",
    "        return t\n",
    "    \n",
    "    def train_images_ds(self):\n",
    "        \"\"\"\n",
    "        returns a version of the train DataSet, for which normalization and post_transforms are turned off\n",
    "        in other words, this will return the images just before they are converted to tensors. \n",
    "        \"\"\"\n",
    "        return self.dtype(False)._dset_indices(self._train_indices, self._dataset_transforms(post=False, normalize=False)).to_dataset()\n",
    "    \n",
    "    def show_batch(self, rows=3, imgsize=(20,20), figsize=(10,10)):\n",
    "        \"\"\"\n",
    "        Shows a sample of rows*rows images from the training set.\n",
    "        \"\"\"\n",
    "        _show_batch( self.train_images_ds(), rows=rows, imgsize=imgsize, figsize=figsize, classes=self.classes)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_binary_folder(cls, folder, **kwargs):\n",
    "        \"\"\"\n",
    "        Construct an ImageDFrame from the filelist that is obtained from TorchVision's ImageFolder,\n",
    "        in other words, the subfolders are the class labels assigned to the files they contain.\n",
    "        \n",
    "        from_binary_folder assumes that we will attempt to use the dataset with a BCELoss functions\n",
    "        and put the target variable as float32 in a column (2D) vector \n",
    "        \"\"\"\n",
    "        try:\n",
    "            folder.samples\n",
    "        except:\n",
    "            folder = ImageFolder(root=folder)\n",
    "        r = ImageDFrame(folder.samples, columns=['filename', 'target'], classes=folder.classes)\n",
    "        r.target = r.target.astype(np.int64)\n",
    "        return r\n",
    "    \n",
    "    @classmethod\n",
    "    def from_image_folder(cls, folder):\n",
    "        \"\"\"\n",
    "        Construct an ImageDFrame from the filelist that is obtained from TorchVision's ImageFolder,\n",
    "        in other words, the subfolders are the class labels assigned to the files they contain.\n",
    "\n",
    "        from_image_folder assumes the data is used with a CrossEntropyLoss function\n",
    "        and puts the target variable as long in a row (1D) vector \n",
    "        \"\"\"\n",
    "        try:\n",
    "            folder.samples\n",
    "        except:\n",
    "            folder = ImageFolder(root=folder)\n",
    "        r = ImageDFrame(folder.samples, columns=['filename', 'target'], classes=folder.classes)\n",
    "        r.target = r.target.astype(np.int64)\n",
    "        return r\n",
    "\n",
    "    @classmethod\n",
    "    def from_image_files(cls, folder, ext=None, omit=None, delimiter='.'):\n",
    "        \"\"\"\n",
    "        Construct an ImageDFrame from a folder with files in which the\n",
    "        first part of the filename indicates the class label, e.g. horse.1.jpg,\n",
    "        cow.2.jpg.\n",
    "        \n",
    "        Args:\n",
    "            folder: str or Path\n",
    "                folder containing the files\n",
    "            ext: str (None)\n",
    "                extension of the files that are included as images\n",
    "            omit: [ str ] (None)\n",
    "                omit all files that end with any of the give strings\n",
    "            delimiter: str ('.')\n",
    "                delimiter used to obtain the class label from the filename.\n",
    "                By default a '.' is used, in which case horse.1.jpg will use the\n",
    "                name 'horse' as its class label.\n",
    "        \"\"\"\n",
    "        if type(folder) == str:\n",
    "            folder = Path(folder)\n",
    "        if ext:\n",
    "            files = list(folder.glob(f'*.{ext}'))\n",
    "        else: \n",
    "            files = list(folder.glob('*'))\n",
    "        if omit is not None:\n",
    "            for o in omit:\n",
    "                files = [ f for f in files if not f.endswith(o) ]\n",
    "        classes = [ ('/' + str(f)).split('/')[-1] for f in files ]\n",
    "        classes = [ c.split(delimiter)[0] for c in classes ]\n",
    "        uniqueclasses = list(set(classes))\n",
    "        str2class = { c:i for i, c in enumerate(uniqueclasses) }\n",
    "        classes = [ str2class[c] for c in classes ]\n",
    "        files = [ (str(f), c) for f, c in zip(files, classes) ]\n",
    "        r = ImageDFrame(files, columns=['filename', 'target'], classes=uniqueclasses)\n",
    "        r.target = r.target.astype(np.int64)\n",
    "        return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e9fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2aa98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
